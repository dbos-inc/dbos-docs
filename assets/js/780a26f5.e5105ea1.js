"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[6928],{968:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>a,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"typescript/examples/hacker-news-agent","title":"Hacker News Research Agent","description":"This example is also available in Python.","source":"@site/docs/typescript/examples/hacker-news-agent.md","sourceDirName":"typescript/examples","slug":"/typescript/examples/hacker-news-agent","permalink":"/typescript/examples/hacker-news-agent","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"displayed_sidebar":"examplesSidebar","sidebar_position":10,"title":"Hacker News Research Agent"},"sidebar":"examplesSidebar","previous":{"title":"Fault-Tolerant Checkout","permalink":"/typescript/examples/checkout-tutorial"},"next":{"title":"Kafka Alert Queue","permalink":"/typescript/examples/kafka-alert-queue"}}');var r=t(4848),o=t(8453);const i={displayed_sidebar:"examplesSidebar",sidebar_position:10,title:"Hacker News Research Agent"},a=void 0,c={},l=[{value:"Main Research Workflow",id:"main-research-workflow",level:2},{value:"Research Query Workflow",id:"research-query-workflow",level:2},{value:"Agent Decision-Making Steps",id:"agent-decision-making-steps",level:2},{value:"Search API Steps",id:"search-api-steps",level:2},{value:"Synthesize Findings Step",id:"synthesize-findings-step",level:2},{value:"Try it Yourself!",id:"try-it-yourself",level:2},{value:"Setting Up OpenAI",id:"setting-up-openai",level:3},{value:"Running Locally",id:"running-locally",level:3}];function u(n){const e={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...n.components},{Details:t}=e;return t||function(n,e){throw new Error("Expected "+(e?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.admonition,{type:"info",children:(0,r.jsxs)(e.p,{children:["This example is also available in ",(0,r.jsx)(e.a,{href:"../../python/examples/hacker-news-agent",children:"Python"}),"."]})}),"\n",(0,r.jsx)(e.p,{children:"In this example, we use DBOS to build an AI deep research agent that autonomously searches Hacker News for information on any topic."}),"\n",(0,r.jsxs)(e.p,{children:["This example demonstrates how to build ",(0,r.jsx)(e.strong,{children:"reliable, durable AI agents"})," with DBOS.\nThe agent starts with a research topic, autonomously searches for related information, makes decisions about when to continue research, and synthesizes findings into a comprehensive report.\nBecause the agent is implemented as a DBOS durable workflow, it can automatically recover from any failure and continue research from where it left off, ensuring no work is lost."]}),"\n",(0,r.jsxs)(e.p,{children:["This example also demonstrates how easy it is to add DBOS to an existing agentic application.\nAdding DBOS to this agent to make it reliable and observable required changing ",(0,r.jsx)(e.strong,{children:"<20 lines of code"}),".\nAll you have to do is annotate workflows and steps."]}),"\n",(0,r.jsxs)(e.p,{children:["All source code is ",(0,r.jsx)(e.a,{href:"https://github.com/dbos-inc/dbos-demo-apps/tree/main/typescript/hacker-news-agent",children:"available on GitHub"}),"."]}),"\n",(0,r.jsx)(e.h2,{id:"main-research-workflow",children:"Main Research Workflow"}),"\n",(0,r.jsx)(e.p,{children:"The core of the agent is the main research workflow.\nIt starts with a topic and autonomously explores related queries until it has enough information, then synthesizes a final report."}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-typescript",children:'async function agenticResearchWorkflowFunction(\n  topic: string,\n  maxIterations: number,\n): Promise<ResearchResult> {\n  console.log(`Starting agentic research for: ${topic}`);\n\n  const allFindings: Finding[] = [];\n  const researchHistory: IterationResult[] = [];\n  let currentIteration = 0;\n  let currentQuery = topic;\n\n  // Main agentic research loop\n  while (currentIteration < maxIterations) {\n    currentIteration++;\n    console.log(`\ud83d\udd04 Starting iteration ${currentIteration}/${maxIterations}`);\n\n    // Research the next query\n    const iterationResult = await researchQueryWorkflow(\n      topic,\n      currentQuery,\n      currentIteration,\n    );\n    researchHistory.push(iterationResult);\n    allFindings.push(iterationResult.evaluation);\n\n    // Handle cases where no results are found\n    const storiesFound = iterationResult.stories_found;\n    if (storiesFound === 0) {\n      console.log(\n        `\u26a0\ufe0f  No stories found for \'${currentQuery}\', trying alternative approach...`,\n      );\n\n      // Generate alternative queries when hitting dead ends\n      const alternativeQuery = await DBOS.runStep(\n        () => generateFollowUps(topic, allFindings, currentIteration),\n        { name: "generateFollowUps" },\n      );\n      if (alternativeQuery) {\n        currentQuery = alternativeQuery;\n        console.log(`\ud83d\udd04 Retrying with: \'${currentQuery}\'`);\n        continue;\n      } else {\n        console.log("\u274c No alternative queries available, continuing...");\n      }\n    }\n\n    // Evaluate whether to continue research\n    console.log("\ud83e\udd14 Agent evaluating whether to continue research...");\n    const shouldContinueDecision = await DBOS.runStep(\n      () => shouldContinue(topic, allFindings, currentIteration, maxIterations),\n      { name: "shouldContinue" },\n    );\n    if (!shouldContinueDecision) {\n      console.log("\u2705 Agent decided to conclude research");\n      break;\n    }\n\n    // Generate next research question based on findings\n    if (currentIteration < maxIterations) {\n      console.log("\ud83d\udcad Agent generating next research question...");\n      const followUpQuery = await DBOS.runStep(\n        () => generateFollowUps(topic, allFindings, currentIteration),\n        { name: "generateFollowUps" },\n      );\n      if (followUpQuery) {\n        currentQuery = followUpQuery;\n        console.log(`\u27a1\ufe0f  Next research focus: \'${currentQuery}\'`);\n      } else {\n        console.log("\ud83d\udca1 No new research directions found, concluding...");\n        break;\n      }\n    }\n  }\n\n  // Final step: Synthesize all findings into comprehensive report\n  console.log("\ud83d\udccb Agent synthesizing final research report...");\n  const finalReport = await DBOS.runStep(\n    () => synthesizeFindings(topic, allFindings),\n    { name: "synthesizeFindings" },\n  );\n\n  // Return complete research results\n  return {\n    topic,\n    total_iterations: currentIteration,\n    max_iterations: maxIterations,\n    research_history: researchHistory,\n    final_report: finalReport,\n    summary: {\n      total_stories: researchHistory.reduce(\n        (sum, r) => sum + r.stories_found,\n        0,\n      ),\n      total_comments: researchHistory.reduce(\n        (sum, r) => sum + r.comments_analyzed,\n        0,\n      ),\n      queries_executed: researchHistory.map((r) => r.query),\n      avg_relevance:\n        allFindings.length > 0\n          ? allFindings.reduce((sum, f) => sum + (f.relevance_score || 0), 0) /\n            allFindings.length\n          : 0,\n    },\n  };\n}\nexport const agenticResearchWorkflow = DBOS.registerWorkflow(\n  agenticResearchWorkflowFunction,\n);\n'})}),"\n",(0,r.jsx)(e.h2,{id:"research-query-workflow",children:"Research Query Workflow"}),"\n",(0,r.jsx)(e.p,{children:"Each iteration of the main research workflow calls a child workflow that searches Hacker News for information about a query, then evaluates and returns its findings."}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-typescript",children:'async function researchQueryWorkflowFunction(\n  topic: string,\n  query: string,\n  iteration: number,\n): Promise<IterationResult> {\n  console.log(`\ud83d\udd0d Searching for stories: \'${query}\'`);\n\n  // Step 1: Search Hacker News for stories about the topic\n  const stories = await DBOS.runStep(() => searchHackerNews(query, 30), {\n    name: "searchHackerNews",\n  });\n\n  if (stories.length > 0) {\n    console.log(`\ud83d\udcda Found ${stories.length} stories, analyzing all stories...`);\n    stories.forEach((story, i) => {\n      const title = (story.title || "No title").slice(0, 80);\n      const points = story.points || 0;\n      const numComments = story.num_comments || 0;\n      console.log(\n        `  \ud83d\udcd6 Story ${i + 1}: ${title}... (${points} points, ${numComments} comments)`,\n      );\n    });\n  } else {\n    console.log("\u274c No stories found for this query");\n  }\n\n  // Step 2: Gather comments from all stories found\n  const comments: any[] = [];\n  if (stories.length > 0) {\n    console.log(`\ud83d\udcac Reading comments from ALL ${stories.length} stories...`);\n\n    for (let i = 0; i < stories.length; i++) {\n      const story = stories[i];\n      const storyId = story.objectID;\n      const title = (story.title || "Unknown").slice(0, 50);\n      const numComments = story.num_comments || 0;\n\n      if (storyId && numComments > 0) {\n        console.log(\n          `  \ud83d\udcad Reading comments from: ${title}... (${numComments} comments)`,\n        );\n        const storyComments = await DBOS.runStep(\n          () => getComments(storyId, 10),\n          { name: "getComments" },\n        );\n        comments.push(...storyComments);\n        console.log(`    \u2713 Read ${storyComments.length} comments`);\n      } else if (storyId) {\n        console.log(`  \ud83d\udcd6 Story has no comments: ${title}`);\n      } else {\n        console.log(`  \u274c No story ID available for: ${title}`);\n      }\n    }\n  }\n\n  // Step 3: Evaluate gathered data and return findings\n  console.log(\n    `\ud83e\udd14 Analyzing findings from ${stories.length} stories and ${comments.length} comments...`,\n  );\n  const evaluation = await DBOS.runStep(\n    () => evaluateResults(topic, query, stories, comments),\n    { name: "evaluateResults" },\n  );\n\n  return {\n    iteration,\n    query,\n    stories_found: stories.length,\n    comments_analyzed: comments.length,\n    evaluation,\n    stories,\n    comments,\n  };\n}\nexport const researchQueryWorkflow = DBOS.registerWorkflow(\n  researchQueryWorkflowFunction,\n);\n'})}),"\n",(0,r.jsx)(e.h2,{id:"agent-decision-making-steps",children:"Agent Decision-Making Steps"}),"\n",(0,r.jsx)(e.p,{children:"The agent's intelligence comes from three key step functions that handle decision-making:"}),"\n",(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:(0,r.jsx)("strong",{children:"Agent Evaluation Step"})}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-typescript",children:'export async function evaluateResults(\n  topic: string,\n  query: string,\n  stories: any[],\n  comments?: any[],\n): Promise<EvaluationResult> {\n  let storiesText = "";\n  const topStories: Story[] = [];\n\n  // Evaluate only the top 10 most relevant stories\n  stories.slice(0, 10).forEach((story, i) => {\n    const title = story.title || "No title";\n    const url = story.url || "No URL";\n    const hnUrl = `https://news.ycombinator.com/item?id=${story.objectID || ""}`;\n    const points = story.points || 0;\n    const numComments = story.num_comments || 0;\n    const author = story.author || "Unknown";\n\n    storiesText += `Story ${i + 1}:\\n`;\n    storiesText += `  Title: ${title}\\n`;\n    storiesText += `  Points: ${points}, Comments: ${numComments}\\n`;\n    storiesText += `  URL: ${url}\\n`;\n    storiesText += `  HN Discussion: ${hnUrl}\\n`;\n    storiesText += `  Author: ${author}\\n\\n`;\n\n    topStories.push({\n      title,\n      url,\n      hn_url: hnUrl,\n      points,\n      num_comments: numComments,\n      author,\n      objectID: story.objectID || "",\n    });\n  });\n\n  let commentsText = "";\n  if (comments) {\n    comments.slice(0, 20).forEach((comment, i) => {\n      const commentText = comment.comment_text || "";\n      if (commentText) {\n        const author = comment.author || "Unknown";\n        const excerpt =\n          commentText.length > 400\n            ? commentText.slice(0, 400) + "..."\n            : commentText;\n\n        commentsText += `Comment ${i + 1}:\\n`;\n        commentsText += `  Author: ${author}\\n`;\n        commentsText += `  Text: ${excerpt}\\n\\n`;\n      }\n    });\n  }\n\n  const prompt = `\n    You are a research agent evaluating search results for: ${topic}\n    \n    Query used: ${query}\n    \n    Stories found:\n    ${storiesText}\n    \n    Comments analyzed:\n    ${commentsText}\n    \n    Provide a DETAILED analysis with specific insights, not generalizations. Focus on:\n    - Specific technical details, metrics, or benchmarks mentioned\n    - Concrete tools, libraries, frameworks, or techniques discussed\n    - Interesting problems, solutions, or approaches described\n    - Performance data, comparison results, or quantitative insights\n    - Notable opinions, debates, or community perspectives\n    - Specific use cases, implementation details, or real-world examples\n    \n    Return JSON with:\n    - "insights": Array of specific, technical insights with context\n    - "relevance_score": Number 1-10\n    - "summary": Brief summary of findings\n    - "key_points": Array of most important points discovered\n    `;\n\n  const messages = [\n    {\n      role: "system" as const,\n      content:\n        "You are a research evaluation agent. Analyze search results and provide structured insights in JSON format.",\n    },\n    { role: "user" as const, content: prompt },\n  ];\n\n  try {\n    const response = await callLLM(messages, "gpt-4o-mini", 0.1, 2000);\n    const cleanedResponse = cleanJsonResponse(response);\n    const evaluation = JSON.parse(cleanedResponse);\n    evaluation.query = query;\n    evaluation.top_stories = topStories;\n    return evaluation;\n  } catch (error) {\n    return {\n      insights: [`Found ${stories.length} stories about ${topic}`],\n      relevance_score: 7,\n      summary: `Basic search results for ${query}`,\n      key_points: [],\n      query,\n    };\n  }\n}\n'})})]}),"\n",(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:(0,r.jsx)("strong",{children:"Follow-up Query Generation Step"})}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-typescript",children:'\nexport async function generateFollowUps(\n  topic: string,\n  currentFindings: Finding[],\n  iteration: number,\n): Promise<string | null> {\n  let findingsSummary = "";\n  currentFindings.forEach((finding) => {\n    findingsSummary += `Query: ${finding.query || "Unknown"}\\n`;\n    findingsSummary += `Summary: ${finding.summary || "No summary"}\\n`;\n    findingsSummary += `Key insights: ${JSON.stringify(finding.insights || [])}\\n`;\n    findingsSummary += `Unanswered questions: ${JSON.stringify(finding.unanswered_questions || [])}\\n\\n`;\n  });\n\n  const prompt = `\n    You are a research agent investigating: ${topic}\n    \n    This is iteration ${iteration} of your research.\n    \n    Current findings:\n    ${findingsSummary}\n    \n    Generate 2-4 SHORT KEYWORD-BASED search queries for Hacker News that explore DIVERSE aspects of ${topic}.\n    \n    CRITICAL RULES:\n    1. Use SHORT keywords (2-4 words max) - NOT long sentences\n    2. Focus on DIFFERENT aspects of ${topic}, not just one narrow area\n    3. Use terms that appear in actual Hacker News story titles\n    4. Avoid repeating previous focus areas\n    5. Think about what tech people actually discuss about ${topic}\n    \n    For ${topic}, consider diverse areas like:\n    - Performance/optimization\n    - Tools/extensions\n    - Comparisons with other technologies\n    - Use cases/applications\n    - Configuration/deployment\n    - Recent developments\n    \n    GOOD examples: ["postgres performance", "database tools", "sql optimization"]\n    BAD examples: ["What are the best practices for PostgreSQL optimization?"]\n    \n    Return only a JSON array of SHORT keyword queries: ["query1", "query2", "query3"]\n    `;\n\n  const messages = [\n    {\n      role: "system" as const,\n      content:\n        "You are a research agent. Generate focused follow-up queries based on current findings. Return only JSON array.",\n    },\n    { role: "user" as const, content: prompt },\n  ];\n\n  try {\n    const response = await callLLM(messages);\n    const cleanedResponse = cleanJsonResponse(response);\n    const queries = JSON.parse(cleanedResponse);\n    return Array.isArray(queries) && queries.length > 0 ? queries[0] : null;\n  } catch (error) {\n    return null;\n  }\n}\n'})})]}),"\n",(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:(0,r.jsx)("strong",{children:"Continuation Decision Step"})}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-typescript",children:'\nexport async function shouldContinue(\n  topic: string,\n  allFindings: Finding[],\n  currentIteration: number,\n  maxIterations: number,\n): Promise<boolean> {\n  if (currentIteration >= maxIterations) {\n    return false;\n  }\n\n  let findingsSummary = "";\n  let totalRelevance = 0;\n\n  allFindings.forEach((finding) => {\n    findingsSummary += `Query: ${finding.query || "Unknown"}\\n`;\n    findingsSummary += `Summary: ${finding.summary || "No summary"}\\n`;\n    findingsSummary += `Relevance: ${finding.relevance_score || 5}/10\\n`;\n    totalRelevance += finding.relevance_score || 5;\n  });\n\n  const avgRelevance =\n    allFindings.length > 0 ? totalRelevance / allFindings.length : 0;\n\n  const prompt = `\n    You are a research agent investigating: ${topic}\n    \n    Current iteration: ${currentIteration}/${maxIterations}\n    \n    Findings so far:\n    ${findingsSummary}\n    \n    Average relevance score: ${avgRelevance.toFixed(1)}/10\n    \n    Decide whether to continue research or conclude. PRIORITIZE THOROUGH EXPLORATION - continue if:\n    1. Current iteration is less than 75% of max_iterations\n    2. Average relevance is above 6.0 and there are likely unexplored aspects\n    3. Recent queries found significant new information\n    4. The research seems to be discovering diverse perspectives on the topic\n    \n    Only stop early if:\n    - Average relevance is below 5.0 for multiple iterations\n    - No new meaningful information in the last 2 iterations\n    - Research appears to be hitting diminishing returns\n    \n    Return JSON with:\n    - "should_continue": boolean\n    `;\n\n  const messages = [\n    {\n      role: "system" as const,\n      content:\n        "You are a research decision agent. Evaluate research completeness and decide whether to continue. Return JSON.",\n    },\n    { role: "user" as const, content: prompt },\n  ];\n\n  try {\n    const response = await callLLM(messages);\n    const cleanedResponse = cleanJsonResponse(response);\n    const decision = JSON.parse(cleanedResponse);\n    return decision.should_continue || true;\n  } catch (error) {\n    return true;\n  }\n}\n'})})]}),"\n",(0,r.jsx)(e.h2,{id:"search-api-steps",children:"Search API Steps"}),"\n",(0,r.jsx)(e.p,{children:"After deciding what terms to search for, the agent calls these steps to retrieve stories and comments from Hacker News."}),"\n",(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:(0,r.jsx)("strong",{children:"Hacker News API Steps"})}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-typescript",children:'export const searchHackerNews = async (\n  query: string,\n  maxResults = 20,\n): Promise<HackerNewsStory[]> => {\n  try {\n    const response = await fetch(\n      `${HN_SEARCH_URL}?${new URLSearchParams({\n        query,\n        hitsPerPage: maxResults.toString(),\n        tags: "story",\n      })}`,\n      { signal: AbortSignal.timeout(30000) },\n    );\n\n    if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);\n\n    const data = (await response.json()) as { hits: HackerNewsStory[] };\n    return data.hits ?? [];\n  } catch (error) {\n    console.error("Error searching Hacker News:", error);\n    return [];\n  }\n};\n\nexport const getComments = async (\n  storyId: string,\n  maxComments = 50,\n): Promise<HackerNewsComment[]> => {\n  try {\n    const response = await fetch(\n      `${HN_SEARCH_URL}?${new URLSearchParams({\n        tags: `comment,story_${storyId}`,\n        hitsPerPage: maxComments.toString(),\n      })}`,\n      { signal: AbortSignal.timeout(30000) },\n    );\n\n    if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);\n\n    const data = (await response.json()) as { hits: HackerNewsComment[] };\n    return data.hits ?? [];\n  } catch (error) {\n    console.error("Error getting comments:", error);\n    return [];\n  }\n};\n'})})]}),"\n",(0,r.jsx)(e.h2,{id:"synthesize-findings-step",children:"Synthesize Findings Step"}),"\n",(0,r.jsx)(e.p,{children:"Finally, after concluding its research, the agentic workflow calls this step to synthesize its findings into a report."}),"\n",(0,r.jsxs)(t,{children:[(0,r.jsx)("summary",{children:(0,r.jsx)("strong",{children:"Synthesize Findings Step"})}),(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-typescript",children:'\nexport async function synthesizeFindings(\n  topic: string,\n  allFindings: Finding[],\n): Promise<SynthesisResult> {\n  let findingsText = "";\n  const storyLinks: Story[] = [];\n\n  allFindings.forEach((finding, i) => {\n    findingsText += `\\n=== Finding ${i + 1} ===\\n`;\n    findingsText += `Query: ${finding.query || "Unknown"}\\n`;\n    findingsText += `Summary: ${finding.summary || "No summary"}\\n`;\n    findingsText += `Key Points: ${JSON.stringify(finding.key_points || [])}\\n`;\n    findingsText += `Insights: ${JSON.stringify(finding.insights || [])}\\n`;\n\n    if (finding.top_stories) {\n      finding.top_stories.forEach((story) => {\n        storyLinks.push({\n          title: story.title || "Unknown",\n          url: story.url || "",\n          hn_url: `https://news.ycombinator.com/item?id=${story.objectID || ""}`,\n          points: story.points || 0,\n          num_comments: story.num_comments || 0,\n        });\n      });\n    }\n  });\n\n  const storyCitations: Record<string, any> = {};\n  let citationId = 1;\n\n  allFindings.forEach((finding) => {\n    if (finding.top_stories) {\n      finding.top_stories.forEach((story) => {\n        const storyId = story.objectID || "";\n        if (storyId && !storyCitations[storyId]) {\n          storyCitations[storyId] = {\n            id: citationId,\n            title: story.title || "Unknown",\n            url: story.url || "",\n            hn_url: story.hn_url || "",\n            points: story.points || 0,\n            comments: story.num_comments || 0,\n          };\n          citationId++;\n        }\n      });\n    }\n  });\n\n  const citationsText = Object.values(storyCitations)\n    .map(\n      (cite) =>\n        `[${cite.id}] ${cite.title} (${cite.points} points, ${cite.comments} comments) - ${cite.hn_url}` +\n        (cite.url ? ` - ${cite.url}` : ""),\n    )\n    .join("\\n");\n\n  const prompt = `\n    You are a research analyst. Synthesize the following research findings into a comprehensive, detailed report about: ${topic}\n    \n    Research Findings:\n    ${findingsText}\n    \n    Available Citations:\n    ${citationsText}\n    \n    IMPORTANT: You must return ONLY a valid JSON object with no additional text, explanations, or formatting.\n    \n    Create a comprehensive research report that flows naturally as a single narrative. Include:\n    - Specific technical details and concrete examples\n    - Actionable insights practitioners can use\n    - Interesting discoveries and surprising findings\n    - Specific tools, libraries, or techniques mentioned\n    - Performance metrics, benchmarks, or quantitative data when available\n    - Notable opinions or debates in the community\n    - INLINE LINKS: When making claims, include clickable links directly in the text using this format: [link text](HN_URL)\n    - Use MANY inline links throughout the report. Aim for at least 4-5 links per paragraph.\n    \n    CRITICAL CITATION RULES - FOLLOW EXACTLY:\n    \n    1. NEVER replace words with bare URLs like "(https://news.ycombinator.com/item?id=123)"\n    2. ALWAYS write complete sentences with all words present\n    3. Add citations using descriptive link text in brackets: [descriptive text](URL)\n    4. Every sentence must be grammatically complete and readable without the links\n    5. Links should ALWAYS be to the Hacker News discussion, NEVER directly to the article.\n    \n    CORRECT examples:\n    "PostgreSQL\'s performance improvements have been significant in recent versions, as discussed in [community forums](https://news.ycombinator.com/item?id=123456), with developers highlighting [specific optimizations](https://news.ycombinator.com/item?id=789012) in query processing."\n    \n    "Redis performance issues can stem from common configuration mistakes, which are well-documented in [troubleshooting guides](https://news.ycombinator.com/item?id=345678) and [community discussions](https://news.ycombinator.com/item?id=901234)."\n    \n    "React\'s licensing changes have sparked significant community debate, as seen in [detailed discussions](https://news.ycombinator.com/item?id=15316175) about the implications for open-source projects."\n    \n    WRONG examples (NEVER DO THIS):\n    "Community discussions reveal a strong interest in the (https://news.ycombinator.com/item?id=18717168) and the common pitfalls"\n    "One significant topic is the (https://news.ycombinator.com/item?id=15316175), which raises important legal considerations"\n    \n    Always link to relevant discussions for:\n    - Every specific tool, library, or technology mentioned\n    - Performance claims and benchmarks  \n    - Community opinions and debates\n    - Technical implementation details\n    - Companies or projects referenced\n    - Version releases or updates\n    - Problem reports or solutions\n    \n    Return a JSON object with this exact structure:\n    {\n        "report": "A comprehensive research report written as flowing narrative text with inline clickable links [like this](https://news.ycombinator.com/item?id=123). Include specific technical details, tools, performance metrics, community opinions, and actionable insights. Make it detailed and informative, not just a summary."\n    }\n    `;\n\n  const messages: Message[] = [\n    {\n      role: "system",\n      content:\n        "You are a research analyst. Provide comprehensive synthesis in JSON format.",\n    },\n    { role: "user", content: prompt },\n  ];\n\n  try {\n    const response = await callLLM(\n      messages,\n      DEFAULT_MODEL,\n      DEFAULT_TEMPERATURE,\n      3000,\n    );\n    const cleanedResponse = cleanJsonResponse(response);\n    const result = JSON.parse(cleanedResponse);\n    return result;\n  } catch (error) {\n    return {\n      report: "JSON parsing error, report could not be generated.",\n      error: `JSON parsing failed, created basic synthesis. Error: ${error}`,\n    };\n  }\n}\n'})})]}),"\n",(0,r.jsx)(e.h2,{id:"try-it-yourself",children:"Try it Yourself!"}),"\n",(0,r.jsx)(e.h3,{id:"setting-up-openai",children:"Setting Up OpenAI"}),"\n",(0,r.jsxs)(e.p,{children:["To run this agent, you need an OpenAI developer account.\nObtain an API key ",(0,r.jsx)(e.a,{href:"https://platform.openai.com/api-keys",children:"here"})," and set up a payment method for your account ",(0,r.jsx)(e.a,{href:"https://platform.openai.com/account/billing/overview",children:"here"}),".\nThis agent uses ",(0,r.jsx)(e.code,{children:"gpt-4o-mini"})," for decision-making."]}),"\n",(0,r.jsx)(e.p,{children:"Set your API key as an environment variable:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-shell",children:"export OPENAI_API_KEY=<your_openai_key>\n"})}),"\n",(0,r.jsx)(e.h3,{id:"running-locally",children:"Running Locally"}),"\n",(0,r.jsx)(e.p,{children:"First, clone this repository:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-shell",children:"git clone https://github.com/dbos-inc/dbos-demo-apps.git\ncd typescript/hacker-news-agent\n"})}),"\n",(0,r.jsx)(e.p,{children:"Install dependencies and build the project:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"npm install\nnpm run build\n"})}),"\n",(0,r.jsxs)(e.p,{children:["Start Postgres (if you already use Postgres, instead set the ",(0,r.jsx)(e.code,{children:"DBOS_SYSTEM_DATABASE_URL"})," environment variable to your database connection string):"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"npx dbos postgres start\n"})}),"\n",(0,r.jsx)(e.p,{children:"Run the agent with any research topic:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:'npx agent "artificial intelligence"\n'})}),"\n",(0,r.jsx)(e.p,{children:"Or try other topics:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-shell",children:'npx agent "rust"\nnpx agent "postgres"\nnpx agent "kubernetes"\n'})}),"\n",(0,r.jsx)(e.p,{children:"The agent will autonomously research your topic, make decisions about what to investigate next, and produce a research report with insights from Hacker News."}),"\n",(0,r.jsx)(e.p,{children:"If the agent fails at any point during its research, you can restart it using its workflow ID to recover it from where it left off:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-shell",children:'npx agent "artificial intelligence" --workflow-id <id>\n'})})]})}function m(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(u,{...n})}):u(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>i,x:()=>a});var s=t(6540);const r={},o=s.createContext(r);function i(n){const e=s.useContext(o);return s.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:i(n.components),s.createElement(o.Provider,{value:e},n.children)}}}]);