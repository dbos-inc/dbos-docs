"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[6844],{6391:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>t,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"typescript/tutorials/externalmessages","title":"Kafka & SQS Integration","description":"In this guide, you\'ll learn how to use DBOS workflows to process Kafka or Simple Queue Service (SQS) messages with exactly-once semantics.","source":"@site/docs/typescript/tutorials/externalmessages.md","sourceDirName":"typescript/tutorials","slug":"/typescript/tutorials/externalmessages","permalink":"/typescript/tutorials/externalmessages","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":65,"frontMatter":{"sidebar_position":65,"title":"Kafka & SQS Integration"},"sidebar":"tutorialSidebar","previous":{"title":"Scheduled Workflows","permalink":"/typescript/tutorials/scheduled-workflows"},"next":{"title":"Logging & Tracing","permalink":"/typescript/tutorials/logging"}}');var i=n(4848),a=n(8453);const t={sidebar_position:65,title:"Kafka & SQS Integration"},o=void 0,c={},l=[{value:"Installation",id:"installation",level:2},{value:"Creating a Receiver",id:"creating-a-receiver",level:2},{value:"Registering Workflow Functions",id:"registering-workflow-functions",level:2},{value:"Deduplicating Messages",id:"deduplicating-messages",level:2},{value:"Rate-Limiting Message Processing",id:"rate-limiting-message-processing",level:2},{value:"Sending Messages",id:"sending-messages",level:2},{value:"Configuration Reference",id:"configuration-reference",level:2}];function d(e){const s={a:"a",code:"code",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components},{TabItem:n,Tabs:r}=s;return n||f("TabItem",!0),r||f("Tabs",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(s.p,{children:["In this guide, you'll learn how to use DBOS ",(0,i.jsx)(s.a,{href:"/typescript/tutorials/workflow-tutorial",children:"workflows"})," to process ",(0,i.jsx)(s.a,{href:"https://kafka.apache.org/",children:"Kafka"})," or ",(0,i.jsx)(s.a,{href:"https://aws.amazon.com/sqs/",children:"Simple Queue Service (SQS)"})," messages with exactly-once semantics."]}),"\n",(0,i.jsx)(s.h2,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(s.p,{children:"First, install an event receiver library:"}),"\n",(0,i.jsxs)(r,{groupId:"message-clients",children:[(0,i.jsx)(n,{value:"kafkajs",label:"KafkaJS",children:(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-shell",children:"npm i @dbos-inc/kafkajs-receive\n"})})}),(0,i.jsx)(n,{value:"confluentkafka",label:"Confluent Kafka",children:(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-shell",children:"npm i @dbos-inc/confluent-kafka-receive\n"})})}),(0,i.jsx)(n,{value:"sqs",label:"SQS",children:(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-shell",children:"npm i @dbos-inc/sqs-receive\n"})})})]}),"\n",(0,i.jsx)(s.h2,{id:"creating-a-receiver",children:"Creating a Receiver"}),"\n",(0,i.jsx)(s.p,{children:"The DBOS event receiver classes connect their underlying client libraries to workflows.  First, construct a DBOS event receiver instance, which is requires an underlying library object or configuration:"}),"\n",(0,i.jsxs)(r,{groupId:"message-clients",children:[(0,i.jsxs)(n,{value:"kafkajs",label:"KafkaJS",children:[(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"import { Kafka } from 'kafkajs';\nimport { KafkaReceiver } from '@dbos-inc/kafkajs-receive';\n\nconst kafkaReceiver = new KafkaReceiver(kafkaConfig);\n"})}),(0,i.jsxs)(s.p,{children:["The ",(0,i.jsx)(s.code,{children:"KafkaReceiver"})," constructor takes a KafkaJS configuration as its argument."]})]}),(0,i.jsxs)(n,{value:"confluentkafka",label:"Confluent Kafka",children:[(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"import { ConfluentKafkaReceiver } from '..';\nimport { KafkaJS as ConfluentKafkaJS } from '@confluentinc/kafka-javascript';\n\nconst kafkaReceiver = new ConfluentKafkaReceiver(kafkaConfig);\n"})}),(0,i.jsxs)(s.p,{children:["The ",(0,i.jsx)(s.code,{children:"ConfluentKafkaReceiver"})," constructor takes a configuration as its argument."]})]}),(0,i.jsxs)(n,{value:"sqs",label:"SQS",children:[(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"import { SQSClient } from '@aws-sdk/client-sqs';\nimport { SQSReceiver } from '@dbos-inc/sqs-receive';\n\nfunction createSQS() {\n  return new SQSClient({ /*configuration per SQS library...*/  });\n}\n\nconst sqsReceiver = new SQSReceiver({\n  client: createSQS,\n});\n"})}),(0,i.jsxs)(s.p,{children:["The ",(0,i.jsx)(s.code,{children:"SQSReceiver"})," constructor takes either an ",(0,i.jsx)(s.code,{children:"SQSClient"})," instance, or a function to provide it.  See the ",(0,i.jsx)(s.a,{href:"#configuration-reference",children:"configuration reference"})," below."]})]})]}),"\n",(0,i.jsx)(s.h2,{id:"registering-workflow-functions",children:"Registering Workflow Functions"}),"\n",(0,i.jsxs)(s.p,{children:["Once a receiver object is created, it can be used to connect specific incoming messages to DBOS ",(0,i.jsx)(s.a,{href:"/typescript/tutorials/workflow-tutorial",children:"workflow"})," functions:"]}),"\n",(0,i.jsxs)(r,{groupId:"message-clients",children:[(0,i.jsxs)(n,{value:"kafkajs",label:"KafkaJS",children:[(0,i.jsxs)(s.p,{children:["The KafkaJS receiver can be used in two ways.  The ",(0,i.jsx)(s.code,{children:"@consumer"})," decorator connects a ",(0,i.jsx)(s.code,{children:"static"})," class workflow method to the receiver:"]}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"@kafkaReceiver.consumer('my-topic')\n@DBOS.workflow()\nstatic async stringTopic(topic: string, partition: number, message: KafkaMessage) {\n  //...\n}\n"})}),(0,i.jsxs)(s.p,{children:["Alternatively, the ",(0,i.jsx)(s.code,{children:"registerConsumer"})," function on the receiver will connect a workflow function to the receiver."]}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"async function myWorkflowFunction(topic: string, partition: number, message: KafkaMessage) { ... }\nkafkaReceiver.registerConsumer(DBOS.registerWorkflow(myWorkflowFunction), 'my-topic');\n"})})]}),(0,i.jsxs)(n,{value:"confluentkafka",label:"Confluent Kafka",children:[(0,i.jsxs)(s.p,{children:["The ",(0,i.jsx)(s.code,{children:"ConfluentKafkaReceiver"})," instance can be used in two ways.  The ",(0,i.jsx)(s.code,{children:"@consumer"})," decorator connects a ",(0,i.jsx)(s.code,{children:"static"})," class workflow method to the receiver:"]}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"@kafkaReceiver.consumer('my-topic')\n@DBOS.workflow()\nstatic async stringTopic(topic: string, partition: number, message: ConfluentKafkaJS.Message) {\n  //...\n}\n"})}),(0,i.jsxs)(s.p,{children:["Alternatively, the ",(0,i.jsx)(s.code,{children:"registerConsumer"})," function on the receiver will connect a workflow function to the receiver."]}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"async function myWorkflowFunction(topic: string, partition: number, message: ConfluentKafkaJS.Message) { ... }\nkafkaReceiver.registerConsumer(DBOS.registerWorkflow(myWorkflowFunction), 'my-topic');\n"})})]}),(0,i.jsxs)(n,{value:"sqs",label:"SQS",children:[(0,i.jsxs)(s.p,{children:["The ",(0,i.jsx)(s.code,{children:"SQSReceiver"})," instance provides a decorator for connecting ",(0,i.jsx)(s.code,{children:"static"})," class workflow methods to message receipt:"]}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"@sqsReceiver.messageConsumer({ queueUrl: process.env['SQS_QUEUE_URL']})\n@DBOS.workflow()\nstatic async recvMessage(msg: Message) {\n  //...\n}\n"})}),(0,i.jsxs)(s.p,{children:["Note that the ",(0,i.jsx)(s.code,{children:"messageConsumer"})," configuration can override all configuration provided to the receiver instance, including the client."]})]})]}),"\n",(0,i.jsx)(s.p,{children:"Note that the function signatures should match those above, as these match the arguments that are provided by the event receivers."}),"\n",(0,i.jsx)(s.h2,{id:"deduplicating-messages",children:"Deduplicating Messages"}),"\n",(0,i.jsxs)(s.p,{children:["DBOS event receivers use a ",(0,i.jsx)(s.a,{href:"/typescript/tutorials/workflow-tutorial#workflow-ids-and-idempotency",children:"workflow id"})," to ensure that messages are processed exactly once.  This key is computed from the message."]}),"\n",(0,i.jsxs)(r,{groupId:"message-clients",children:[(0,i.jsx)(n,{value:"kafkajs",label:"KafkaJS",children:(0,i.jsx)(s.p,{children:"The message topic, partition, and offset uniquely identify a Kafka message, and are used to ensure that only one DBOS workflow is executed per message."})}),(0,i.jsx)(n,{value:"confluentkafka",label:"Confluent Kafka",children:(0,i.jsx)(s.p,{children:"The message topic, partition, and offset uniquely identify a Kafka message, and are used to ensure that only one DBOS workflow is executed per message."})}),(0,i.jsx)(n,{value:"sqs",label:"SQS",children:(0,i.jsxs)(s.p,{children:["AWS SQS messages have unique IDs assigned, which are used by default to create workflow IDs.  However, SQS messages may be sent more than once by the sender, so an ",(0,i.jsx)(s.a,{href:"#configuration-reference",children:"option"})," is provided to generate IDs from the message contents."]})})]}),"\n",(0,i.jsx)(s.h2,{id:"rate-limiting-message-processing",children:"Rate-Limiting Message Processing"}),"\n",(0,i.jsxs)(s.p,{children:["By default, event receivers start new workflows immediately upon message receipt.  If message processing should be rate-limited, DBOS ",(0,i.jsx)(s.a,{href:"/typescript/tutorials/queue-tutorial",children:"queues"})," can be used.  Generally, the queue name is provided as a parameter; see ",(0,i.jsx)(s.a,{href:"#configuration-reference",children:"configuration"})," for details."]}),"\n",(0,i.jsx)(s.h2,{id:"sending-messages",children:"Sending Messages"}),"\n",(0,i.jsxs)(s.p,{children:["The DBOS libraries for Kafka and SQS do not include code for sending messages.  Messages should be sent using the underlying messaging library, but wrapped in ",(0,i.jsx)(s.a,{href:"/typescript/tutorials/step-tutorial",children:"DBOS steps"}),"."]}),"\n",(0,i.jsxs)(r,{groupId:"message-clients",children:[(0,i.jsx)(n,{value:"kafkajs",label:"KafkaJS",children:(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"// Setup ...\nconst kafka = new Kafka(kafkaConfig);\nproducer = kafka.producer();\n\n// ... produce messages during workflow processing\nawait DBOS.runStep(async () => {\n  await producer.send({ topic, messages: [{ value: message }] });\n});    \n\n// ... shutdown\nawait producer?.disconnect();\n"})})}),(0,i.jsx)(n,{value:"confluentkafka",label:"Confluent Kafka",children:(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"// Setup ...\nconst kafka = new Kafka(kafkaConfig);\nproducer = kafka.producer();\n\n// ... produce messages during workflow processing\nawait DBOS.runStep(async () => {\n  await producer.send({ topic, messages: [{ value: message }] });\n});    \n\n// ... shutdown\nawait producer?.disconnect();\n"})})}),(0,i.jsx)(n,{value:"sqs",label:"SQS",children:(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"// Setup ...\nconst sqs = new SQSClient(sqsConfig);\n\n// ... produce messages during workflow processing\nawait DBOS.runStep(async () => {\n  await sqs.send(new SendMessageCommand(message));\n});    \n\n// SQS client - no cleanup\n"})})})]}),"\n",(0,i.jsx)(s.h2,{id:"configuration-reference",children:"Configuration Reference"}),"\n",(0,i.jsxs)(r,{groupId:"message-clients",children:[(0,i.jsxs)(n,{value:"kafkajs",label:"KafkaJS",children:[(0,i.jsx)(s.p,{children:"DBOS receivers consume kafka messages from topics and initiate workflows.  The topic(s) may be specified as a string, regular expression, or an array of strings and regular expressions."}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"export type ConsumerTopics = string | RegExp | Array<string | RegExp>;\n"})}),(0,i.jsxs)(s.p,{children:["Options for the decorator and ",(0,i.jsx)(s.code,{children:"registerConsumer"})," are the same:"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:"queueName"}),": If specified, workflows for processing messages will be enqueued"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:"config"}),": Configuration, as specified by the underlying kafka library"]}),"\n"]}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"registerConsumer<This, Return>(\n  func: (this: This, ...args: KafkaArgs) => Promise<Return>,\n  topics: ConsumerTopics,\n  options: {\n    queueName?: string;\n    config?: ConsumerConfig;\n  } = {},\n);\n\nconsumer(\n  topics: ConsumerTopics,\n  options: {\n    queueName?: string;\n    config?: ConsumerConfig\n  }\n);\n\n"})})]}),(0,i.jsxs)(n,{value:"confluentkafka",label:"Confluent Kafka",children:[(0,i.jsx)(s.p,{children:"DBOS receivers consume kafka messages from topics and initiate workflows.  The topic(s) may be specified as a string, regular expression, or an array of strings and regular expressions."}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"export type ConsumerTopics = string | RegExp | Array<string | RegExp>;\n"})}),(0,i.jsxs)(s.p,{children:["Options for the decorator and ",(0,i.jsx)(s.code,{children:"registerConsumer"})," are the same:"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:"queueName"}),": If specified, workflows for processing messages will be enqueued"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:"config"}),": Configuration, as specified by the underlying kafka library"]}),"\n"]}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"export type ConsumerTopics = string | RegExp | Array<string | RegExp>;\n\nregisterConsumer<This, Return>(\n  func: (this: This, ...args: KafkaArgs) => Promise<Return>,\n  topics: ConsumerTopics,\n  options: {\n    queueName?: string;\n    config?: KafkaJS.ConsumerConstructorConfig;\n  } = {},\n)\n\nconsumer(\n  topics: ConsumerTopics,\n  options: {\n    queueName?: string;\n    config?: KafkaJS.ConsumerConstructorConfig\n  }\n);\n\n"})})]}),(0,i.jsxs)(n,{value:"sqs",label:"SQS",children:[(0,i.jsx)(s.p,{children:"SQS message receipt can be configured at the receiver, class, or method level, with method-level configuration items overriding the class- or receiver-level defaults."}),(0,i.jsx)(s.p,{children:"Configuration items are:"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:"client"}),": Fully configured SQS client, or a function to get it"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:"workflowQueueName"}),": If specified, workflows for processing messages will be enqueued to the named queue"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:"queueUrl"}),": SQS Queue URL (or part) for receiving messages"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:"getWorkflowKey"}),": Optional function to calculate a ",(0,i.jsx)(s.a,{href:"/typescript/tutorials/workflow-tutorial#workflow-ids-and-idempotency",children:"workflow key"})," from a message; if not specified, the ",(0,i.jsx)(s.a,{href:"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-queue-message-identifiers.html",children:"message ID"})," will be used"]}),"\n"]}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-typescript",children:"interface SQSConfig {\n  client?: SQSClient | (() => SQSClient);\n  queueUrl?: string;\n  getWorkflowKey?: (m: Message) => string;\n  workflowQueueName?: string;\n}\n"})})]})]})]})}function u(e={}){const{wrapper:s}={...(0,a.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}function f(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},8453:(e,s,n)=>{n.d(s,{R:()=>t,x:()=>o});var r=n(6540);const i={},a=r.createContext(i);function t(e){const s=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),r.createElement(a.Provider,{value:s},e.children)}}}]);