"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[8407],{1164:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>i,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"production/hosting-with-kubernetes","title":"Deploying With Kubernetes","description":"This guide offers recommendations when deploying a DBOS-enabled application in Kubernetes.","source":"@site/docs/production/hosting-with-kubernetes.md","sourceDirName":"production","slug":"/production/hosting-with-kubernetes","permalink":"/production/hosting-with-kubernetes","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":70,"frontMatter":{"sidebar_position":70,"title":"Deploying With Kubernetes"},"sidebar":"tutorialSidebar","previous":{"title":"Deploying With Docker","permalink":"/production/hosting-with-docker"},"next":{"title":"Workflow Retention Policies","permalink":"/production/retention"}}');var r=o(4848),s=o(8453);const i={sidebar_position:70,title:"Deploying With Kubernetes"},a=void 0,l={},c=[{value:"Deployment",id:"deployment",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Availability",id:"availability",level:2},{value:"Scaling",id:"scaling",level:2},{value:"KEDA scaler",id:"keda-scaler",level:3},{value:"The Metrics endpoint",id:"the-metrics-endpoint",level:3},{value:"Long lived workflows",id:"long-lived-workflows",level:2},{value:"Application versionning",id:"application-versionning",level:3},{value:"Workflow patching",id:"workflow-patching",level:3},{value:"Workflow Recovery",id:"workflow-recovery",level:2}];function p(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",p:"p",pre:"pre",strong:"strong",...(0,s.R)(),...e.components},{Details:o}=n;return o||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:"This guide offers recommendations when deploying a DBOS-enabled application in Kubernetes."}),"\n",(0,r.jsx)(n.h2,{id:"deployment",children:"Deployment"}),"\n",(0,r.jsxs)(n.p,{children:["As DBOS is an open-source library that does depend on any external services except Postgres, it does not require any special Kubernetes configuration. In this guide we assume you are deploying a standard ",(0,r.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",children:"Kubernetes Deployment"}),". Here are sample manifests for deploying a service and its Postgres database:"]}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:(0,r.jsx)("strong",{children:"Sample Postgres manifest"})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n        - name: postgres\n          image: pgvector/pgvector:pg16\n          env:\n            - name: POSTGRES_USER\n              value: "postgres"\n            - name: POSTGRES_PASSWORD\n              value: "dbos"\n          ports:\n            - containerPort: 5432\n          volumeMounts:\n            - mountPath: /var/lib/postgresql/data\n              name: postgres-storage\n      volumes:\n        - name: postgres-storage\n          emptyDir: {}\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: postgres\nspec:\n  selector:\n    app: postgres\n  ports:\n    - port: 5432\n      targetPort: 5432\n'})})]}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:(0,r.jsx)("strong",{children:"Sample application manifest"})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dbos-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dbos-app\n  template:\n    metadata:\n      labels:\n        app: dbos-app\n    spec:\n      containers:\n        - name: dbos-app\n          image: <image URI>\n          env:\n            - name: DBOS_SYSTEM_DATABASE_URL\n              value: postgres://postgres:dbos@postgres:5432/dbos_app_starter\n          ports:\n            - containerPort: 8000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dbos-app\nspec:\n  type: LoadBalancer\n  selector:\n    app: dbos-app\n  ports:\n    - port: 8000\n      targetPort: 8000\n"})})]}),"\n",(0,r.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["Some DBOS configuration options contain sensitive information, like the DBOS ",(0,r.jsx)(n.a,{href:"/explanations/system-tables",children:"system database URL"})," and your ",(0,r.jsx)(n.a,{href:"/production/hosting-conductor",children:"DBOS conductor"})," API key. We recommend you use ",(0,r.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/configuration/secret/",children:"Kubernetes secrets"})," to share them with your application containers."]}),"\n",(0,r.jsx)(n.h2,{id:"availability",children:"Availability"}),"\n",(0,r.jsxs)(n.p,{children:["In addition to ",(0,r.jsx)(n.a,{href:"/production/checklist",children:"general tips"})," for running a DBOS-enabled app in production:"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Readiness probe"}),": Have the probe wait until DBOS is launched before Kubernetes can route traffic to pods."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Resource limits"}),": DBOS doesn't add significant CPU and memory overheads. However, note that all DBOS SDKs run background tasks, so setting more than 1000m CPU time can significantly improve the performance of a busy application."]}),"\n",(0,r.jsx)(n.p,{children:"We recommend configuring more than one replica in your DBOS Deployment. Each replica will start an independent DBOS worker that can process scheduled workflows and handle tasks from DBOS queues."}),"\n",(0,r.jsx)(n.h2,{id:"scaling",children:"Scaling"}),"\n",(0,r.jsxs)(n.p,{children:["Kubernetes offers a native autoscaling mechanism (",(0,r.jsx)(n.a,{href:"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/",children:"HPA"}),") and ",(0,r.jsx)(n.a,{href:"https://keda.sh",children:"KEDA"})," is another popular option. While you can scale your DBOS deployments based on resource consumption alone (e.g., memory), you can also introspect the load on DBOS queues to perform application-aware scaling, that is, scale the number of pods in your deployments based on how many DBOS workflows are currently enqueued."]}),"\n",(0,r.jsxs)(n.p,{children:["In this section we'll demonstrate how to attune KEDA to the length of a DBOS queue. The queue is configured with a per-worker concurrency cap, so we can estimate how many workers are required to sustain a queue's load by dividing the number of tasks in the queue by the worker concurrency limit. For instance, if we configure a queue with a per-worker concurrency limit of 5 tasks and there are 20 workflows in the queue, we can scale to ",(0,r.jsx)(n.code,{children:"20 / 5 = 4"})," workers to accommodate the load."]}),"\n",(0,r.jsx)(n.h3,{id:"keda-scaler",children:"KEDA scaler"}),"\n",(0,r.jsxs)(n.p,{children:["We'll use a ",(0,r.jsx)(n.a,{href:"https://keda.sh/docs/2.18/scalers/metrics-api/",children:"metrics-api"})," scaler to operate the scaling. A metrics API scaler works by polling a specified endpoint to obtain a metric value, used for computing the target number of pods in the deployment."]}),"\n",(0,r.jsxs)(n.p,{children:["In the KEDA manifest below, we expect the endpoint to return the length of a DBOS queue named ",(0,r.jsx)(n.code,{children:"queueName"}),".\nKEDA will calculate the desired replica count as: ",(0,r.jsx)(n.code,{children:"queue_length / targetValue"}),". So if your queue has 20 pending tasks and ",(0,r.jsx)(n.code,{children:"targetValue"})," is 2 (matching your per-worker concurrency limit), KEDA scales to 10 replicas."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'apiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: dbos-app-scaledobject\nspec:\n  scaleTargetRef:\n    name: dbos-app\n  minReplicaCount: 1\n  maxReplicaCount: 100\n  triggers:\n  - type: metrics-api\n    metadata:\n      url: http://dbos-app.default.svc.cluster.local:8000/metrics/queueName\n      valueLocation: queue_length\n      targetValue: "2"\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Check the ",(0,r.jsx)(n.a,{href:"https://keda.sh/docs/2.18/reference/scaledobject-spec/#overview",children:"KEDA documentation"})," to learn more about scalers."]}),"\n",(0,r.jsx)(n.h3,{id:"the-metrics-endpoint",children:"The Metrics endpoint"}),"\n",(0,r.jsx)(n.p,{children:"In this example, using the DBOS Golang SDK, an application has configured a DBOS queue with per-worker concurrency limits of 2 tasks per worker. It exposes the endpoint KEDA polls to obtain, periodically, the queue length, using the DBOS list workflows API."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-go",children:'\nqueue := dbos.NewWorkflowQueue(dbosContext, "queueName", dbos.WithWorkerConcurrency(2))\n\ntype MetricsResponse struct {\n    QueueLength int `json:"queue_length"`\n}\n\n// Return the current size of the specified queue\n// which is the number of `PENDING` and `ENQUEUED` tasks\nr.GET("/metrics/:queueName", func(c *gin.Context) {\n    queueName := c.Param("queueName")\n    workflows, err := dbos.ListWorkflows(dbosContext, dbos.WithQueuesOnly(), dbos.WithQueueName(queueName))\n    if err != nil {\n        c.JSON(http.StatusInternalServerError, gin.H{"error": fmt.Sprintf("Error computing metrics: %v", err)})\n        return\n    }\n\n    c.JSON(http.StatusOK, MetricsResponse{QueueLength: len(workflows)})\n})\n'})}),"\n",(0,r.jsx)(n.h2,{id:"long-lived-workflows",children:"Long lived workflows"}),"\n",(0,r.jsx)(n.p,{children:"DBOS workflows can run for weeks or even years, all the while their implementation evolves. DBOS supports two primitives to support upgrading your workflows' code while maintaining resources for earlier workflow invocations: application versioning and workflow patching."}),"\n",(0,r.jsx)(n.h3,{id:"application-versionning",children:"Application versionning"}),"\n",(0,r.jsx)(n.p,{children:"DBOS Transact SDKs support an application-wide version number, stored alongside workflow records in the DBOS system database. You can override the default version number logic to provide a number of your choice (for example, an image name)."}),"\n",(0,r.jsxs)(n.p,{children:["Using this version number, you can implement logic to maintain enough resources available for workflows across all versions. For instance, if your DBOS application is a regular deployment, you can maintain one deployment per application version. You can automate the logic either with a custom controller or from tools like ",(0,r.jsx)(n.a,{href:"https://flagger.app/",children:"Flagger"})," and ",(0,r.jsx)(n.a,{href:"https://argoproj.github.io/argo-rollouts/concepts/#blue-green",children:"Argo rollout"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"workflow-patching",children:"Workflow patching"}),"\n",(0,r.jsxs)(n.p,{children:["In ",(0,r.jsx)(n.a,{href:"/python/tutorials/upgrading-workflows",children:"patch mode"}),", you can keep a single deployment which pods will process (and recover) any workflow. You are responsible for maintaining ",(0,r.jsx)(n.em,{children:"patches"})," in the code, which determine the execution branch a certain workflow should take."]}),"\n",(0,r.jsx)(n.h2,{id:"workflow-recovery",children:"Workflow Recovery"}),"\n",(0,r.jsxs)(n.p,{children:["We recommend using ",(0,r.jsx)(n.a,{href:"/production/conductor",children:"DBOS Conductor"})," to manage workflow recovery in production. While you can configure DBOS to have every worker recover every pending workflow at startup, efficient recovery relies on keeping track of the ID of DBOS processes for which workflows must be recovered, which DBOS Conductor does for you."]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>i,x:()=>a});var t=o(6540);const r={},s=t.createContext(r);function i(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);