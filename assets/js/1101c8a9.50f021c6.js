"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[1259],{2414:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>u,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"python/reference/queues","title":"Queues","description":"Queues allow you to ensure that functions will be run, without starting them immediately.","source":"@site/docs/python/reference/queues.md","sourceDirName":"python/reference","slug":"/python/reference/queues","permalink":"/python/reference/queues","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Queues"},"sidebar":"tutorialSidebar","previous":{"title":"DBOS Methods & Variables","permalink":"/python/reference/contexts"},"next":{"title":"Workflow Handles","permalink":"/python/reference/workflow_handles"}}');var t=r(4848),o=r(8453);const i={sidebar_position:4,title:"Queues"},u=void 0,a={},l=[{value:"class dbos.Queue",id:"class-dbosqueue",level:3},{value:"enqueue",id:"enqueue",level:3},{value:"enqueue_async",id:"enqueue_async",level:3},{value:"SetEnqueueOptions",id:"setenqueueoptions",level:3}];function c(e){const n={a:"a",code:"code",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"Queues allow you to ensure that functions will be run, without starting them immediately.\nQueues are useful for controlling the number of functions run in parallel, or the rate at which functions are started."}),"\n",(0,t.jsx)(n.h3,{id:"class-dbosqueue",children:"class dbos.Queue"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"Queue(\n    name: str = None,\n    concurrency: Optional[int] = None,\n    limiter: Optional[QueueRateLimit] = None,\n    *,\n    worker_concurrency: Optional[int] = None,\n    priority_enabled: bool = False,\n    partition_queue: bool = False,\n    polling_interval_sec: float = 1.0,\n)\n\nclass QueueRateLimit(TypedDict):\n    limit: int\n    period: float  # In seconds\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"name"}),": The name of the queue. Must be unique among all queues in the application."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"concurrency"}),": The maximum number of functions from this queue that may run concurrently.\nThis concurrency limit is global across all DBOS processes using this queue.\nIf not provided, any number of functions may run concurrently."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"limiter"}),": A limit on the maximum number of functions which may be started in a given period."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"worker_concurrency"}),": The maximum number of functions from this queue that may run concurrently on a given DBOS process. Must be less than or equal to ",(0,t.jsx)(n.code,{children:"concurrency"}),". DBOS uses ",(0,t.jsx)(n.code,{children:"executor_id"})," to distinguish processes\u2014this is set automatically by Conductor and Cloud, but if those are not used it must be set to a unique value for each process through ",(0,t.jsx)(n.a,{href:"/python/reference/configuration",children:"configuration"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"priority_enabled"}),": Enable setting priority for workflows on this queue."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"partition_queue"}),": Enable partitioning for this queue."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"polling_interval_sec"}),": The interval at which DBOS polls the database for new workflows on this queue."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example syntax:"})}),"\n",(0,t.jsx)(n.p,{children:"This queue may run no more than 10 functions concurrently and may not start more than 50 functions per 30 seconds:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'queue = Queue("example_queue", concurrency=10, limiter={"limit": 50, "period": 30})\n'})}),"\n",(0,t.jsx)(n.h3,{id:"enqueue",children:"enqueue"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"queue.enqueue(\n    func: Callable[P, R],\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -> WorkflowHandle[R]\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Enqueue a function for processing and return a ",(0,t.jsx)(n.a,{href:"/python/reference/workflow_handles#workflowhandle",children:"handle"})," to it.\nYou can enqueue any DBOS-annotated function.\nThe ",(0,t.jsx)(n.code,{children:"enqueue"})," method durably enqueues your function; after it returns your function is guaranteed to eventually execute even if your app is interrupted."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example syntax:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from dbos import DBOS, Queue\n\nqueue = Queue("example_queue")\n\n@DBOS.step()\ndef process_task(task):\n  ...\n\n@DBOS.workflow()\ndef process_tasks(tasks):\n  task_handles = []\n  # Enqueue each task so all tasks are processed concurrently.\n  for task in tasks:\n    handle = queue.enqueue(process_task, task)\n    task_handles.append(handle)\n  # Wait for each task to complete and retrieve its result.\n  # Return the results of all tasks.\n  return [handle.get_result() for handle in task_handles]\n'})}),"\n",(0,t.jsx)(n.h3,{id:"enqueue_async",children:"enqueue_async"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"queue.enqueue_async(\n    func: Callable[P, Coroutine[Any, Any, R]],\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -> WorkflowHandle[R]\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Asynchronously enqueue an async function for processing and return an ",(0,t.jsx)(n.a,{href:"/python/reference/workflow_handles#workflowhandleasync",children:"async handle"})," to it.\nYou can enqueue any DBOS-annotated async function.\nThe ",(0,t.jsx)(n.code,{children:"enqueue_async"})," method durably enqueues your function; after it returns your function is guaranteed to eventually execute even if your app is interrupted.\nThe enqueued function is launched into a different event loop as its caller."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example syntax:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from dbos import DBOS, Queue\n\nqueue = Queue("example_queue")\n\n@DBOS.step()\nasync def process_task_async(task):\n  ...\n\n@DBOS.workflow()\nasync def process_tasks(tasks):\n  task_handles = []\n  # Enqueue each task so all tasks are processed concurrently.\n  for task in tasks:\n    handle = await queue.enqueue_async(process_task_async, task)\n    task_handles.append(handle)\n  # Wait for each task to complete and retrieve its result.\n  # Return the results of all tasks.\n  return [await handle.get_result() for handle in task_handles]\n'})}),"\n",(0,t.jsx)(n.h3,{id:"setenqueueoptions",children:"SetEnqueueOptions"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"SetEnqueueOptions(\n    *,\n    deduplication_id: Optional[str] = None,\n    priority: Optional[int] = None,\n    app_version: Optional[str] = None,\n    queue_partition_key: Optional[str] = None,\n)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Set options for enclosed workflow enqueue operations.\nThese options are ",(0,t.jsx)(n.strong,{children:"not propagated"})," to child workflows."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"deduplication_id"}),": At any given time, only one workflow with a specific deduplication ID can be enqueued in the specified queue. If a workflow with a deduplication ID is currently enqueued or actively executing (status ",(0,t.jsx)(n.code,{children:"ENQUEUED"})," or ",(0,t.jsx)(n.code,{children:"PENDING"}),"), subsequent workflow enqueue attempt with the same deduplication ID in the same queue will raise a ",(0,t.jsx)(n.code,{children:"DBOSQueueDeduplicatedError"})," exception. Defaults to ",(0,t.jsx)(n.code,{children:"None"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"priority"}),": The priority of the enqueued workflow in the specified queue. Workflows with the same priority are dequeued in ",(0,t.jsx)(n.strong,{children:"FIFO (first in, first out)"})," order. Priority values can range from ",(0,t.jsx)(n.code,{children:"1"})," to ",(0,t.jsx)(n.code,{children:"2,147,483,647"}),", where ",(0,t.jsx)(n.strong,{children:"a low number indicates a higher priority"}),". Defaults to ",(0,t.jsx)(n.code,{children:"None"}),". Workflows without assigned priorities have the highest priority and are dequeued before workflows with assigned priorities."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"app_version"}),": The application version of the workflow to enqueue. The workflow may only be dequeued by processes running that version. Defaults to the current application version."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"queue_partition_key"}),": The queue partition in which to enqueue this workflow. Use if and only if the queue is partitioned (",(0,t.jsx)(n.code,{children:"partition_queue=True"}),"). In partitioned queues, all flow control (including concurrency and rate limits) is applied to individual partitions instead of the queue as a whole."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Deduplication Example"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from dbos import DBOS, Queue, SetEnqueueOptions\nfrom dbos import error as dboserror\n\nqueue = Queue("example_queue")\n\nwith SetEnqueueOptions(deduplication_id="my_dedup_id"):\n    try:\n        handle = queue.enqueue(example_workflow, ...)\n    except dboserror.DBOSQueueDeduplicatedError as e:\n        # Handle deduplication error\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Priority Example"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'queue = Queue("priority_queue", priority_enabled=True)\n\nwith SetEnqueueOptions(priority=10):\n    # All workflows are enqueued with priority set to 10\n    # They will be dequeued in FIFO order\n    for task in tasks:\n        queue.enqueue(task_workflow, task)\n\n# first_workflow (priority=1) will be dequeued before all task_workflows (priority=10)\nwith SetEnqueueOptions(priority=1):\n    queue.enqueue(first_workflow)\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Partitioned Queue Example"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'queue = Queue("partitioned_queue", partition_queue=True, concurrency=1)\n\n@DBOS.workflow()\ndef process_task(task: Task):\n  ...\n\n\ndef on_user_task_submission(user_id: str, task: Task):\n    # Partition the task queue by user ID. As the queue has a\n    # maximum concurrency of 1, this means that at most one\n    # task can run at once per user (but tasks from different\n    # users can run concurrently).\n    with SetEnqueueOptions(queue_partition_key=user_id):\n        queue.enqueue(process_task, task)\n'})})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>u});var s=r(6540);const t={},o=s.createContext(t);function i(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function u(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);