"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[1537],{5280:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>t,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"production/hosting-with-cloud-run","title":"Deploying With Google Cloud Run","description":"This guide covers deploying a DBOS application to Google Cloud Run with a Cloud SQL for PostgreSQL database and DBOS Conductor. It includes best practices for security, availability, and scalability.","source":"@site/docs/production/hosting-with-cloud-run.md","sourceDirName":"production","slug":"/production/hosting-with-cloud-run","permalink":"/production/hosting-with-cloud-run","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":71,"frontMatter":{"sidebar_position":71,"title":"Deploying With Google Cloud Run"},"sidebar":"tutorialSidebar","previous":{"title":"Deploying With Kubernetes","permalink":"/production/hosting-with-kubernetes"},"next":{"title":"Workflow Retention Policies","permalink":"/production/retention"}}');var r=o(4848),i=o(8453);const t={sidebar_position:71,title:"Deploying With Google Cloud Run"},l="Deploying a DBOS App on Google Cloud Run",c={},a=[{value:"Choosing a Cloud Run Execution Mode",id:"choosing-a-cloud-run-execution-mode",level:2},{value:"Service",id:"service",level:3},{value:"Worker Pool",id:"worker-pool",level:3},{value:"Job",id:"job",level:3},{value:"Deploying to Cloud Run",id:"deploying-to-cloud-run",level:2},{value:"Scaling a Worker Pool",id:"scaling-a-worker-pool",level:2},{value:"Upgrading Workflow Code",id:"upgrading-workflow-code",level:2},{value:"Cloud Run revisions",id:"cloud-run-revisions",level:3},{value:"Service mode",id:"service-mode",level:3},{value:"Versioning",id:"versioning",level:4},{value:"Patching",id:"patching",level:4},{value:"Worker pool mode",id:"worker-pool-mode",level:3},{value:"Versioning",id:"versioning-1",level:4},{value:"Patching",id:"patching-1",level:4},{value:"Advanced scenarios",id:"advanced-scenarios",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:o,TabItem:s,Tabs:t}=n;return o||h("Details",!0),s||h("TabItem",!0),t||h("Tabs",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"deploying-a-dbos-app-on-google-cloud-run",children:"Deploying a DBOS App on Google Cloud Run"})}),"\n",(0,r.jsxs)(n.p,{children:["This guide covers deploying a DBOS application to ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/run",children:"Google Cloud Run"})," with a ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/sql/docs/postgres",children:"Cloud SQL for PostgreSQL"})," database and ",(0,r.jsx)(n.a,{href:"/production/conductor",children:"DBOS Conductor"}),". It includes best practices for security, availability, and scalability."]}),"\n",(0,r.jsx)(n.h2,{id:"choosing-a-cloud-run-execution-mode",children:"Choosing a Cloud Run Execution Mode"}),"\n",(0,r.jsx)(n.p,{children:"Cloud Run offers three execution modes, each mapping differently to DBOS workloads:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Service"})," handles HTTP requests and auto-scales based on traffic. Best for synchronous workflows; requires ",(0,r.jsx)(n.code,{children:"--min-instances=1"})," for long-lived or asynchronous work."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Worker Pool"})," runs always-on instances with no HTTP listener. Best for queue-heavy applications that need all DBOS background services online at all times."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Job"})," runs a container to completion and exits. Useful for periodic batch work with no always-on requirement."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"service",children:"Service"}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/run/docs/overview/what-is-cloud-run#services",children:"Cloud Run service"})," listens for HTTP requests and scales automatically based on traffic."]}),"\n",(0,r.jsxs)(n.p,{children:["Cloud Run keeps a container alive while it processes a request, making services a great fit for ",(0,r.jsx)(n.strong,{children:"short-lived, synchronous workflows"})," that complete before the response is sent, or for workflow management via the ",(0,r.jsx)(n.a,{href:"/golang/reference/client",children:"DBOS client"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["For ",(0,r.jsx)(n.strong,{children:"long-lived or asynchronous workflows"}),", a service works but requires at least one instance running at all times. DBOS runs background services\u2014the scheduler, queue runner, recovery service, and Conductor connection\u2014that operate independently of HTTP requests. If the service scales to zero, these stop. Set ",(0,r.jsx)(n.code,{children:"--min-instances=1"})," to keep them active."]}),"\n",(0,r.jsx)(n.admonition,{title:"Database connection exhaustion",type:"caution",children:(0,r.jsxs)(n.p,{children:["In Service mode, use a connection pooler like ",(0,r.jsx)(n.a,{href:"https://www.pgbouncer.org/",children:"PgBouncer"})," in front of your Cloud SQL instance. Cloud Run can scale to hundreds of instances under load, which may exhaust your database's maximum connections. PgBouncer must run in ",(0,r.jsx)(n.strong,{children:"session mode"}),"\u2014DBOS uses LISTEN/NOTIFY, which is ",(0,r.jsx)(n.a,{href:"https://www.pgbouncer.org/features.html",children:"incompatible with transaction mode"}),"."]})}),"\n",(0,r.jsx)(n.h3,{id:"worker-pool",children:"Worker Pool"}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/run/docs/overview/what-is-cloud-run#workers",children:"Cloud Run worker pool"})," runs always-on containers without an HTTP listener. Because instances never scale to zero, all DBOS background services stay online."]}),"\n",(0,r.jsxs)(n.p,{children:["Worker pools suit DBOS applications that rely heavily on queues. Every instance actively dequeues and processes workflows, and the pool can be resized via the ",(0,r.jsx)(n.a,{href:"https://docs.cloud.google.com/run/docs/reference/rest",children:"Cloud Run REST API"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["Worker pools don't auto-scale, but you can implement an ",(0,r.jsx)(n.strong,{children:"external scaler"})," from within the pool. Use a DBOS ",(0,r.jsx)(n.a,{href:"/golang/tutorials/workflow-tutorial#scheduled-workflows",children:"scheduled workflow"})," that periodically checks queue length with ",(0,r.jsx)(n.a,{href:"/golang/reference/client",children:(0,r.jsx)(n.code,{children:"ListWorkflows"})})," and calls the ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/run/docs/reference/rest/v2/projects.locations.workerPools",children:"Cloud Run Admin API"})," to resize the pool based on load.\nThis works ",(0,r.jsx)(n.em,{children:"even from within the pool"})," because DBOS guarantees only one process runs a scheduled function at a time, even across multiple instances. This prevents a thundering herd of conflicting resize requests."]}),"\n",(0,r.jsxs)(n.p,{children:["See ",(0,r.jsx)(n.a,{href:"#scaling-a-worker-pool",children:"Scaling a worker pool"})," below for a full walkthrough."]}),"\n",(0,r.jsx)(n.h3,{id:"job",children:"Job"}),"\n",(0,r.jsxs)(n.p,{children:["A ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/run/docs/overview/what-is-cloud-run#jobs",children:"Cloud Run job"})," runs a container to completion and exits without listening for HTTP requests."]}),"\n",(0,r.jsxs)(n.p,{children:["Because DBOS has a ",(0,r.jsx)(n.a,{href:"/golang/tutorials/workflow-tutorial#scheduled-workflows",children:"built-in scheduler"}),", you typically don't need Cloud Run Jobs. However, Jobs suit applications that consist entirely of periodic work with no always-on requirement\u2014the job starts, runs workflows to completion, and shuts down, so you only pay for the time it runs."]}),"\n",(0,r.jsx)(n.h2,{id:"deploying-to-cloud-run",children:"Deploying to Cloud Run"}),"\n",(0,r.jsx)(n.p,{children:"Deploying a DBOS application to Cloud Run is no different from deploying any other containerized application. You need a Dockerfile, a database, and the standard Cloud Run deployment commands."}),"\n",(0,r.jsxs)(n.p,{children:["The one DBOS-specific detail is the ",(0,r.jsx)(n.strong,{children:"database connection string"}),": it must be provided in ",(0,r.jsx)(n.code,{children:"key=value"})," format (e.g., ",(0,r.jsx)(n.code,{children:"user=postgres password=secret database=myappdb host=/cloudsql/..."}),"). On Cloud Run, use the ",(0,r.jsx)(n.code,{children:"--add-cloudsql-instances"})," flag to mount the ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/sql/docs/postgres/connect-run",children:"Cloud SQL Auth Proxy"})," Unix socket, then pass the socket path as the ",(0,r.jsx)(n.code,{children:"host"})," parameter. This gives your app a private, encrypted path to the database with no public IP."]}),"\n",(0,r.jsx)(n.admonition,{title:"Schema migration",type:"tip",children:(0,r.jsxs)(n.p,{children:["By default, DBOS creates its ",(0,r.jsx)(n.a,{href:"/explanations/system-tables",children:"system tables"})," on startup. If your Cloud Run service account doesn't have DDL privileges, run ",(0,r.jsx)(n.a,{href:"/golang/reference/cli",children:(0,r.jsx)(n.code,{children:"dbos migrate"})})," with a privileged user before deploying."]})}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:(0,r.jsx)("strong",{children:"Walkthrough: deploying a DBOS app"})}),(0,r.jsxs)(n.p,{children:["This walkthrough deploys a sample DBOS Go application (",(0,r.jsx)(n.a,{href:"https://github.com/dbos-inc/dbos-demo-apps/tree/main/golang/cloudrun",children:"source code"}),") to Cloud Run with a Cloud SQL PostgreSQL database. It covers project setup, infrastructure, and deployment in both ",(0,r.jsx)(n.strong,{children:"Service"})," and ",(0,r.jsx)(n.strong,{children:"Worker Pool"})," modes."]}),(0,r.jsx)(n.hr,{}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Google Cloud project setup"})}),(0,r.jsx)(n.p,{children:"You need a Google Cloud project with billing enabled and the required APIs turned on."}),(0,r.jsxs)(n.p,{children:["Install the ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/sdk/docs/install-sdk",children:"Google Cloud SDK"}),", then:"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"gcloud auth login\ngcloud projects create [YOUR_PROJECT_ID]\ngcloud config set project [YOUR_PROJECT_ID]\n\ngcloud beta billing projects link [YOUR_PROJECT_ID] \\\n  --billing-account=[YOUR_BILLING_ACCOUNT_ID]\n\ngcloud services enable \\\n  run.googleapis.com \\\n  sqladmin.googleapis.com \\\n  compute.googleapis.com \\\n  servicenetworking.googleapis.com \\\n  secretmanager.googleapis.com \\\n  artifactregistry.googleapis.com \\\n  cloudbuild.googleapis.com\n"})}),(0,r.jsx)(n.hr,{}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"VPC networking for Cloud SQL"})}),(0,r.jsx)(n.p,{children:"Create a VPC with a subnet for Cloud Run, allocate an IP range for VPC peering, and establish the peering connection:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Create VPC\ngcloud compute networks create main-vpc --subnet-mode=custom\n\n# Create subnet for Cloud Run\ngcloud compute networks subnets create run-subnet \\\n  --network=main-vpc \\\n  --region=us-central1 \\\n  --range=10.0.0.0/24\n\n# Allocate IP range for Cloud SQL peering\ngcloud compute addresses create google-managed-services-default \\\n  --global \\\n  --purpose=VPC_PEERING \\\n  --prefix-length=16 \\\n  --description="Peering for Google Cloud SQL" \\\n  --network=main-vpc\n\n# Establish VPC peering\ngcloud services vpc-peerings connect \\\n  --service=servicenetworking.googleapis.com \\\n  --ranges=google-managed-services-default \\\n  --network=main-vpc\n'})}),(0,r.jsx)(n.hr,{}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Cloud SQL PostgreSQL instance"})}),(0,r.jsx)(n.p,{children:"Create a private-IP-only PostgreSQL instance and an application database:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Create the Cloud SQL instance (private IP only)\ngcloud sql instances create my-postgres-instance \\\n  --database-version=POSTGRES_17 \\\n  --tier=db-perf-optimized-N-2 \\\n  --region=us-central1 \\\n  --root-password="[YOUR_STRONG_PASSWORD]" \\\n  --network=projects/[YOUR_PROJECT_ID]/global/networks/main-vpc \\\n  --no-assign-ip\n\n# Create the application database\ngcloud sql databases create myappdb --instance=my-postgres-instance\n'})}),(0,r.jsx)(n.p,{children:"Store the database password in Secret Manager:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'echo -n "[YOUR_STRONG_PASSWORD]" | gcloud secrets create db-password \\\n  --data-file=- \\\n  --replication-policy="automatic"\n'})}),(0,r.jsxs)(n.p,{children:["Store the ",(0,r.jsx)(n.a,{href:"/production/conductor",children:"DBOS Conductor"})," API key:"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'echo -n "[YOUR_CONDUCTOR_API_KEY]" | gcloud secrets create conductor-api-key \\\n  --data-file=- \\\n  --replication-policy="automatic"\n'})}),(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["For production, consider creating a dedicated database user instead of using the ",(0,r.jsx)(n.code,{children:"postgres"})," superuser. Grant it only the permissions your application needs."]})}),(0,r.jsx)(n.hr,{}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"IAM service account and permissions"})}),(0,r.jsx)(n.p,{children:"Create a service account for Cloud Run and grant it access to the secrets and Cloud SQL:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Create service account\ngcloud iam service-accounts create run-identity \\\n  --display-name="Cloud Run Service Account"\n\n# Grant access to the database password secret\ngcloud secrets add-iam-policy-binding db-password \\\n  --member="serviceAccount:run-identity@[YOUR_PROJECT_ID].iam.gserviceaccount.com" \\\n  --role="roles/secretmanager.secretAccessor"\n\n# Grant access to the Conductor API key secret (if using Conductor)\ngcloud secrets add-iam-policy-binding conductor-api-key \\\n  --member="serviceAccount:run-identity@[YOUR_PROJECT_ID].iam.gserviceaccount.com" \\\n  --role="roles/secretmanager.secretAccessor"\n\n# Grant Cloud SQL client role\ngcloud projects add-iam-policy-binding [YOUR_PROJECT_ID] \\\n  --member="serviceAccount:run-identity@[YOUR_PROJECT_ID].iam.gserviceaccount.com" \\\n  --role="roles/cloudsql.client"\n'})}),(0,r.jsxs)(n.p,{children:["When deploying with ",(0,r.jsx)(n.code,{children:"--source"}),", Cloud Build runs under the project's default Compute Engine service account, not ",(0,r.jsx)(n.code,{children:"run-identity"}),". This account needs the ",(0,r.jsx)(n.code,{children:"cloudbuild.builds.builder"})," role to build and push container images:"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# [YOUR_PROJECT_NUMBER] is the numeric project number (not the project ID)\n# Find it in the Google Cloud Console under project settings\ngcloud projects add-iam-policy-binding [YOUR_PROJECT_ID] \\\n  --member="serviceAccount:[YOUR_PROJECT_NUMBER]-compute@developer.gserviceaccount.com" \\\n  --role="roles/cloudbuild.builds.builder"\n'})}),(0,r.jsx)(n.hr,{}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Sample Dockerfile"})}),(0,r.jsx)(n.p,{children:"Multi-stage build with a distroless runtime image:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-dockerfile",metastring:'title="Dockerfile"',children:'# --- Build Stage ---\nFROM golang:1.24 as builder\n\nWORKDIR /app\nCOPY go.mod go.sum ./\nRUN go mod download && go mod tidy\nCOPY . .\nRUN CGO_ENABLED=0 GOOS=linux go build -o main .\n\n# --- Run Stage ---\nFROM gcr.io/distroless/static-debian12\nCOPY --from=builder /app/main /\nEXPOSE 8080\nCMD ["/main"]\n'})}),(0,r.jsx)(n.p,{children:"You can test the build locally against a local PostgreSQL instance before deploying:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Build the image\ndocker build -t dbos-go-starter-image .\n\n# Run with a local Postgres\ndocker run --rm -p 8080:8080 \\\n  -e DB_USER=postgres \\\n  -e DB_PASSWORD="your_local_db_password" \\\n  -e DB_NAME=myappdb \\\n  -e INSTANCE_UNIX_SOCKET=host.docker.internal \\\n  -e DBOS_CONDUCTOR_KEY="your_conductor_api_key" \\\n  dbos-go-starter-image\n'})}),(0,r.jsxs)(n.p,{children:["Then hit ",(0,r.jsx)(n.code,{children:"http://localhost:8080/workflow/1"})," to start a DBOS workflow."]}),(0,r.jsx)(n.hr,{}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Deploy"})}),(0,r.jsx)(n.p,{children:"Deploy from source\u2014Cloud Build automatically builds your container and pushes it to Artifact Registry."}),(0,r.jsxs)(t,{groupId:"cloud-run-mode",children:[(0,r.jsxs)(s,{value:"service",label:"Service",children:[(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"gcloud run deploy my-app \\\n  --source . \\\n  --region us-central1 \\\n  --service-account run-identity@[YOUR_PROJECT_ID].iam.gserviceaccount.com \\\n  --network main-vpc \\\n  --subnet run-subnet \\\n  --vpc-egress private-ranges-only \\\n  --add-cloudsql-instances [YOUR_PROJECT_ID]:us-central1:my-postgres-instance \\\n  --set-secrets DB_PASSWORD=db-password:latest,DBOS_CONDUCTOR_KEY=conductor-api-key:latest \\\n  --set-env-vars DB_USER=postgres,DB_NAME=myappdb,INSTANCE_UNIX_SOCKET=/cloudsql/[YOUR_PROJECT_ID]:us-central1:my-postgres-instance \\\n  --allow-unauthenticated\n"})}),(0,r.jsx)(n.p,{children:"Key flags:"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"--set-secrets"})})," Injects secrets from Secret Manager as environment variables."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"--add-cloudsql-instances"})})," Mounts the Cloud SQL Auth Proxy socket, letting the app connect via ",(0,r.jsx)(n.code,{children:"INSTANCE_UNIX_SOCKET"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"--source ."})})," Builds your Dockerfile remotely via ",(0,r.jsx)(n.a,{href:"http://cloud.google.com/build",children:"Cloud Build"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"--allow-unauthenticated"})})," Makes the service publicly accessible."]}),"\n"]})]}),(0,r.jsxs)(s,{value:"worker-pool",label:"Worker Pool",children:[(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"gcloud beta run worker-pools deploy my-app \\\n  --source . \\\n  --region us-central1 \\\n  --instances=1 \\\n  --service-account run-identity@[YOUR_PROJECT_ID].iam.gserviceaccount.com \\\n  --network main-vpc \\\n  --subnet run-subnet \\\n  --vpc-egress private-ranges-only \\\n  --add-cloudsql-instances [YOUR_PROJECT_ID]:us-central1:my-postgres-instance \\\n  --set-secrets DB_PASSWORD=db-password:latest,DBOS_CONDUCTOR_KEY=conductor-api-key:latest \\\n  --set-env-vars DB_USER=postgres,DB_NAME=myappdb,INSTANCE_UNIX_SOCKET=/cloudsql/[YOUR_PROJECT_ID]:us-central1:my-postgres-instance,GCP_PROJECT_ID=[YOUR_PROJECT_ID],GCP_REGION=us-central1,WORKER_POOL_NAME=my-app\n"})}),(0,r.jsx)(n.p,{children:"Key flags:"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"--set-secrets"})})," Injects secrets from Secret Manager as environment variables."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"--add-cloudsql-instances"})})," Mounts the Cloud SQL Auth Proxy socket, letting the app connect via ",(0,r.jsx)(n.code,{children:"INSTANCE_UNIX_SOCKET"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"--source ."})})," Builds your Dockerfile remotely via ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/build",children:"Cloud Build"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"--instances=1"})})," Initial always-on instance count. The ",(0,r.jsx)(n.a,{href:"#scaling-a-worker-pool-1",children:"scaling workflow"})," adjusts this based on queue depth."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"GCP_PROJECT_ID"})}),", ",(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"GCP_REGION"})}),", ",(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"WORKER_POOL_NAME"})})," Used by the scaling workflow to call the Cloud Run API."]}),"\n"]})]})]}),(0,r.jsx)(n.hr,{}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Build logs"})}),(0,r.jsxs)(n.p,{children:["During deployment, ",(0,r.jsx)(n.code,{children:"gcloud"})," streams Cloud Build output to your terminal. You can also view logs in the ",(0,r.jsx)(n.a,{href:"https://console.cloud.google.com/cloud-build/builds",children:"Cloud Build console"})," or with:"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"gcloud builds list --limit=5 --region=us-central1\ngcloud builds log [BUILD_ID] --region=us-central1\n"})}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Service URL (service mode only)"})}),(0,r.jsxs)(n.p,{children:["On successful deployment, ",(0,r.jsx)(n.code,{children:"gcloud"})," prints the service URL:"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Service URL: https://my-app-XXXXXXXXXX.us-central1.run.app\n"})}),(0,r.jsx)(n.p,{children:"Retrieve it later with:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"gcloud run services describe my-app --region us-central1 --format='value(status.url)'\n"})}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Application logs"})}),(0,r.jsxs)(n.p,{children:["For a ",(0,r.jsx)(n.strong,{children:"service"}),":"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"gcloud logging read \\\n  'resource.type=cloud_run_revision AND resource.labels.service_name=my-app' \\\n  --limit 100 --format='text'\n"})}),(0,r.jsxs)(n.p,{children:["For a ",(0,r.jsx)(n.strong,{children:"worker pool"}),":"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"gcloud logging read \\\n  'resource.type=cloud_run_worker_pool AND resource.labels.worker_pool_name=my-app' \\\n  --limit 100 --format='text'\n"})}),(0,r.jsxs)(n.p,{children:["Or view logs in the ",(0,r.jsx)(n.a,{href:"https://console.cloud.google.com/run",children:"Cloud Run console"})," under the ",(0,r.jsx)(n.strong,{children:"Logs"})," tab."]}),(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Test the deployment (service mode only)"})}),(0,r.jsx)(n.p,{children:"Start a DBOS workflow:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"curl -X GET https://my-app-XXXXXXXXXX.us-central1.run.app/workflow/1\n"})}),(0,r.jsxs)(n.p,{children:["This runs the three-step ",(0,r.jsx)(n.code,{children:"ExampleWorkflow"})," with task ID ",(0,r.jsx)(n.code,{children:"1"}),". Each step takes 5 seconds. Poll progress with:"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"curl -X GET https://my-app-XXXXXXXXXX.us-central1.run.app/last_step/1\n"})}),(0,r.jsxs)(n.p,{children:["Returns ",(0,r.jsx)(n.code,{children:"1"}),", ",(0,r.jsx)(n.code,{children:"2"}),", or ",(0,r.jsx)(n.code,{children:"3"})," depending on how many steps have completed."]})]}),"\n",(0,r.jsx)(n.h2,{id:"scaling-a-worker-pool",children:"Scaling a Worker Pool"}),"\n",(0,r.jsxs)(n.p,{children:["Worker pools don't auto-scale, but you can build an ",(0,r.jsx)(n.strong,{children:"external scaler"})," inside the pool using a DBOS ",(0,r.jsx)(n.a,{href:"/golang/tutorials/workflow-tutorial#scheduled-workflows",children:"scheduled workflow"}),". DBOS guarantees only one instance runs a scheduled function at a time\u2014even across a multi-instance pool\u2014preventing a thundering herd of conflicting resize requests."]}),"\n",(0,r.jsxs)(n.p,{children:["The complete implementation is in the ",(0,r.jsx)(n.a,{href:"https://github.com/dbos-inc/dbos-demo-apps/tree/main/golang/cloudrun",children:"cloud-run demo app"}),"."]}),"\n",(0,r.jsxs)(n.admonition,{title:"IAM permissions",type:"tip",children:[(0,r.jsx)(n.p,{children:"The worker pool's service account needs permission to manage Cloud Run resources and to act as itself when creating new revisions."}),(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:(0,r.jsx)("strong",{children:"IAM commands"})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Grant Cloud Run admin role\ngcloud projects add-iam-policy-binding [YOUR_PROJECT_ID] \\\n  --member="serviceAccount:run-identity@[YOUR_PROJECT_ID].iam.gserviceaccount.com" \\\n  --role="roles/run.admin"\n\n# Grant actAs permission on the service account itself\ngcloud iam service-accounts add-iam-policy-binding \\\n  run-identity@[YOUR_PROJECT_ID].iam.gserviceaccount.com \\\n  --member="serviceAccount:run-identity@[YOUR_PROJECT_ID].iam.gserviceaccount.com" \\\n  --role="roles/iam.serviceAccountUser"\n'})})]})]}),"\n",(0,r.jsxs)(n.p,{children:["The scheduled workflow periodically checks the queue depth and resizes the pool to match by calling the ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/run/docs/reference/rest/v2/projects.locations.workerPools",children:"Cloud Run Admin API"}),". It authenticates with a short-lived access token from the ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/compute/docs/metadata/overview",children:"GCE metadata server"}),", reads the current instance count with a ",(0,r.jsx)(n.code,{children:"GET"}),", and updates it with a ",(0,r.jsx)(n.code,{children:"PATCH"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Here's an example in Go (the same approach works in any DBOS-supported language):"}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:(0,r.jsx)("strong",{children:"Scaling workflow snippet"})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-go",metastring:'title="main.go"',children:'func ScalingWorkflow(ctx dbos.DBOSContext, scheduledTime time.Time) (string, error) {\n    // 1. Read queue length by listing all enqueued/pending workflows\n    workflows, err := dbos.ListWorkflows(ctx, dbos.WithQueuesOnly(), dbos.WithQueueName(taskQueue.Name))\n    if err != nil {\n        return "", fmt.Errorf("failed to list workflows: %w", err)\n    }\n    qlen := len(workflows)\n\n    // 2. Get current instance count from the Cloud Run Admin API\n    currentInstances, err := dbos.RunAsStep(ctx, func(stepCtx context.Context) (int, error) {\n        return getWorkerPoolInstances(stepCtx)\n    })\n    if err != nil {\n        return "", fmt.Errorf("failed to get current instances: %w", err)\n    }\n\n    // 3. Compute desired instances: ceil(queue_depth / worker_concurrency)\n    desiredInstances := int(math.Ceil(float64(qlen) / float64(WORKER_CONCURRENCY)))\n    if desiredInstances < 1 {\n        desiredInstances = 1\n    }\n\n    // 4. Resize the pool if needed\n    if desiredInstances != currentInstances {\n        _, err := dbos.RunAsStep(ctx, func(stepCtx context.Context) (string, error) {\n            return setWorkerPoolInstances(stepCtx, desiredInstances)\n        })\n        if err != nil {\n            return "", fmt.Errorf("failed to set instances: %w", err)\n        }\n    }\n\n    return fmt.Sprintf("qlen=%d, instances=%d", qlen, desiredInstances), nil\n}\n'})})]}),"\n",(0,r.jsx)(n.h2,{id:"upgrading-workflow-code",children:"Upgrading Workflow Code"}),"\n",(0,r.jsxs)(n.p,{children:["Deploying new code to Cloud Run creates a new ",(0,r.jsx)(n.strong,{children:"revision"}),". By default, Cloud Run routes all traffic to the latest revision immediately. Understanding how revisions interact with ",(0,r.jsx)(n.a,{href:"/golang/tutorials/upgrading-workflows",children:"upgrading DBOS code"})," is key to safely deploying changes without disrupting in-progress workflows."]}),"\n",(0,r.jsxs)(n.p,{children:["DBOS supports two strategies for deploying breaking changes: ",(0,r.jsx)(n.strong,{children:"versioning"})," and ",(0,r.jsx)(n.strong,{children:"patching"}),". Each maps differently to Cloud Run's revision model depending on whether you run a Service or a Worker Pool."]}),"\n",(0,r.jsx)(n.h3,{id:"cloud-run-revisions",children:"Cloud Run revisions"}),"\n",(0,r.jsxs)(n.p,{children:["Every ",(0,r.jsx)(n.code,{children:"gcloud run deploy"})," or ",(0,r.jsx)(n.code,{children:"gcloud beta run worker-pools deploy"})," creates a new revision (e.g., ",(0,r.jsx)(n.code,{children:"my-app-00001-abc"}),"). Cloud Run injects the revision name into every container as the ",(0,r.jsx)(n.code,{children:"K_REVISION"})," environment variable."]}),"\n",(0,r.jsxs)(n.p,{children:["For ",(0,r.jsx)(n.strong,{children:"services"}),", you can ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration",children:"split traffic"})," between revisions, enabling blue-green or canary deployments. By default, 100% of traffic goes to the latest revision."]}),"\n",(0,r.jsxs)(n.p,{children:["For ",(0,r.jsx)(n.strong,{children:"worker pools"}),", a new deployment replaces all running instances. Old instances are shut down regardless of what they were processing."]}),"\n",(0,r.jsx)(n.h3,{id:"service-mode",children:"Service mode"}),"\n",(0,r.jsx)(n.h4,{id:"versioning",children:"Versioning"}),"\n",(0,r.jsxs)(n.p,{children:["Set ",(0,r.jsx)(n.a,{href:"/golang/reference/dbos-context#initialization",children:(0,r.jsx)(n.code,{children:"ApplicationVersion"})})," to ",(0,r.jsx)(n.code,{children:"K_REVISION"})," so each Cloud Run revision gets a distinct DBOS version. Workflows started on a revision are tagged with that revision's version. A DBOS process only recovers workflows matching its own version, so old workflows won't be replayed with new code. To drain old workflows, keep the previous revision active (with a share of traffic or ",(0,r.jsx)(n.code,{children:"--min-instances=1"}),") until all its workflows complete. You can check with ",(0,r.jsx)(n.a,{href:"/golang/reference/methods#listworkflows",children:(0,r.jsx)(n.code,{children:"ListWorkflows"})}),"."]}),"\n",(0,r.jsx)(n.h4,{id:"patching",children:"Patching"}),"\n",(0,r.jsxs)(n.p,{children:["With ",(0,r.jsx)(n.a,{href:"/golang/tutorials/upgrading-workflows#patching",children:"patching"}),", fix the application version to a constant and enable patching in the ",(0,r.jsx)(n.a,{href:"/golang/reference/dbos-context#initialization",children:"DBOS configuration"}),". Since all revisions share the same version, new containers automatically recover in-progress workflows from previous deployments. Cloud Run routes traffic to the latest revision by default, so new requests go to the new code while the patching logic in your workflow handles the transition for recovered workflows."]}),"\n",(0,r.jsx)(n.h3,{id:"worker-pool-mode",children:"Worker pool mode"}),"\n",(0,r.jsx)(n.p,{children:"When you deploy a new worker pool revision, Cloud Run replaces all running instances. Old instances shut down, and new instances start with the new code."}),"\n",(0,r.jsx)(n.h4,{id:"versioning-1",children:"Versioning"}),"\n",(0,r.jsxs)(n.p,{children:["If ",(0,r.jsx)(n.code,{children:"ApplicationVersion"})," is set to ",(0,r.jsx)(n.code,{children:"K_REVISION"}),", the new instances have a different version than workflows started by the old instances. Those in-progress workflows won't be automatically recovered because the version doesn't match."]}),"\n",(0,r.jsxs)(n.p,{children:["To migrate them, ",(0,r.jsx)(n.a,{href:"/golang/tutorials/workflow-management#forking-workflows",children:"fork"})," the old workflows to the new version using ",(0,r.jsx)(n.a,{href:"/golang/reference/methods#forkworkflow",children:(0,r.jsx)(n.code,{children:"ForkWorkflow"})})," with the new ",(0,r.jsx)(n.code,{children:"ApplicationVersion"}),". The new workers will then execute the forked workflows. You can automate this as part of a post-deployment step or a startup routine that lists old-version workflows and forks them."]}),"\n",(0,r.jsx)(n.h4,{id:"patching-1",children:"Patching"}),"\n",(0,r.jsxs)(n.p,{children:["With a fixed application version and patching enabled, the new worker pool instances automatically recover workflows from the previous deployment. ",(0,r.jsx)(n.a,{href:"/production/conductor",children:"Conductor"})," detects that the old instances went down and that new instances with the same version are available, triggering recovery without any manual intervention."]}),"\n",(0,r.jsx)(n.h3,{id:"advanced-scenarios",children:"Advanced scenarios"}),"\n",(0,r.jsxs)(n.p,{children:["More complex deployment strategies are possible. You can combine versioning and patching\u2014for example, using versioning for major changes and patching for hotfixes within a version. In Service mode, you can use Cloud Run ",(0,r.jsx)(n.a,{href:"https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#tags",children:"revision tags"})," to route a subset of traffic to a tagged revision, letting you test new workflow code in production before shifting all traffic."]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}function h(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},8453:(e,n,o)=>{o.d(n,{R:()=>t,x:()=>l});var s=o(6540);const r={},i=s.createContext(r);function t(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);