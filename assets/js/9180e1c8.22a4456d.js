"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[3482],{2059:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>l});var o=n(5893),t=n(1151);const s={sidebar_position:17,title:"Integrating with Kafka",description:"Learn how to integrate DBOS and Kafka."},r=void 0,i={id:"tutorials/kafka-integration",title:"Integrating with Kafka",description:"Learn how to integrate DBOS and Kafka.",source:"@site/docs/tutorials/kafka-integration.md",sourceDirName:"tutorials",slug:"/tutorials/kafka-integration",permalink:"/tutorials/kafka-integration",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:17,frontMatter:{sidebar_position:17,title:"Integrating with Kafka",description:"Learn how to integrate DBOS and Kafka."},sidebar:"tutorialSidebar",previous:{title:"Using Libraries",permalink:"/tutorials/using-libraries"},next:{title:"Scheduled Workflows",permalink:"/tutorials/scheduled-workflows"}},c={},l=[];function f(e){const a={a:"a",code:"code",p:"p",pre:"pre",...(0,t.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(a.p,{children:"In this guide, you'll learn how to use DBOS transactions and workflows to process Kafka messages with exactly-once semantics."}),"\n",(0,o.jsxs)(a.p,{children:["First, install ",(0,o.jsx)(a.a,{href:"https://kafka.js.org/",children:"KafkaJS"})," in your application:"]}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{children:"npm install kafkajs\n"})}),"\n",(0,o.jsx)(a.p,{children:"Then, define your transaction or workflow. It must take in the Kafka topic, partition, and message as inputs:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-javascript",children:"import { Workflow, WorkflowContext } from '@dbos-inc/dbos-sdk';\n\nexport class KafkaExample{\n  @Workflow()\n  static async kafkaWorkflow(ctxt: WorkflowContext, topic: string, partition: number, message: KafkaMessage) {\n    ctxt.logger.info(`Message received: ${message.value?.toString()}`)\n  }\n}\n"})}),"\n",(0,o.jsxs)(a.p,{children:["Then, annotate your method with a ",(0,o.jsx)(a.a,{href:"/api-reference/decorators#kafka-consume",children:(0,o.jsx)(a.code,{children:"@KafkaConsume"})})," decorator specifiying which topic to consume from.\nAdditionally, annotate your class with a ",(0,o.jsx)(a.a,{href:"/api-reference/decorators#kafka",children:(0,o.jsx)(a.code,{children:"@Kafka"})})," decorator defining which brokers to connect to.\nDBOS invokes your method exactly-once for each message sent to the topic."]}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-javascript",children:"import { KafkaConfig, KafkaMessage} from \"kafkajs\";\nimport { Workflow, WorkflowContext, Kafka, KafkaConsume } from '@dbos-inc/dbos-sdk';\n\nconst kafkaConfig: KafkaConfig = {\n    brokers: ['localhost:9092']\n}\n\n@Kafka(kafkaConfig)\nexport class KafkaExample{\n\n  @KafkaConsume(\"example-topic\")\n  @Workflow()\n  static async kafkaWorkflow(ctxt: WorkflowContext, topic: string, partition: number, message: KafkaMessage) {\n    ctxt.logger.info(`Message received: ${message.value?.toString()}`)\n  }\n}\n"})}),"\n",(0,o.jsxs)(a.p,{children:["If you need more control, you can pass detailed configurations to both the ",(0,o.jsx)(a.code,{children:"@Kafka"})," and ",(0,o.jsx)(a.code,{children:"@KafkaConsume"})," decorators.\nThe ",(0,o.jsx)(a.code,{children:"@Kafka"})," decorator takes in a ",(0,o.jsx)(a.a,{href:"https://kafka.js.org/docs/configuration",children:"KafkaJS configuration object"})," used to configure Kafka for all methods in its class.\nThe ",(0,o.jsx)(a.code,{children:"@KafkaConsume"})," decorator takes in a ",(0,o.jsx)(a.a,{href:"https://kafka.js.org/docs/consuming#options",children:"KafkaJS consumer configuration"})," as an optional second argument.\nFor example, you can specify a custom consumer group ID:"]}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-javascript",children:'@KafkaConsume("example-topic", { groupId: "custom-group-id" })\n@Workflow()\nstatic async kafkaWorkflow(ctxt: WorkflowContext, topic: string, partition: number, message: KafkaMessage) {\n  ctxt.logger.info(`Message received: ${message.value?.toString()}`)\n}\n'})}),"\n",(0,o.jsxs)(a.p,{children:["Under the hood, DBOS constructs an ",(0,o.jsx)(a.a,{href:"./idempotency-tutorial",children:"idempotency key"})," for each Kafka message from its topic, partition, and offset and passes it into your workflow or transaction.\nThis combination is guaranteed to be unique for each Kafka cluster.\nThus, even if a message is delivered multiple times (e.g., due to transient network failures or application interruptions), your transaction or workflow processes it exactly once."]})]})}function d(e={}){const{wrapper:a}={...(0,t.a)(),...e.components};return a?(0,o.jsx)(a,{...e,children:(0,o.jsx)(f,{...e})}):f(e)}},1151:(e,a,n)=>{n.d(a,{Z:()=>i,a:()=>r});var o=n(7294);const t={},s=o.createContext(t);function r(e){const a=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function i(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),o.createElement(s.Provider,{value:a},e.children)}}}]);