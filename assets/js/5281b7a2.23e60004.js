"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[2443],{936:(e,o,t)=>{t.r(o),t.d(o,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"architecture","title":"DBOS Architecture","description":"DBOS provides a lightweight library for durable workflows built on top of Postgres.","source":"@site/docs/architecture.md","sourceDirName":".","slug":"/architecture","permalink":"/architecture","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"hide_table_of_contents":false,"title":"DBOS Architecture"},"sidebar":"tutorialSidebar","previous":{"title":"Why DBOS?","permalink":"/why-dbos"},"next":{"title":"Learn DBOS Python","permalink":"/python/programming-guide"}}');var r=t(4848),n=t(8453);const a={hide_table_of_contents:!1,title:"DBOS Architecture"},i=void 0,c={},l=[{value:"Comparison to External Workflow Orchestrators",id:"comparison-to-external-workflow-orchestrators",level:2},{value:"Applications and Databases",id:"applications-and-databases",level:2},{value:"How Workflow Recovery Works",id:"how-workflow-recovery-works",level:2},{value:"Application and Workflow Versions",id:"application-and-workflow-versions",level:2},{value:"Durable Queues",id:"durable-queues",level:2},{value:"Self-Hosting DBOS with Conductor",id:"self-hosting-dbos-with-conductor",level:2},{value:"Host Applications on DBOS Cloud",id:"host-applications-on-dbos-cloud",level:2}];function d(e){const o={a:"a",code:"code",em:"em",h2:"h2",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,n.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(o.p,{children:"DBOS provides a lightweight library for durable workflows built on top of Postgres.\nArchitecturally, an application built with DBOS looks like this:"}),"\n",(0,r.jsx)("img",{src:t(9452).A,alt:"DBOS Architecture",width:"750",className:"custom-img"}),"\n",(0,r.jsxs)(o.p,{children:["You install the DBOS library into your existing application running on your existing servers and infrastructure and connect it to a Postgres database.\nThen, you annotate workflows and steps in your application code.\nThe DBOS library ",(0,r.jsx)(o.strong,{children:"checkpoints"})," those workflows and steps in Postgres.\nIf your program fails, crashes, or is interrupted, DBOS uses those checkpoints to automatically recover your workflows from the last completed step."]}),"\n",(0,r.jsx)("img",{src:t(1436).A,alt:"DBOS Steps",width:"750",className:"custom-img"}),"\n",(0,r.jsx)(o.h2,{id:"comparison-to-external-workflow-orchestrators",children:"Comparison to External Workflow Orchestrators"}),"\n",(0,r.jsxs)(o.p,{children:["DBOS architecture is radically simpler than other workflow systems such as Temporal, Airflow or AWS Step Functions.\nAll these systems implement workflows via ",(0,r.jsx)(o.strong,{children:"external orchestration"}),".\nAt a high-level, their architectures look like this:"]}),"\n",(0,r.jsx)("img",{src:t(8427).A,alt:"External Orchestrator Architecture",width:"750",className:"custom-img"}),"\n",(0,r.jsx)(o.p,{children:"Externally orchestrated systems are made up of an orchestrator and a bunch of workers. The orchestrator runs workflow code, dispatching steps to workers through queues.\nWorkers execute steps, then return their output to the orchestrator, which persists that output to a data store then dispatches the next step.\nApplication code can't call workflows directly, but instead sends requests to the orchestrator server to start workflows and fetch their results."}),"\n",(0,r.jsx)(o.p,{children:"While DBOS can be installed into an existing application as a library, adding an external orchestrator to an application requires substantially rearchitecting it.\nFirst, you must move all workflow and step code from application servers to workers.\nThen, you must also rewrite all interaction between your application and its workflows to go through the orchestration server and its client APIs.\nNext, you must build infrastructure to operate and scale the worker servers.\nFinally, you must operate and scale the orchestration server and its underlying data store (for example, Cassandra for Temporal), which are both single points of failure for your application."}),"\n",(0,r.jsx)(o.h2,{id:"applications-and-databases",children:"Applications and Databases"}),"\n",(0,r.jsxs)(o.p,{children:["Each DBOS application server connects to a Postgres database, called the system database.\nThis database durably stores workflow and step checkpoints, and queue and message state.\nIts schema and tables are documented ",(0,r.jsx)(o.a,{href:"/explanations/system-tables",children:"here"}),".\nOne physical Postgres server can host multiple system databases for several DBOS applications.\nSeparate DBOS applications (meaning separate code bases) should not share a system database."]}),"\n",(0,r.jsx)(o.p,{children:"For example, in this diagram we deploy two DBOS applications, each with three servers.\nEach application has its own isolated system database on the same physical Postgres server, and all of the application's servers connect to its system database."}),"\n",(0,r.jsx)("img",{src:t(7486).A,alt:"DBOS System Database",width:"750",className:"custom-img"}),"\n",(0,r.jsx)(o.h2,{id:"how-workflow-recovery-works",children:"How Workflow Recovery Works"}),"\n",(0,r.jsx)(o.p,{children:"To recover workflows from failures, DBOS checkpoints in its system database the input of each workflow and the output of each step.\nWhen a program executing a workflow fails, crashes, or is interrupted, DBOS uses those checkpoints to recover the workflow from its last completed step.\nHere's how that works:"}),"\n",(0,r.jsxs)(o.ol,{children:["\n",(0,r.jsxs)(o.li,{children:["\n",(0,r.jsxs)(o.p,{children:["First, DBOS must detect that workflow execution has failed.\nFor a single-node application, on startup, DBOS looks up and attempts to recover all incomplete (",(0,r.jsx)(o.code,{children:"PENDING"}),") workflows.\nIn a distributed setting, detecting failed workflow execution can be done automatically through services like ",(0,r.jsx)(o.a,{href:"#self-hosting-dbos-with-conductor",children:"DBOS Conductor"})," or ",(0,r.jsx)(o.a,{href:"#host-applications-on-dbos-cloud",children:"DBOS Cloud"})," or manually using the admin API (more documentation ",(0,r.jsx)(o.a,{href:"/production/self-hosting/workflow-recovery",children:"here"}),")."]}),"\n"]}),"\n",(0,r.jsxs)(o.li,{children:["\n",(0,r.jsx)(o.p,{children:"Next, DBOS restarts the interrupted workflow from the beginning by calling it with its checkpointed inputs.\nAs the workflow re-executes, it checks before executing each step if that step's output is checkpointed in Postgres.\nIf there is a checkpoint, the step returns the checkpointed output instead of executing."}),"\n"]}),"\n",(0,r.jsxs)(o.li,{children:["\n",(0,r.jsxs)(o.p,{children:["Eventually, the recovered workflow reaches a step whose output is ",(0,r.jsx)(o.strong,{children:"not"})," checkpointed in Postgres.\nThe recovered workflow executes that step normally and proceeds from there, thus ",(0,r.jsx)(o.strong,{children:"resuming from the last completed step."})]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(o.p,{children:"For DBOS to be able to safely recover a workflow, your code must satisfy two requirements:"}),"\n",(0,r.jsxs)(o.ol,{children:["\n",(0,r.jsxs)(o.li,{children:["\n",(0,r.jsxs)(o.p,{children:["The workflow function must be ",(0,r.jsx)(o.strong,{children:"deterministic"}),": if executed multiple times, with the same arguments and step return values, the workflow should invoke the same steps with the same inputs in the same order. If you need to perform any non-deterministic operation like accessing the database, calling a third-party API, generating a random number, or getting the local time, you should do it in a step instead of directly in the workflow function."]}),"\n"]}),"\n",(0,r.jsxs)(o.li,{children:["\n",(0,r.jsxs)(o.p,{children:["Steps should be ",(0,r.jsx)(o.strong,{children:"idempotent"}),", meaning it should be safe to retry them multiple times.\nIf a workflow fails while executing a step, it retries the step during recovery.\nHowever, once a step completes and is checkpointed, it is never re-executed."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(o.h2,{id:"application-and-workflow-versions",children:"Application and Workflow Versions"}),"\n",(0,r.jsxs)(o.p,{children:["If code changes between when a workflow starts and when it its recovered, safe recovery may not be possible.\nTo guard against this, DBOS ",(0,r.jsx)(o.em,{children:"versions"})," applications and their workflows.\nWhen DBOS is launched, it computes an application version from a hash of the source code of your workflows. You can override the version through configuration.\nAll workflows are tagged with the application version on which they started."]}),"\n",(0,r.jsxs)(o.p,{children:["When DBOS tries to recover workflows, it only recovers workflows whose version matches the current application version.\nThis prevents unsafe recovery of workflows that depend on different code.\nTo safely recover workflows started on an older version of your code, you should start a process running that code version.\nAlternatively, you can use the ",(0,r.jsx)(o.a,{href:"/production/self-hosting/workflow-management#forking-workflows",children:"workflow fork"})," operation to restart a workflow from a specific step on a specific code version.\nFor more information, see the ",(0,r.jsx)(o.a,{href:"/production/self-hosting/workflow-recovery",children:"workflow recovery documentation"}),"."]}),"\n",(0,r.jsx)(o.h2,{id:"durable-queues",children:"Durable Queues"}),"\n",(0,r.jsxs)(o.p,{children:["One powerful feature of DBOS is that you can ",(0,r.jsx)(o.strong,{children:"enqueue"})," workflows for later execution with managed concurrency.\nYou can enqueue a workflow from within a DBOS app directly or from anywhere using a DBOS client."]}),"\n",(0,r.jsx)(o.p,{children:'When you enqueue a workflow, it may be executed on any of your application\'s servers.\nAll DBOS applications periodically poll their queues to find and execute new work.\nThis is in contrast to other queue services that have separate "worker servers" that can execute queued tasks.\nIn DBOS, all of your application servers act as queue workers, as in this diagram:'}),"\n",(0,r.jsx)("img",{src:t(5717).A,alt:"DBOS Queues",width:"750",className:"custom-img"}),"\n",(0,r.jsxs)(o.p,{children:["To help you operate at scale, DBOS queues provide ",(0,r.jsx)(o.strong,{children:"flow control"}),".\nYou can customize the rate and concurrency at which workflows are dequeued and executed.\nFor example, you can set a ",(0,r.jsx)(o.strong,{children:"worker concurrency"})," for each of your queues on each of your servers, limiting how many workflows from that queue may execute concurrently on that server.\nFor more information on queues, see the docs (",(0,r.jsx)(o.a,{href:"/python/tutorials/queue-tutorial",children:"Python"}),", ",(0,r.jsx)(o.a,{href:"/typescript/tutorials/queue-tutorial",children:"TypeScript"}),")."]}),"\n",(0,r.jsx)(o.h2,{id:"self-hosting-dbos-with-conductor",children:"Self-Hosting DBOS with Conductor"}),"\n",(0,r.jsx)(o.p,{children:"The simplest way to operate DBOS durable workflows in production is to connect your application to Conductor.\nConductor is an optional management service that helps you self-host DBOS applications.\nIt provides:"}),"\n",(0,r.jsxs)(o.ul,{children:["\n",(0,r.jsxs)(o.li,{children:[(0,r.jsx)(o.a,{href:"/production/self-hosting/workflow-recovery",children:(0,r.jsx)(o.strong,{children:"Distributed workflow recovery"})}),": In a distributed environment with many executors running durable workflows, Conductor automatically detects when the execution of a durable workflow is interrupted (for example, if its executor is restarted, interrupted, or crashes) and recovers the workflow to another healthy executor."]}),"\n",(0,r.jsxs)(o.li,{children:[(0,r.jsx)(o.a,{href:"/production/self-hosting/workflow-management",children:(0,r.jsx)(o.strong,{children:"Workflow and queue observability"})}),": Conductor provides dashboards of all active and past workflows and all queued tasks, including their status, inputs, outputs, and steps."]}),"\n",(0,r.jsxs)(o.li,{children:[(0,r.jsx)(o.a,{href:"/production/self-hosting/workflow-management",children:(0,r.jsx)(o.strong,{children:"Workflow and queue management"})}),": From the Conductor dashboard, cancel, resume, or restart any workflow execution and manage the tasks in your distributed queues."]}),"\n"]}),"\n",(0,r.jsx)(o.p,{children:"Architecturally, Conductor looks like this:"}),"\n",(0,r.jsx)("img",{src:t(5284).A,alt:"DBOS Conductor Architecture",width:"750",className:"custom-img"}),"\n",(0,r.jsx)(o.p,{children:"Each of your application servers opens a secure websocket connection to Conductor.\nAll of Conductor's features are powered by these websocket connections.\nWhen you open a Conductor dashboard in your browser, your request is sent over websocket to one of your application servers, which serves the request (for example, retrieving a list of recent workflows) and sends the result back through the websocket.\nIf one of your application servers fails, Conductor detects the failure through the closed websocket connection and, after a grace period, directs another server to recover its workflows.\nThis architecture has two useful implications:"}),"\n",(0,r.jsxs)(o.ol,{children:["\n",(0,r.jsxs)(o.li,{children:["Conductor is ",(0,r.jsx)(o.strong,{children:"secure"})," and ",(0,r.jsx)(o.strong,{children:"privacy-preserving"}),". It does not have access to your database, nor does it need direct access to your application servers. Instead, your servers open outbound websocket connections to it and communicate exclusively through its websocket protocol."]}),"\n",(0,r.jsxs)(o.li,{children:["Conductor is ",(0,r.jsx)(o.strong,{children:"out-of-band"}),". Conductor is ",(0,r.jsx)(o.strong,{children:"only"})," used for observability and recovery and is never in the critical path of workflow execution (unlike the external orchestrators of other workflow systems).\nIf your application's connection to Conductor is interrupted, it will continue to operate normally, and any failed workflows will automatically be recovered as soon as the connection is restored."]}),"\n"]}),"\n",(0,r.jsxs)(o.p,{children:["For more information on Conductor, see ",(0,r.jsx)(o.a,{href:"/production/self-hosting/conductor",children:"its docs"}),"."]}),"\n",(0,r.jsx)(o.h2,{id:"host-applications-on-dbos-cloud",children:"Host Applications on DBOS Cloud"}),"\n",(0,r.jsx)(o.p,{children:"You can deploy DBOS applications to DBOS Cloud.\nDBOS Cloud is a serverless platform for durably executed applications.\nIt provides:"}),"\n",(0,r.jsxs)(o.ul,{children:["\n",(0,r.jsxs)(o.li,{children:[(0,r.jsx)(o.a,{href:"/production/dbos-cloud/application-management",children:(0,r.jsx)(o.strong,{children:"Application hosting and autoscaling"})}),": Managed hosting of your application in the cloud, automatically scaling to millions of users. Applications are charged only for the CPU time they actually consume."]}),"\n",(0,r.jsxs)(o.li,{children:[(0,r.jsx)(o.a,{href:"/production/dbos-cloud/application-management",children:(0,r.jsx)(o.strong,{children:"Automatic workflow version management"})}),": DBOS Cloud seamlessly manages code version upgrades, launching new workflows on new code versions while completing old workflows on old code versions."]}),"\n",(0,r.jsxs)(o.li,{children:[(0,r.jsx)(o.a,{href:"/production/dbos-cloud/application-management",children:(0,r.jsx)(o.strong,{children:"Managed workflow recovery"})}),": If a cloud executor is interrupted, crashed, or restarted, each of its workflows is automatically recovered by another executor."]}),"\n",(0,r.jsxs)(o.li,{children:[(0,r.jsx)(o.a,{href:"/production/dbos-cloud/workflow-management",children:(0,r.jsx)(o.strong,{children:"Workflow and queue observability"})}),": Dashboards of all active and past workflows and all queued tasks, including their status, inputs, outputs, and steps."]}),"\n",(0,r.jsxs)(o.li,{children:[(0,r.jsx)(o.a,{href:"/production/dbos-cloud/workflow-management",children:(0,r.jsx)(o.strong,{children:"Workflow and queue management"})}),": From an online dashboard, cancel, resume, or restart any workflow execution and manage the tasks in your distributed queues."]}),"\n"]}),"\n",(0,r.jsxs)(o.p,{children:["See ",(0,r.jsx)(o.a,{href:"/production/dbos-cloud/deploying-to-cloud",children:(0,r.jsx)(o.strong,{children:"Deploying to DBOS Cloud"})})," to learn more."]})]})}function h(e={}){const{wrapper:o}={...(0,n.R)(),...e.components};return o?(0,r.jsx)(o,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},9452:(e,o,t)=>{t.d(o,{A:()=>s});const s=t.p+"assets/images/dbos-architecture-be89e880bc75334f1743bf8c256209cf.png"},5284:(e,o,t)=>{t.d(o,{A:()=>s});const s=t.p+"assets/images/dbos-conductor-architecture-052b057ba4714b1909a6dd3bc4a95f9e.png"},5717:(e,o,t)=>{t.d(o,{A:()=>s});const s=t.p+"assets/images/dbos-queues-3c55540c18343e0602412501556bbc40.png"},1436:(e,o,t)=>{t.d(o,{A:()=>s});const s=t.p+"assets/images/dbos-steps-e17ae35715cb4119eb29b231848fcbab.jpg"},7486:(e,o,t)=>{t.d(o,{A:()=>s});const s=t.p+"assets/images/dbos-system-database-50ad8da4dd1ed1c70e068ba4ddf16c63.png"},8427:(e,o,t)=>{t.d(o,{A:()=>s});const s=t.p+"assets/images/external-architecture-237de26c1b2114f287d50e733c29ceba.png"},8453:(e,o,t)=>{t.d(o,{R:()=>a,x:()=>i});var s=t(6540);const r={},n=s.createContext(r);function a(e){const o=s.useContext(n);return s.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function i(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(n.Provider,{value:o},e.children)}}}]);