"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[3719],{177:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>c,contentTitle:()=>i,default:()=>d,frontMatter:()=>t,metadata:()=>r,toc:()=>f});var o=n(4848),s=n(8453);const t={sidebar_position:30,title:"Integrating with Kafka",description:"Learn how to integrate DBOS and Kafka."},i="KafkaJS",r={id:"typescript/tutorials/requestsandevents/kafka-integration",title:"Integrating with Kafka",description:"Learn how to integrate DBOS and Kafka.",source:"@site/docs/typescript/tutorials/requestsandevents/kafka-integration.md",sourceDirName:"typescript/tutorials/requestsandevents",slug:"/typescript/tutorials/requestsandevents/kafka-integration",permalink:"/typescript/tutorials/requestsandevents/kafka-integration",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:30,frontMatter:{sidebar_position:30,title:"Integrating with Kafka",description:"Learn how to integrate DBOS and Kafka."},sidebar:"tutorialSidebar",previous:{title:"HTTP Serving",permalink:"/typescript/tutorials/requestsandevents/http-serving-tutorial"},next:{title:"Creating Custom Event Receivers",permalink:"/typescript/tutorials/requestsandevents/custom-event-receiver"}},c={},f=[{value:"KafkaJS Integration Decorators",id:"kafkajs-integration-decorators",level:2},{value:"<code>@Kafka(kafkaConfig: KafkaConfig)</code>",id:"kafka",level:3},{value:"<code>@KafkaConsume(topic: string | RegExp | Array&lt;string | RegExp&gt;, consumerConfig?: ConsumerConfig, queueName?: string)</code>",id:"kafka-consume",level:3},{value:"Concurrency and Rate Limiting",id:"concurrency-and-rate-limiting",level:4},{value:"Confluent Kafka Integration Decorators",id:"confluent-kafka-integration-decorators",level:2},{value:"<code>@CKafka(kafkaConfig: KafkaConfig)</code>",id:"ckafka",level:3},{value:"<code>@CKafkaConsume(topic: string | RegExp | Array&lt;string | RegExp&gt;, consumerConfig?: ConsumerConfig, queueName?: string)</code>",id:"ckafka-consume",level:3},{value:"Concurrency and Rate Limiting",id:"concurrency-and-rate-limiting-1",level:4}];function l(e){const a={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(a.p,{children:"In this guide, you'll learn how to use DBOS transactions and workflows to process Kafka messages with exactly-once semantics."}),"\n",(0,o.jsx)(a.p,{children:"As there is more than one Kafka client for the JavaScript ecosystem, DBOS supports pluggable libraries."}),"\n",(0,o.jsx)(a.header,{children:(0,o.jsx)(a.h1,{id:"kafkajs",children:"KafkaJS"})}),"\n",(0,o.jsxs)(a.p,{children:["First, install the DBOS library for ",(0,o.jsx)(a.a,{href:"https://kafka.js.org/",children:"KafkaJS"})," in your application:"]}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{children:"npm install @dbos-inc/dbos-kafkajs\n"})}),"\n",(0,o.jsx)(a.p,{children:"Then, define your transaction or workflow. It must take in the Kafka topic, partition, and message as inputs:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-javascript",children:"import { DBOS } from '@dbos-inc/dbos-sdk';\nimport { KafkaConfig, KafkaMessage} from \"kafkajs\";\n\nexport class KafkaExample{\n  @DBOS.workflow()\n  static async kafkaWorkflow(topic: string, partition: number, message: KafkaMessage) {\n    DBOS.logger.info(`Message received: ${message.value?.toString()}`)\n  }\n}\n"})}),"\n",(0,o.jsxs)(a.p,{children:["Then, annotate your method with a ",(0,o.jsx)(a.a,{href:"#kafka-consume",children:(0,o.jsx)(a.code,{children:"@KafkaConsume"})})," decorator specifying which topic to consume from.\nAdditionally, annotate your class with a ",(0,o.jsx)(a.a,{href:"#kafka",children:(0,o.jsx)(a.code,{children:"@Kafka"})})," decorator defining which brokers to connect to.\nDBOS invokes your method exactly-once for each message sent to the topic."]}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-javascript",children:'import { DBOS } from "@dbos-inc/dbos-sdk";\nimport { KafkaConfig, KafkaMessage} from "kafkajs";\nimport { Kafka, KafkaConsume } from "@dbos-inc/dbos-kafkajs";\n\nconst kafkaConfig: KafkaConfig = {\n    brokers: [\'localhost:9092\']\n}\n\n@Kafka(kafkaConfig)\nexport class KafkaExample{\n  @KafkaConsume("example-topic")\n  @DBOS.workflow()\n  static async kafkaWorkflow(topic: string, partition: number, message: KafkaMessage) {\n    DBOS.logger.info(`Message received: ${message.value?.toString()}`)\n  }\n}\n'})}),"\n",(0,o.jsxs)(a.p,{children:["If you need more control, you can pass detailed configurations to both the ",(0,o.jsx)(a.code,{children:"@Kafka"})," and ",(0,o.jsx)(a.code,{children:"@KafkaConsume"})," decorators.\nThe ",(0,o.jsx)(a.code,{children:"@Kafka"})," decorator takes in a ",(0,o.jsx)(a.a,{href:"https://kafka.js.org/docs/configuration",children:"KafkaJS configuration object"})," used to configure Kafka for all methods in its class.\nThe ",(0,o.jsx)(a.code,{children:"@KafkaConsume"})," decorator takes in a ",(0,o.jsx)(a.a,{href:"https://kafka.js.org/docs/consuming#options",children:"KafkaJS consumer configuration"})," as an optional second argument.\nFor example, you can specify a custom consumer group ID:"]}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-javascript",children:'@KafkaConsume("example-topic", { groupId: "custom-group-id" })\n@DBOS.workflow()\nstatic async kafkaWorkflow(topic: string, partition: number, message: KafkaMessage) {\n  DBOS.logger.info(`Message received: ${message.value?.toString()}`)\n}\n'})}),"\n",(0,o.jsxs)(a.p,{children:["Under the hood, DBOS constructs an ",(0,o.jsx)(a.a,{href:"../idempotency-tutorial",children:"idempotency key"})," for each Kafka message from its topic, partition, and offset and passes it into your workflow or transaction.\nThis combination is guaranteed to be unique for each Kafka cluster.\nThus, even if a message is delivered multiple times (e.g., due to transient network failures or application interruptions), your transaction or workflow processes it exactly once."]}),"\n",(0,o.jsx)(a.h2,{id:"kafkajs-integration-decorators",children:"KafkaJS Integration Decorators"}),"\n",(0,o.jsx)(a.h3,{id:"kafka",children:(0,o.jsx)(a.code,{children:"@Kafka(kafkaConfig: KafkaConfig)"})}),"\n",(0,o.jsxs)(a.p,{children:["Class-level decorator defining a Kafka configuration to use in all class methods.\nTakes in a ",(0,o.jsx)(a.a,{href:"https://kafka.js.org/docs/configuration",children:"KafkaJS configuration object"}),"."]}),"\n",(0,o.jsx)(a.h3,{id:"kafka-consume",children:(0,o.jsx)(a.code,{children:"@KafkaConsume(topic: string | RegExp | Array<string | RegExp>, consumerConfig?: ConsumerConfig, queueName?: string)"})}),"\n",(0,o.jsxs)(a.p,{children:["Runs a transaction or workflow exactly-once for each message received on the specified topic(s).\nTakes in a Kafka topic or list of Kafka topics (required) and a ",(0,o.jsx)(a.a,{href:"https://kafka.js.org/docs/consuming#options",children:"KafkaJS consumer configuration"})," (optional).\nRequires class to be decorated with ",(0,o.jsx)(a.a,{href:"#kafka",children:(0,o.jsx)(a.code,{children:"@Kafka"})}),".\nThe decorated method must take as input a Kafka topic, partition, and message as in the example below:"]}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-javascript",children:'import { DBOS } from "@dbos-inc/dbos-sdk";\nimport { KafkaConfig, KafkaMessage} from "kafkajs";\nimport { Kafka, KafkaConsume } from "@dbos-inc/dbos-kafkajs";\n\nconst kafkaConfig: KafkaConfig = {\n    brokers: [\'localhost:9092\']\n}\n\n@Kafka(kafkaConfig)\nclass KafkaExample{\n\n  @KafkaConsume("example-topic")\n  @DBOS.workflow()\n  static async kafkaWorkflow(topic: string, partition: number, message: KafkaMessage) {\n    // This workflow executes exactly once for each message sent to "example-topic".\n    // All methods annotated with Kafka decorators must take in the topic, partition, and message as inputs just like this method.\n  }\n}\n'})}),"\n",(0,o.jsx)(a.h4,{id:"concurrency-and-rate-limiting",children:"Concurrency and Rate Limiting"}),"\n",(0,o.jsxs)(a.p,{children:["By default, ",(0,o.jsx)(a.code,{children:"@KafkaConsume"})," workflows are started immediately upon receiving Kafka messages.  If ",(0,o.jsx)(a.code,{children:"queueName"})," is provided to the ",(0,o.jsx)(a.code,{children:"@KafkaConsume"})," decorator, then the workflows will be enqueued in a ",(0,o.jsx)(a.a,{href:"/typescript/tutorials/queue-tutorial",children:"workflow queue"})," and subject to rate limits."]}),"\n",(0,o.jsx)(a.h1,{id:"confluents-javascript-client-for-apache-kafka",children:"Confluent's JavaScript Client for Apache Kafka"}),"\n",(0,o.jsxs)(a.p,{children:["First, install the DBOS library for ",(0,o.jsx)(a.a,{href:"https://github.com/confluentinc/confluent-kafka-javascript",children:"Confluent's JavaScript Client for Apache Kafka"})," in your application:"]}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{children:"npm install @dbos-inc/dbos-confluent-kafka\n"})}),"\n",(0,o.jsx)(a.p,{children:"Then, define your transaction or workflow. It must take in the Kafka topic, partition, and message as inputs:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-javascript",children:"import { DBOS } from '@dbos-inc/dbos-sdk';\nimport { KafkaConfig, Message } from \"@dbos-inc/dbos-confluent-kafka\";\n\nexport class CKafkaExample{\n  @DBOS.workflow()\n  static async kafkaWorkflow(topic: string, partition: number, message: Message) {\n    DBOS.logger.info(`Message received: ${message.value?.toString()}`)\n  }\n}\n"})}),"\n",(0,o.jsxs)(a.p,{children:["Then, annotate your method with a ",(0,o.jsx)(a.a,{href:"#ckafka-consume",children:(0,o.jsx)(a.code,{children:"@CKafkaConsume"})})," decorator specifying which topic to consume from.\nAdditionally, annotate your class with a ",(0,o.jsx)(a.a,{href:"#ckafka",children:(0,o.jsx)(a.code,{children:"@CKafka"})})," decorator defining which brokers to connect to.\nDBOS invokes your method exactly-once for each message sent to the topic."]}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-javascript",children:'import { DBOS } from "@dbos-inc/dbos-sdk";\nimport { KafkaConfig, Message, CKafka, CKafkaConsume } from "@dbos-inc/dbos-confluent-kafka";\n\nconst kafkaConfig: KafkaConfig = {\n    brokers: [\'localhost:9092\']\n}\n\n@CKafka(kafkaConfig)\nexport class CKafkaExample{\n  @CKafkaConsume("example-topic")\n  @DBOS.workflow()\n  static async kafkaWorkflow(topic: string, partition: number, message: Message) {\n    DBOS.logger.info(`Message received: ${message.value?.toString()}`)\n  }\n}\n'})}),"\n",(0,o.jsxs)(a.p,{children:["If you need more control, you can pass detailed configurations to both the ",(0,o.jsx)(a.code,{children:"@CKafka"})," and ",(0,o.jsx)(a.code,{children:"@CKafkaConsume"})," decorators.\nThe ",(0,o.jsx)(a.code,{children:"@CKafka"})," and ",(0,o.jsx)(a.code,{children:"@CKafkaConsume"})," decorators take in a ",(0,o.jsx)(a.a,{href:"https://github.com/confluentinc/librdkafka/blob/v2.6.1/CONFIGURATION.md",children:"configuration object"})," used to configure Kafka for all methods in its class.  You can also use ",(0,o.jsx)(a.a,{href:"https://github.com/confluentinc/confluent-kafka-javascript/blob/master/MIGRATION.md#kafkajs",children:"KafkaJS-like configuration options"}),"."]}),"\n",(0,o.jsx)(a.p,{children:"For example, you can specify a custom consumer group ID:"}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-javascript",children:'@CKafkaConsume("example-topic", { groupId: "custom-group-id" })\n@DBOS.workflow()\nstatic async kafkaWorkflow(topic: string, partition: number, message: Message) {\n  DBOS.logger.info(`Message received: ${message.value?.toString()}`)\n}\n'})}),"\n",(0,o.jsxs)(a.p,{children:["Under the hood, DBOS constructs an ",(0,o.jsx)(a.a,{href:"../idempotency-tutorial",children:"idempotency key"})," for each Kafka message from its topic, partition, and offset and passes it into your workflow or transaction.\nThis combination is guaranteed to be unique for each Kafka cluster.\nThus, even if a message is delivered multiple times (e.g., due to transient network failures or application interruptions), your transaction or workflow processes it exactly once."]}),"\n",(0,o.jsx)(a.h2,{id:"confluent-kafka-integration-decorators",children:"Confluent Kafka Integration Decorators"}),"\n",(0,o.jsx)(a.h3,{id:"ckafka",children:(0,o.jsx)(a.code,{children:"@CKafka(kafkaConfig: KafkaConfig)"})}),"\n",(0,o.jsxs)(a.p,{children:["Class-level decorator defining a Kafka configuration to use in all class methods.\nTakes in a ",(0,o.jsx)(a.a,{href:"https://kafka.js.org/docs/configuration",children:"KafkaJS configuration object"})," or ",(0,o.jsx)(a.a,{href:"https://github.com/confluentinc/librdkafka/blob/v2.6.1/CONFIGURATION.md",children:"rdkafka configuration object"}),"."]}),"\n",(0,o.jsx)(a.h3,{id:"ckafka-consume",children:(0,o.jsx)(a.code,{children:"@CKafkaConsume(topic: string | RegExp | Array<string | RegExp>, consumerConfig?: ConsumerConfig, queueName?: string)"})}),"\n",(0,o.jsxs)(a.p,{children:["Runs a transaction or workflow exactly-once for each message received on the specified topic(s).\nTakes in a Kafka topic or list of Kafka topics (required) and a consumer configuration.\nRequires class to be decorated with ",(0,o.jsx)(a.a,{href:"#ckafka",children:(0,o.jsx)(a.code,{children:"@CKafka"})}),".\nThe decorated method must take as input a Kafka topic, partition, and message as in the example below:"]}),"\n",(0,o.jsx)(a.pre,{children:(0,o.jsx)(a.code,{className:"language-javascript",children:'import { DBOS } from "@dbos-inc/dbos-sdk";\nimport { KafkaConfig, Message, CKafka, CKafkaConsume } from "@dbos-inc/dbos-confluent-kafka";\n\nconst kafkaConfig: KafkaConfig = {\n    brokers: [\'localhost:9092\']\n}\n\n@CKafka(kafkaConfig)\nclass CKafkaExample{\n  @CKafkaConsume("example-topic")\n  @DBOS.workflow()\n  static async kafkaWorkflow(topic: string, partition: number, message: KafkaMessage) {\n    // This workflow executes exactly once for each message sent to "example-topic".\n    // All methods annotated with CKafka decorators must take in the topic, partition, and message as inputs just like this method.\n  }\n}\n'})}),"\n",(0,o.jsx)(a.h4,{id:"concurrency-and-rate-limiting-1",children:"Concurrency and Rate Limiting"}),"\n",(0,o.jsxs)(a.p,{children:["By default, ",(0,o.jsx)(a.code,{children:"@CKafkaConsume"})," workflows are started immediately upon receiving Kafka messages.  If ",(0,o.jsx)(a.code,{children:"queueName"})," is provided to the ",(0,o.jsx)(a.code,{children:"@CKafkaConsume"})," decorator, then the workflows will be enqueued in a ",(0,o.jsx)(a.a,{href:"/typescript/tutorials/queue-tutorial",children:"workflow queue"})," and subject to rate limits."]})]})}function d(e={}){const{wrapper:a}={...(0,s.R)(),...e.components};return a?(0,o.jsx)(a,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,a,n)=>{n.d(a,{R:()=>i,x:()=>r});var o=n(6540);const s={},t=o.createContext(s);function i(e){const a=o.useContext(t);return o.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function r(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(t.Provider,{value:a},e.children)}}}]);