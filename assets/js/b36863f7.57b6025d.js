"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[228],{6112:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>l});var n=a(4848),o=a(8453);const s={sidebar_position:17,title:"Integrating with Kafka",description:"Learn how to integrate DBOS and Kafka."},r=void 0,i={id:"typescript/tutorials/kafka-integration",title:"Integrating with Kafka",description:"Learn how to integrate DBOS and Kafka.",source:"@site/docs/typescript/tutorials/kafka-integration.md",sourceDirName:"typescript/tutorials",slug:"/typescript/tutorials/kafka-integration",permalink:"/typescript/tutorials/kafka-integration",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:17,frontMatter:{sidebar_position:17,title:"Integrating with Kafka",description:"Learn how to integrate DBOS and Kafka."},sidebar:"tutorialSidebar",previous:{title:"Using Libraries",permalink:"/typescript/tutorials/using-libraries"},next:{title:"Scheduled Workflows",permalink:"/typescript/tutorials/scheduled-workflows"}},c={},l=[];function f(e){const t={a:"a",code:"code",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.p,{children:"In this guide, you'll learn how to use DBOS transactions and workflows to process Kafka messages with exactly-once semantics."}),"\n",(0,n.jsxs)(t.p,{children:["First, install ",(0,n.jsx)(t.a,{href:"https://kafka.js.org/",children:"KafkaJS"})," in your application:"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"npm install kafkajs\n"})}),"\n",(0,n.jsx)(t.p,{children:"Then, define your transaction or workflow. It must take in the Kafka topic, partition, and message as inputs:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-javascript",children:"import { Workflow, WorkflowContext } from '@dbos-inc/dbos-sdk';\n\nexport class KafkaExample{\n  @Workflow()\n  static async kafkaWorkflow(ctxt: WorkflowContext, topic: string, partition: number, message: KafkaMessage) {\n    ctxt.logger.info(`Message received: ${message.value?.toString()}`)\n  }\n}\n"})}),"\n",(0,n.jsxs)(t.p,{children:["Then, annotate your method with a ",(0,n.jsx)(t.a,{href:"/typescript/reference/decorators#kafka-consume",children:(0,n.jsx)(t.code,{children:"@KafkaConsume"})})," decorator specifying which topic to consume from.\nAdditionally, annotate your class with a ",(0,n.jsx)(t.a,{href:"/typescript/reference/decorators#kafka",children:(0,n.jsx)(t.code,{children:"@Kafka"})})," decorator defining which brokers to connect to.\nDBOS invokes your method exactly-once for each message sent to the topic."]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-javascript",children:"import { KafkaConfig, KafkaMessage} from \"kafkajs\";\nimport { Workflow, WorkflowContext, Kafka, KafkaConsume } from '@dbos-inc/dbos-sdk';\n\nconst kafkaConfig: KafkaConfig = {\n    brokers: ['localhost:9092']\n}\n\n@Kafka(kafkaConfig)\nexport class KafkaExample{\n\n  @KafkaConsume(\"example-topic\")\n  @Workflow()\n  static async kafkaWorkflow(ctxt: WorkflowContext, topic: string, partition: number, message: KafkaMessage) {\n    ctxt.logger.info(`Message received: ${message.value?.toString()}`)\n  }\n}\n"})}),"\n",(0,n.jsxs)(t.p,{children:["If you need more control, you can pass detailed configurations to both the ",(0,n.jsx)(t.code,{children:"@Kafka"})," and ",(0,n.jsx)(t.code,{children:"@KafkaConsume"})," decorators.\nThe ",(0,n.jsx)(t.code,{children:"@Kafka"})," decorator takes in a ",(0,n.jsx)(t.a,{href:"https://kafka.js.org/docs/configuration",children:"KafkaJS configuration object"})," used to configure Kafka for all methods in its class.\nThe ",(0,n.jsx)(t.code,{children:"@KafkaConsume"})," decorator takes in a ",(0,n.jsx)(t.a,{href:"https://kafka.js.org/docs/consuming#options",children:"KafkaJS consumer configuration"})," as an optional second argument.\nFor example, you can specify a custom consumer group ID:"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-javascript",children:'@KafkaConsume("example-topic", { groupId: "custom-group-id" })\n@Workflow()\nstatic async kafkaWorkflow(ctxt: WorkflowContext, topic: string, partition: number, message: KafkaMessage) {\n  ctxt.logger.info(`Message received: ${message.value?.toString()}`)\n}\n'})}),"\n",(0,n.jsxs)(t.p,{children:["Under the hood, DBOS constructs an ",(0,n.jsx)(t.a,{href:"./idempotency-tutorial",children:"idempotency key"})," for each Kafka message from its topic, partition, and offset and passes it into your workflow or transaction.\nThis combination is guaranteed to be unique for each Kafka cluster.\nThus, even if a message is delivered multiple times (e.g., due to transient network failures or application interruptions), your transaction or workflow processes it exactly once."]})]})}function d(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(f,{...e})}):f(e)}},8453:(e,t,a)=>{a.d(t,{R:()=>r,x:()=>i});var n=a(6540);const o={},s=n.createContext(o);function r(e){const t=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),n.createElement(s.Provider,{value:t},e.children)}}}]);