"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[4492],{8632:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>r,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"python/prompting","title":"AI Model Prompting","description":"You may want assistance from an AI model in building a DBOS application.","source":"@site/docs/python/prompting.md","sourceDirName":"python","slug":"/python/prompting","permalink":"/python/prompting","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":30,"frontMatter":{"sidebar_position":30,"title":"AI Model Prompting"},"sidebar":"tutorialSidebar","previous":{"title":"Add DBOS To Your App","permalink":"/python/integrating-dbos"},"next":{"title":"Workflows","permalink":"/python/tutorials/workflow-tutorial"}}');var s=t(4848),a=t(8453);const r={sidebar_position:30,title:"AI Model Prompting"},i=void 0,l={},c=[{value:"How To Use",id:"how-to-use",level:2},{value:"Prompt",id:"prompt",level:2}];function u(e){const n={a:"a",code:"code",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"You may want assistance from an AI model in building a DBOS application.\nTo make sure your model has the latest information on how to use DBOS, provide it with this prompt."}),"\n",(0,s.jsx)(n.h2,{id:"how-to-use",children:"How To Use"}),"\n",(0,s.jsx)(n.p,{children:"First, use the click-to-copy button in the top right of the code block to copy the full prompt to your clipboard.\nThen, paste into your AI tool of choice (for example OpenAI's ChatGPT or Anthropic's Claude).\nThis adds the prompt to your AI model's context, giving it up-to-date instructions on how to build an application with DBOS."}),"\n",(0,s.jsx)(n.p,{children:"If you are using an AI-powered IDE, you can add this prompt to your project's context.\nFor example:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Cursor: Add the prompt to ",(0,s.jsx)(n.a,{href:"https://docs.cursor.com/context/rules-for-ai",children:"your project rules"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Zed: Copy the prompt to a file in your project, then use the ",(0,s.jsx)(n.a,{href:"https://zed.dev/docs/assistant/commands?highlight=%2Ffile#file",children:(0,s.jsx)(n.code,{children:"/file"})})," command to add the file to your context."]}),"\n",(0,s.jsxs)(n.li,{children:["Windsurf: Copy the prompt to a file in your project, then use ",(0,s.jsx)(n.a,{href:"https://docs.windsurf.com/chat/overview",children:(0,s.jsx)(n.code,{children:"@-Mention"})})," to add the file to your context."]}),"\n",(0,s.jsxs)(n.li,{children:["GitHub Copilot: Create a ",(0,s.jsx)(n.a,{href:"https://docs.github.com/en/copilot/customizing-copilot/adding-repository-custom-instructions-for-github-copilot",children:(0,s.jsx)(n.code,{children:".github/copilot-instructions.md"})})," file in your repository and add the prompt to it."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"prompt",children:"Prompt"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-markdown",children:'# Build Reliable Applications With DBOS\n\n## Guidelines\n\n- Respond in a friendly and concise manner\n- Ask clarifying questions when requirements are ambiguous\n- Generate code in Python using the DBOS library\n- You MUST import all methods and classes used in the code you generate\n- You SHALL keep all code in a single file unless otherwise specified.\n- DBOS does NOT stand for anything.\n\n## Workflow Guidelines\n\nWorkflows provide durable execution so you can write programs that are resilient to any failure.\nWorkflows are comprised of steps, which are ordinary Python functions annotated with @DBOS.step().\nWhen using DBOS workflows, you should annotate any function that performs complex operations or accesses external APIs or services as a step. \nYou can turn any Python function into a step by annotating it with the @DBOS.step decorator. The only requirement is that its inputs and outputs should be serializable.\n\nIf a workflow is interrupted for any reason (e.g., an executor restarts or crashes), when your program restarts the workflow automatically resumes execution from the last completed step.\n\n- If asked to add DBOS to existing code, you MUST ask which function to make a workflow. Do NOT recommend any changes until they have told you what function to make a workflow. Do NOT make a function a workflow unless SPECIFICALLY requested.\n- When making a function a workflow, you should make all functions it calls steps. Do NOT change the functions in any way except by adding the @Step annotation.\n- Do NOT make functions steps unless they are DIRECTLY called by a workflow.\n- If the workflow function performs a non-deterministic action, you MUST move that action to its own function and make that function a step. Examples of non-deterministic actions include accessing an external API or service, accessing files on disk, generating a random number, of getting the current time.\n- Do NOT use threads to start workflows or to start steps in workflows. You should instead use DBOS.start_workflow and DBOS queues.\n- DBOS workflows and steps should NOT have side effects in memory outside of their own scope. They can access global variables, but they should NOT create or update global variables or variables outside their scope.\n- Do NOT call any DBOS context method (DBOS.send, DBOS.recv, DBOS.start_workflow, DBOS.sleep, DBOS.set_event, DBOS.get_event) from a step.\n- Do NOT start workflows from inside a step.\n- Do NOT call DBOS.set_event and DBOS.recv from outside a workflow.\n\n## DBOS Lifecycle Guidelines\n\nAny DBOS program MUST configure the DBOS constructor at the top and MUST call DBOS.launch() in its main function.\nDBOS must always be configured like so, unless otherwise specified:\n\n```python\nimport os\nfrom dbos import DBOS, DBOSConfig\n\nconfig: DBOSConfig = {\n    "name": "my-app",\n    "database_url": os.environ.get("DBOS_DATABASE_URL"),\n}\nDBOS(config=config)\n```\n\nAnd DBOS.launch() should always be called in the main function like so:\n\n```python\nif __name__ == "__main__":\n    DBOS.launch()\n```\n\nIn a FastAPI application, the server should ALWAYS be started explicitly after a DBOS.launch in the main function:\n\n```python\nif __name__ == "__main__":\n    DBOS.launch()\n    uvicorn.run(app, host="0.0.0.0", port=8000)\n```\n\nIf an app contains scheduled workflows and NOTHING ELSE (no HTTP server), then the main thread should block forever while the scheduled workflows run like this:\n\n```python\nif __name__ == "__main__":\n    DBOS.launch()\n    threading.Event().wait()\n```\n\n## Workflow and Steps Examples\n\nSimple example:\n\n\n```python\nimport os\nfrom dbos import DBOS, DBOSConfig\n\nconfig: DBOSConfig = {\n    "name": "dbos-starter",\n    "database_url": os.environ.get("DBOS_DATABASE_URL"),\n}\nDBOS(config=config)\n\n@DBOS.step()\ndef step_one():\n    print("Step one completed!")\n\n@DBOS.step()\ndef step_two():\n    print("Step two completed!")\n\n@DBOS.workflow()\ndef dbos_workflow():\n    step_one()\n    step_two()\n\nif __name__ == "__main__":\n    DBOS.launch()\n    dbos_workflow()\n```\n\nExample with FastAPI:\n\n```python\nimport os\n\nfrom dbos import DBOS, DBOSConfig\nfrom fastapi import FastAPI\n\napp = FastAPI()\nconfig: DBOSConfig = {\n    "name": "dbos-starter",\n    "database_url": os.environ.get("DBOS_DATABASE_URL"),\n}\nDBOS(config=config, fastapi=app)\n\n@DBOS.step()\ndef step_one():\n    print("Step one completed!")\n\n@DBOS.step()\ndef step_two():\n    print("Step two completed!")\n\n@app.get("/")\n@DBOS.workflow()\ndef dbos_workflow():\n    step_one()\n    step_two()\n\nif __name__ == "__main__":\n    DBOS.launch()\n    uvicorn.run(app, host="0.0.0.0", port=8000)\n```\n\nExample with queues:\n\n```python\nimport os\nimport time\n\nfrom dbos import DBOS, DBOSConfig, Queue\nfrom fastapi import FastAPI\n\napp = FastAPI()\nconfig: DBOSConfig = {\n    "name": "dbos-starter",\n    "database_url": os.environ.get("DBOS_DATABASE_URL"),\n}\nDBOS(config=config, fastapi=app)\n\nqueue = Queue("example-queue")\n\n@DBOS.step()\ndef dbos_step(n: int):\n    time.sleep(5)\n    print(f"Step {n} completed!")\n\n@app.get("/")\n@DBOS.workflow()\ndef dbos_workflow():\n    print("Enqueueing steps")\n    handles = []\n    for i in range(10):\n        handle = queue.enqueue(dbos_step, i)\n        handles.append(handle)\n    results = [handle.get_result() for handle in handles]\n    print(f"Successfully completed {len(results)} steps")\n```\n\n#### Scheduled Workflow\n\nYou can schedule DBOS workflows to run exactly once per time interval. To do this, annotate the workflow with the @DBOS.scheduled decorator and specify the schedule in crontab syntax. For example:\n\n```python\n@DBOS.scheduled("* * * * *")\n@DBOS.workflow()\ndef run_every_minute(scheduled_time, actual_time):\n    print(f"I am a scheduled workflow. It is currently {scheduled_time}.")\n```\n\n- A scheduled workflow MUST specify a crontab schedule.\n- It MUST take in two arguments, scheduled and actual time. Both are datetime.datetimes of when the workflow started.\n\n\n## Workflow Documentation:\n\nIf an exception is thrown from a workflow, the workflow TERMINATES.\nDBOS records the exception, sets the workflow status to `ERROR`, and does not recover the workflow.\n\n## Workflow IDs\n\nEvery time you execute a workflow, that execution is assigned a unique ID, by default a UUID.\nYou can access this ID through the `DBOS.workflow_id` context variable.\n\nSet the workflow ID of a workflow with SetWorkflowID.\nIf a workflow is called multiple times with the same ID, it executes ONLY ONCE.\n\n```python\n@DBOS.workflow()\ndef example_workflow():\n    DBOS.logger.info(f"I am a workflow with ID {DBOS.workflow_id}")\n\nworkflow_id = "my-workflow-id"\n\nwith SetWorkflowID(workflow_id):\n    example_workflow()\n```\n\n## Starting in the Background\n\nYou can use DBOS.start_workflow to start a workflow in the background without waiting for it to complete.\nThis is useful for long-running or interactive workflows.\n\n`start_workflow` returns a workflow handle, from which you can access information about the workflow or wait for it to complete and retrieve its result.\nThe `start_workflow` method resolves after the handle is durably created; at this point the workflow is guaranteed to run to completion even if the app is interrupted.\n\nNEVER start a workflow from inside a step.\n\nHere\'s an example:\n\n```python\n@DBOS.workflow()\ndef example_workflow(var1: str, var2: str):\n    DBOS.sleep(10) # Sleep for 10 seconds\n    return var1 + var2\n\n# Start example_workflow in the background\nhandle: WorkflowHandle = DBOS.start_workflow(example_workflow, "var1", "var2")\n# Wait for the workflow to complete and retrieve its result.\nresult = handle.get_result()\n```\n\nYou can also use DBOS.retrieve_workflow to retrieve a workflow\'s handle from its ID.\n\n## Workflow Events\n\nWorkflows can emit _events_, which are key-value pairs associated with the workflow\'s ID.\nThey are useful for publishing information about the state of an active workflow, for example to transmit information to the workflow\'s caller.\n\n#### set_event\n\nAny workflow can call `DBOS.set_event` to publish a key-value pair, or update its value if has already been published.\nONLY call this from a workflow function, NEVER from a step.\n\n```python\nDBOS.set_event(\n    key: str,\n    value: Any,\n) -> None\n```\n#### get_event\n\nYou can call `DBOS.get_event` to retrieve the value published by a particular workflow identity for a particular key.\nIf the event does not yet exist, this call waits for it to be published, returning `None` if the wait times out.\nNEVER call this from inside a step.\n\n```python\nDBOS.get_event(\n    workflow_id: str,\n    key: str,\n    timeout_seconds: float = 60,\n) -> None\n```\n\n#### Events Example\n\nEvents are especially useful for writing interactive workflows that communicate information to their caller.\nFor example, in one demo, the checkout workflow, after validating an order, needs to send the customer a unique payment ID.\nTo communicate the payment ID to the customer, it uses events.\n\nThe payments workflow emits the payment ID using `set_event()`:\n\n```python\n@DBOS.workflow()\ndef checkout_workflow():\n    ...\n    payment_id = ...\n    dbos.set_event(PAYMENT_ID, payment_id)\n    ...\n```\n\nThe FastAPI handler that originally started the workflow uses `get_event()` to await this payment ID, then returns it:\n\n```python\n@app.post("/checkout/{idempotency_key}")\ndef checkout_endpoint(idempotency_key: str) -> Response:\n    # Idempotently start the checkout workflow in the background.\n    with SetWorkflowID(idempotency_key):\n        handle = DBOS.start_workflow(checkout_workflow)\n    # Wait for the checkout workflow to send a payment ID, then return it.\n    payment_id = DBOS.get_event(handle.workflow_id, PAYMENT_ID)\n    if payment_id is None:\n        raise HTTPException(status_code=404, detail="Checkout failed to start")\n    return Response(payment_id)\n```\n\n## Workflow Messaging and Notifications\nYou can send messages to a specific workflow ID.\nThis is useful for sending notifications to an active workflow.\n\n#### Send\n\nYou can call `DBOS.send()` to send a message to a workflow.\nMessages can optionally be associated with a topic and are queued on the receiver per topic.\nNEVER call this from a step.\n\n```python\nDBOS.send(\n    destination_id: str,\n    message: Any,\n    topic: Optional[str] = None\n) -> None\n```\n\n#### Recv\n\nWorkflows can call `DBOS.recv()` to receive messages sent to them, optionally for a particular topic.\nEach call to `recv()` waits for and consumes the next message to arrive in the queue for the specified topic, returning `None` if the wait times out.\nIf the topic is not specified, this method only receives messages sent without a topic.\nONLY call this from inside a workflow function, NEVER from a step.\n\n```python\nDBOS.recv(\n    topic: Optional[str] = None,\n    timeout_seconds: float = 60,\n) -> Any\n```\n\n#### Messages Example\n\nMessages are especially useful for sending notifications to a workflow.\nFor example, in one demo, the checkout workflow, after redirecting customers to a payments page, must wait for a notification that the user has paid.\n\nTo wait for this notification, the payments workflow uses `recv()`, executing failure-handling code if the notification doesn\'t arrive in time:\n\n```python\n@DBOS.workflow()\ndef checkout_workflow():\n  ... # Validate the order, then redirect customers to a payments service.\n  payment_status = DBOS.recv(PAYMENT_STATUS)\n  if payment_status is not None and payment_status == "paid":\n      ... # Handle a successful payment.\n  else:\n      ... # Handle a failed payment or timeout.\n```\n\nAn endpoint waits for the payment processor to send the notification, then uses `send()` to forward it to the workflow:\n\n```python\n@app.post("/payment_webhook/{workflow_id}/{payment_status}")\ndef payment_endpoint(payment_id: str, payment_status: str) -> Response:\n    # Send the payment status to the checkout workflow.\n    DBOS.send(payment_id, payment_status, PAYMENT_STATUS)\n```\n\n### sleep\n\n```python\nDBOS.sleep(\n    seconds: float\n) -> None\n```\n\nSleep for the given number of seconds.\nMay only be called from within a workflow.\nThis sleep is durable&mdash;it records its intended wake-up time in the database so if it is interrupted and recovers, it still wakes up at the intended time.\n\n## Coroutine (Async) Workflows\n\n- Coroutinues (functions defined with `async def`, also known as async functions) can also be DBOS workflows.\n- If provided with async code, you MUST use coroutine workflows and steps\n- Coroutine workflows may invoke and await on coroutine steps\n- You MUST use start_workflow_async and enqueue_async to start or enqueue coroutine workflows.\n-  You MUST use the async versions of the event and messaging context methods for coroutines (get_event_async, send_async, etc.). They have the same API but are async.\n\n\n```python\n@DBOS.step()\nasync def example_step():\n    async with aiohttp.ClientSession() as session:\n        async with session.get("https://example.com") as response:\n            return await response.text()\n\n@DBOS.workflow()\nasync def example_workflow(friend: str):\n    await DBOS.sleep_async(10)\n    body = await example_step()\n    result = await asyncio.to_thread(example_transaction, body)\n    return result\n```\n\n### Configurable Retries\n\nYou can optionally configure a step to automatically retry any exception a set number of times with exponential backoff.\nThis is useful for automatically handling transient failures, like making requests to unreliable APIs.\nRetries are configurable through arguments to the step decorator:\n\n```python\nDBOS.step(\n    retries_allowed: bool = False,\n    interval_seconds: float = 1.0,\n    max_attempts: int = 3,\n    backoff_rate: float = 2.0\n)\n```\n\nFor example, we configure this step to retry exceptions (such as if `example.com` is temporarily down) up to 10 times:\n\n```python\n@DBOS.step(retries_allowed=True, max_attempts=10)\ndef example_step():\n    return requests.get("https://example.com").text\n```\n\n### DBOS Queues\n\n\nQueues allow you to run functions with managed concurrency.\nThey are useful for controlling the number of functions run in parallel, or the rate at which functions are started.\n\nTo create a queue, specify its name:\n\n```python\nfrom dbos import Queue\n\nqueue = Queue("example_queue")\n```\n\nYou can then enqueue any DBOS workflow, step, or transaction.\nEnqueuing a function submits it for execution and returns a handle to it.\nQueued tasks are started in first-in, first-out (FIFO) order.\n\n```python\nqueue = Queue("example_queue")\n\n@DBOS.step()\ndef process_task(task):\n  ...\n\ntask = ...\nhandle = queue.enqueue(process_task, task)\n```\n\n### Queue Example\n\nHere\'s an example of a workflow using a queue to process tasks concurrently:\n\n```python\nfrom dbos import DBOS, Queue\n\nqueue = Queue("example_queue")\n\n@DBOS.step()\ndef process_task(task):\n  ...\n\n@DBOS.workflow()\ndef process_tasks(tasks):\n  task_handles = []\n  # Enqueue each task so all tasks are processed concurrently.\n  for task in tasks:\n    handle = queue.enqueue(process_task, task)\n    task_handles.append(handle)\n  # Wait for each task to complete and retrieve its result.\n  # Return the results of all tasks.\n  return [handle.get_result() for handle in task_handles]\n```\n\n### Managing Concurrency\n\nYou can specify the _concurrency_ of a queue, the maximum number of functions from this queue that may run concurrently, at two scopes: global and per process.\nGlobal concurrency limits are applied across all DBOS processes using this queue.\nPer process concurrency limits are applied to each DBOS process using this queue.\nIf no limit is provided, any number of functions may run concurrently.\nFor example, this queue has a maximum global concurrency of 10 and a per process maximum concurrency of 5, so at most 10 functions submitted to it may run at once, up to 5 per process:\n\n```python\nfrom dbos import Queue\n\nqueue = Queue("example_queue", concurrency=10, worker_concurrency=5)\n```\n\nYou may want to specify a maximum concurrency if functions in your queue submit work to an external process with limited resources.\nThe concurrency limit guarantees that even if many functions are submitted at once, they won\'t overwhelm the process.\n\n### Rate Limiting\n\nYou can set _rate limits_ for a queue, limiting the number of functions that it can start in a given period.\nRate limits are global across all DBOS processes using this queue.\nFor example, this queue has a limit of 50 with a period of 30 seconds, so it may not start more than 50 functions in 30 seconds:\n\n```python\nqueue = Queue("example_queue", limiter={"limit": 50, "period": 30})\n```\n\nRate limits are especially useful when working with a rate-limited API, such as many LLM APIs.\n\n### In-Order Processing\n\nYou can use a queue with `concurrency=1` to guarantee sequential, in-order processing of events.\nOnly a single event will be processed at a time.\nFor example, this app processes events sequentially in the order of their arrival:\n\n ```python\nfrom fastapi import FastAPI\nfrom dbos import DBOS, Queue\n\napp = FastAPI()\nDBOS(fastapi=app)\n\nqueue = Queue("in_order_queue", concurrency=1)\n\n@DBOS.step()\ndef process_event(event: str):\n    ...\n\n@app.post("/events/{event}")\ndef event_endpoint(event: str):\n    queue.enqueue(process_event, event)\n ```\n\n## Python Classes\n\n You can add DBOS workflow and step decorators to your Python class instance methods.\nTo add DBOS decorators to your methods, their class MUST inherit from `DBOSConfiguredInstance` and must be decorated with `@DBOS.dbos_class`.\nFor example:\n\n```python\n@DBOS.dbos_class()\nclass URLFetcher(DBOSConfiguredInstance):\n    def __init__(self, url: str):\n        self.url = url\n        super().__init__(config_name=url)\n\n    @DBOS.workflow()\n    def fetch_workflow(self):\n        return self.fetch_url()\n\n    @DBOS.step()\n    def fetch_url(self):\n        return requests.get(self.url).text\n    \nexample_fetcher = URLFetcher("https://example.com")\nprint(example_fetcher.fetch_workflow())\n```\n\nWhen you create a new instance of a DBOS-decorated class,  `DBOSConfiguredInstance` must be instantiated with a `config_name`.\nThis `config_name` should be a unique identifier of the instance.\nAdditionally, all DBOS-decorated classes must be instantiated before `DBOS.launch()` is called.\n\n\n### Testing DBOS Functions\n\nUnless otherwise specified, recommend testing DBOS applications with pytest.\n\nYou MUST use this fixture to reset DBOS between tests:\n\n```python\n@pytest.fixture()\ndef reset_dbos():\n    DBOS.destroy()\n    config: DBOSConfig = {\n        "name": "my-app",\n        "database_url": os.environ.get("TESTING_DATABASE_URL"),\n    }\n    DBOS(config=config)\n    DBOS.reset_system_database()\n    DBOS.launch()\n```\n\n## Workflow Handle\n\nDBOS.start_workflow, DBOS.retrieve_workflow, and enqueue return workflow handles.\n\n#### get_workflow_id\n\n```python\nhandle.get_workflow_id() -> str\n```\n\nRetrieve the ID of the workflow.\n\n#### get_result\n\n```python\nhandle.get_result() -> R\n```\n\nWait for the workflow to complete, then return its result.\n\n#### get_status\n\n```python\nhandle.get_status() -> WorkflowStatus\n```\n\nRetrieve the workflow status:\n\n```python\nclass WorkflowStatus:\n    workflow_id: str # The workflow\'s ID\n    status: str # The workflow\'s current state. One of PENDING, SUCCESS, ERROR, RETRIES_EXCEEDED, or CANCELLED\n    name: str # The fully qualified name of the workflow function\n    class_name: Optional[str] # If the workflow function is a class method, the name of the class\n    config_name: Optional[str] # If the workflow function is a method of a configured class, the name of the class configuration\n```\n\n### Transactions\n\nTransactions are a special type of step that are optimized for database accesses.\nThey execute as a single database transaction.\n\nONLY use transactions if you are SPECIFICALLY requested to perform database operations, DO NOT USE THEM OTHERWISE.\n\nIf asked to add DBOS to code that already contains database operations, ALWAYS make it a step, do NOT attempt to make it a transaction unless requested.\n\nONLY use transactions with a Postgres database.\nTo access any other database, ALWAYS use steps.\n\nTo make a Python function a transaction, annotate it with the DBOS.transaction decorator.\nThen, access the database using the DBOS.sql_session client, which is a SQLAlchemy client DBOS automatically connects to your database.\nHere are some examples:\n\n\n#### SQLAlchemy\n\n```python\ngreetings = Table(\n    "greetings", \n    MetaData(), \n    Column("name", String), \n    Column("note", String)\n)\n\n@DBOS.transaction()\ndef example_insert(name: str, note: str) -> None:\n    # Insert a new greeting into the database\n    DBOS.sql_session.execute(greetings.insert().values(name=name, note=note))\n\n@DBOS.transaction()\ndef example_select(name: str) -> Optional[str]:\n    # Select the first greeting to a particular name\n    row = DBOS.sql_session.execute(\n        select(greetings.c.note).where(greetings.c.name == name)\n    ).first()\n    return row[0] if row else None\n```\n\n#### Raw SQL\n\n```python\n@DBOS.transaction()\ndef example_insert(name: str, note: str) -> None:\n    # Insert a new greeting into the database\n    sql = text("INSERT INTO greetings (name, note) VALUES (:name, :note)")\n    DBOS.sql_session.execute(sql, {"name": name, "note": note})\n\n\n@DBOS.transaction()\ndef example_select(name: str) -> Optional[str]:\n    # Select the first greeting to a particular name\n    sql = text("SELECT note FROM greetings WHERE name = :name LIMIT 1")\n    row = DBOS.sql_session.execute(sql, {"name": name}).first()\n    return row[0] if row else None\n```\n\n#### With FastAPI\n\n```python\nimport os\n\nfrom dbos import DBOS, DBOSConfig\nfrom fastapi import FastAPI\n\nfrom schema import example_table\n\napp = FastAPI()\nconfig: DBOSConfig = {\n    "name": "dbos-starter",\n    "database_url": os.environ.get("DBOS_DATABASE_URL"),\n}\nDBOS(config=config, fastapi=app)\n\n@DBOS.transaction()\ndef insert_row():\n        DBOS.sql_session.execute(example_table.insert().values(name="dbos"))\n\n@DBOS.transaction()\ndef count_rows():\n    count = DBOS.sql_session.execute(example_table.select()).rowcount\n    print(f"Row count: {count}")\n\n@app.get("/")\n@DBOS.workflow()\ndef dbos_workflow():\n    insert_row()\n    count_rows()\n```\n\nNEVER async def a transaction.\n\n'})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>i});var o=t(6540);const s={},a=o.createContext(s);function r(e){const n=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),o.createElement(a.Provider,{value:n},e.children)}}}]);