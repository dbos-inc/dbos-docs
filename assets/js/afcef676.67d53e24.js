"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[7553],{2643:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"python/reference/contexts","title":"DBOS Methods & Variables","description":"DBOS provides a number of useful context methods and variables.","source":"@site/docs/python/reference/contexts.md","sourceDirName":"python/reference","slug":"/python/reference/contexts","permalink":"/python/reference/contexts","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"DBOS Methods & Variables"},"sidebar":"tutorialSidebar","previous":{"title":"Workflows & Steps","permalink":"/python/reference/decorators"},"next":{"title":"Queues","permalink":"/python/reference/queues"}}');var r=s(4848),o=s(8453);const i={sidebar_position:3,title:"DBOS Methods & Variables"},l=void 0,a={},d=[{value:"Context Methods",id:"context-methods",level:2},{value:"start_workflow",id:"start_workflow",level:3},{value:"start_workflow_async",id:"start_workflow_async",level:3},{value:"send",id:"send",level:3},{value:"send_async",id:"send_async",level:3},{value:"recv",id:"recv",level:3},{value:"recv_async",id:"recv_async",level:3},{value:"set_event",id:"set_event",level:3},{value:"set_event_async",id:"set_event_async",level:3},{value:"get_event",id:"get_event",level:3},{value:"get_event_async",id:"get_event_async",level:3},{value:"get_all_events",id:"get_all_events",level:3},{value:"get_all_events_async",id:"get_all_events_async",level:3},{value:"sleep",id:"sleep",level:3},{value:"sleep_async",id:"sleep_async",level:3},{value:"run_step",id:"run_step",level:3},{value:"run_step_async",id:"run_step_async",level:3},{value:"get_result",id:"get_result",level:3},{value:"get_result_async",id:"get_result_async",level:3},{value:"get_workflow_status",id:"get_workflow_status",level:3},{value:"get_workflow_status_async",id:"get_workflow_status_async",level:3},{value:"retrieve_workflow",id:"retrieve_workflow",level:3},{value:"retrieve_workflow_async",id:"retrieve_workflow_async",level:3},{value:"write_stream",id:"write_stream",level:3},{value:"write_stream_async",id:"write_stream_async",level:3},{value:"close_stream",id:"close_stream",level:3},{value:"close_stream_async",id:"close_stream_async",level:3},{value:"read_stream",id:"read_stream",level:3},{value:"read_stream_async",id:"read_stream_async",level:3},{value:"patch",id:"patch",level:3},{value:"patch_async",id:"patch_async",level:3},{value:"deprecate_patch",id:"deprecate_patch",level:3},{value:"deprecate_patch_async",id:"deprecate_patch_async",level:3},{value:"Workflow Management Methods",id:"workflow-management-methods",level:2},{value:"list_workflows",id:"list_workflows",level:3},{value:"list_workflows_async",id:"list_workflows_async",level:3},{value:"list_queued_workflows",id:"list_queued_workflows",level:3},{value:"list_queued_workflows_async",id:"list_queued_workflows_async",level:3},{value:"list_workflow_steps",id:"list_workflow_steps",level:3},{value:"list_workflow_steps_async",id:"list_workflow_steps_async",level:3},{value:"cancel_workflow",id:"cancel_workflow",level:3},{value:"cancel_workflow_async",id:"cancel_workflow_async",level:3},{value:"resume_workflow",id:"resume_workflow",level:3},{value:"resume_workflow_async",id:"resume_workflow_async",level:3},{value:"fork_workflow",id:"fork_workflow",level:3},{value:"fork_workflow_async",id:"fork_workflow_async",level:3},{value:"delete_workflow",id:"delete_workflow",level:3},{value:"delete_workflow_async",id:"delete_workflow_async",level:3},{value:"Workflow Status",id:"workflow-status",level:3},{value:"Context Variables",id:"context-variables",level:2},{value:"logger",id:"logger",level:3},{value:"sql_session",id:"sql_session",level:3},{value:"workflow_id",id:"workflow_id",level:3},{value:"step_id",id:"step_id",level:3},{value:"step_status",id:"step_status",level:3},{value:"span",id:"span",level:3},{value:"application_version",id:"application_version",level:3},{value:"executor_id",id:"executor_id",level:3},{value:"Debouncing",id:"debouncing",level:2},{value:"Debouncer.create",id:"debouncercreate",level:3},{value:"debounce",id:"debounce",level:3},{value:"Debouncer.create_async",id:"debouncercreate_async",level:3},{value:"debounce_async",id:"debounce_async",level:3},{value:"Authentication",id:"authentication",level:2},{value:"authenticated_user",id:"authenticated_user",level:3},{value:"authenticated_roles",id:"authenticated_roles",level:3},{value:"assumed_role",id:"assumed_role",level:3},{value:"set_authentication",id:"set_authentication",level:3},{value:"Context Management",id:"context-management",level:2},{value:"SetWorkflowID",id:"setworkflowid",level:3},{value:"SetWorkflowTimeout",id:"setworkflowtimeout",level:3},{value:"DBOSContextEnsure",id:"dboscontextensure",level:3},{value:"DBOSContextSetAuth",id:"dboscontextsetauth",level:3},{value:"Alerting",id:"alerting",level:2},{value:"alert_handler",id:"alert_handler",level:3},{value:"Custom Serialization",id:"custom-serialization",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(n.p,{children:["DBOS provides a number of useful context methods and variables.\nAll are accessed through the syntax ",(0,r.jsx)(n.code,{children:"DBOS.<method>"})," and can only be used once a DBOS class object has been initialized."]}),"\n",(0,r.jsx)(n.h2,{id:"context-methods",children:"Context Methods"}),"\n",(0,r.jsx)(n.h3,{id:"start_workflow",children:"start_workflow"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.start_workflow(\n    func: Workflow[P, R],\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -> WorkflowHandle[R]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Start a workflow in the background and return a ",(0,r.jsx)(n.a,{href:"/python/reference/workflow_handles",children:"handle"})," to it.\nThe ",(0,r.jsx)(n.code,{children:"DBOS.start_workflow"})," method resolves after the handle is durably created; at this point the workflow is guaranteed to run to completion even if the app is interrupted."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example syntax:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'@DBOS.workflow()\ndef example_workflow(var1: str, var2: str):\n    DBOS.logger.info("I am a workflow")\n\n# Start example_workflow in the background\nhandle: WorkflowHandle = DBOS.start_workflow(example_workflow, "var1", "var2")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"start_workflow_async",children:"start_workflow_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.start_workflow_async(\n    func: Workflow[P, Coroutine[Any, Any, R]],\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -> Coroutine[Any, Any, WorkflowHandleAsync[R]]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Start an asynchronous workflow and return a ",(0,r.jsx)(n.a,{href:"/python/reference/workflow_handles",children:"handle"})," to it.\nThe ",(0,r.jsx)(n.code,{children:"DBOS.start_workflow_async"})," method resolves after the handle is durably created; at this point the workflow is guaranteed to run to completion even if the app is interrupted.\nThe workflow started with ",(0,r.jsx)(n.code,{children:"DBOS.start_workflow_async"})," runs in the same event loop as its caller."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example syntax:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'@DBOS.workflow()\nasync def example_workflow(var1: str, var2: str):\n    DBOS.logger.info("I am a workflow")\n\n# Start example_workflow\nhandle: WorkflowHandleAsync = await DBOS.start_workflow_async(example_workflow, "var1", "var2")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"send",children:"send"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.send(\n    destination_id: str,\n    message: Any,\n    topic: Optional[str] = None\n) -> None\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Send a message to the workflow identified by ",(0,r.jsx)(n.code,{children:"destination_id"}),".\nMessages can optionally be associated with a topic.\nThe ",(0,r.jsx)(n.code,{children:"send"})," function should not be used in ",(0,r.jsx)(n.a,{href:"/python/tutorials/workflow-tutorial#coroutine-async-workflows",children:"coroutine workflows"}),", ",(0,r.jsx)(n.a,{href:"#send_async",children:(0,r.jsx)(n.code,{children:"send_async"})})," should be used instead."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"destination_id"}),": The workflow to which to send the message."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"message"}),": The message to send. Must be serializable."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"topic"}),": A topic with which to associate the message. Messages are enqueued per-topic on the receiver."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"send_async",children:"send_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.send_async(\n    destination_id: str,\n    message: Any,\n    topic: Optional[str] = None\n) -> Coroutine[Any, Any, None]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#send",children:(0,r.jsx)(n.code,{children:"send"})})]}),"\n",(0,r.jsx)(n.h3,{id:"recv",children:"recv"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.recv(\n    topic: Optional[str] = None,\n    timeout_seconds: float = 60,\n) -> Any\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Receive and return a message sent to this workflow.\nCan only be called from within a workflow or step.\nMessages are dequeued first-in, first-out from a queue associated with the topic.\nCalls to ",(0,r.jsx)(n.code,{children:"recv"})," wait for the next message in the queue, returning ",(0,r.jsx)(n.code,{children:"None"})," if the wait times out.\nIf no topic is specified, ",(0,r.jsx)(n.code,{children:"recv"})," can only access messages sent without a topic.\nThe ",(0,r.jsx)(n.code,{children:"recv"})," function should not be used in ",(0,r.jsx)(n.a,{href:"/python/tutorials/workflow-tutorial#coroutine-async-workflows",children:"coroutine workflows"}),", ",(0,r.jsx)(n.a,{href:"#recv_async",children:(0,r.jsx)(n.code,{children:"recv_async"})})," should be used instead."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"topic"}),": A topic queue on which to wait."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"timeout_seconds"}),": A timeout in seconds. If the wait times out, return ",(0,r.jsx)(n.code,{children:"None"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["The first message enqueued on the input topic, or ",(0,r.jsx)(n.code,{children:"None"})," if the wait times out."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"recv_async",children:"recv_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.recv_async(\n    topic: Optional[str] = None,\n    timeout_seconds: float = 60,\n) -> Coroutine[Any, Any, Any]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#recv",children:(0,r.jsx)(n.code,{children:"recv"})})]}),"\n",(0,r.jsx)(n.h3,{id:"set_event",children:"set_event"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.set_event(\n    key: str,\n    value: Any,\n) -> None\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Create and associate with this workflow an event with key ",(0,r.jsx)(n.code,{children:"key"})," and value ",(0,r.jsx)(n.code,{children:"value"}),".\nIf the event already exists, update its value.\nCan only be called from within a workflow.\nThe ",(0,r.jsx)(n.code,{children:"set_event"})," function should not be used in ",(0,r.jsx)(n.a,{href:"/python/tutorials/workflow-tutorial#coroutine-async-workflows",children:"coroutine workflows"}),", ",(0,r.jsx)(n.code,{children:"set_event_async"})," should be used instead."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"key"}),": The key of the event."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"value"}),": The value of the event. Must be serializable."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"set_event_async",children:"set_event_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.set_event_async(\n    key: str,\n    value: Any,\n) -> Coroutine[Any, Any, None]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#set_event",children:(0,r.jsx)(n.code,{children:"set_event"})})]}),"\n",(0,r.jsx)(n.h3,{id:"get_event",children:"get_event"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.get_event(\n    workflow_id: str,\n    key: str,\n    timeout_seconds: float = 60,\n) -> Any\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Retrieve the latest value of an event published by the workflow identified by ",(0,r.jsx)(n.code,{children:"workflow_id"})," to the key ",(0,r.jsx)(n.code,{children:"key"}),".\nIf the event does not yet exist, wait for it to be published, returning ",(0,r.jsx)(n.code,{children:"None"})," if the wait times out.\nThe ",(0,r.jsx)(n.code,{children:"get_event"})," function should not be used in ",(0,r.jsx)(n.a,{href:"/python/tutorials/workflow-tutorial#coroutine-async-workflows",children:"coroutine workflows"}),", ",(0,r.jsx)(n.a,{href:"#get_event_async",children:(0,r.jsx)(n.code,{children:"get_event_async"})})," should be used instead."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"workflow_id"}),": The identifier of the workflow whose events to retrieve."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"key"}),": The key of the event to retrieve."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"timeout_seconds"}),": A timeout in seconds. If the wait times out, return ",(0,r.jsx)(n.code,{children:"None"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["The value of the event published by ",(0,r.jsx)(n.code,{children:"workflow_id"})," with name ",(0,r.jsx)(n.code,{children:"key"}),", or ",(0,r.jsx)(n.code,{children:"None"})," if the wait times out."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"get_event_async",children:"get_event_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.get_event_async(\n    workflow_id: str,\n    key: str,\n    timeout_seconds: float = 60,\n) -> Coroutine[Any, Any, Any]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#get_event",children:(0,r.jsx)(n.code,{children:"get_event"})})]}),"\n",(0,r.jsx)(n.h3,{id:"get_all_events",children:"get_all_events"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.get_all_events(\n    workflow_id: str\n) -> Dict[str, Any]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Retrieve the latest values of all events published by ",(0,r.jsx)(n.code,{children:"workflow_id"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"workflow_id"}),": The identifier of the workflow whose events to retrieve."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"get_all_events_async",children:"get_all_events_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.get_all_events_async(\n    workflow_id: str\n) -> Dict[str, Any]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#get_all_events",children:(0,r.jsx)(n.code,{children:"get_all_events"})}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"sleep",children:"sleep"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.sleep(\n    seconds: float\n) -> None\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Sleep for the given number of seconds.\nMay only be called from within a workflow.\nThis sleep is durable\u2014it records its intended wake-up time in the database so if it is interrupted and recovers, it still wakes up at the intended time.\nThe ",(0,r.jsx)(n.code,{children:"sleep"})," function should not be used in ",(0,r.jsx)(n.a,{href:"/python/tutorials/workflow-tutorial#coroutine-async-workflows",children:"coroutine workflows"}),", ",(0,r.jsx)(n.a,{href:"#sleep_async",children:(0,r.jsx)(n.code,{children:"sleep_async"})})," should be used instead."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"seconds"}),": The number of seconds to sleep."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"sleep_async",children:"sleep_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.sleep_async(\n    seconds: float\n) -> Coroutine[Any, Any, None]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#sleep",children:(0,r.jsx)(n.code,{children:"sleep"})})]}),"\n",(0,r.jsx)(n.h3,{id:"run_step",children:"run_step"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.run_step(\n    dbos_step_options: Optional[StepOptions],\n    func: Callable[P, R],\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -> R:\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Runs the provided ",(0,r.jsx)(n.code,{children:"func"})," function (or lambda) as a checkpointed DBOS ",(0,r.jsx)(n.a,{href:"/python/tutorials/step-tutorial",children:"step"}),".  ",(0,r.jsx)(n.code,{children:"args"})," and ",(0,r.jsx)(n.code,{children:"kwargs"})," will be passed to ",(0,r.jsx)(n.code,{children:"func"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"StepOptions"})," object has the following fields.  All fields are optional."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class StepOptions(TypedDict, total=False):\n    """\n    Configuration options for steps.\n\n    Attributes:\n        name:\n            Optional name for the step.\n            If not provided, the function\'s name will be used.\n\n        retries_allowed:\n            Whether the step should be retried on failure.\n\n        interval_seconds:\n            Initial delay (in seconds) between retry attempts.\n\n        max_attempts:\n            Maximum number of attempts before the step is\n            considered failed.\n\n        backoff_rate:\n            Multiplier applied to `interval_seconds` after\n            each failed attempt (e.g. 2.0 = exponential backoff).\n    """\n\n    name: Optional[str]\n    retries_allowed: bool\n    interval_seconds: float\n    max_attempts: int\n    backoff_rate: float\n'})}),"\n",(0,r.jsx)(n.h3,{id:"run_step_async",children:"run_step_async"}),"\n",(0,r.jsxs)(n.p,{children:["Version of ",(0,r.jsx)(n.a,{href:"#run_step",children:(0,r.jsx)(n.code,{children:"run_step"})})," to be called from ",(0,r.jsx)(n.code,{children:"async"})," contexts."]}),"\n",(0,r.jsx)(n.h3,{id:"get_result",children:"get_result"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.get_result(\n    workflow_id: str,\n) -> Optional[Any]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Wait for the workflow identified by ",(0,r.jsx)(n.code,{children:"workflow_id"})," to complete, and return its result.  This is similar to calling ",(0,r.jsx)(n.a,{href:"/python/reference/workflow_handles#get_result",children:(0,r.jsx)(n.code,{children:"get_result"})})," on a ",(0,r.jsx)(n.a,{href:"/python/reference/workflow_handles",children:"WorkflowHandle"}),", but is a single step that does not require a handle."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"workflow_id"}),": The identifier of the workflow whose result to return."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"The result of the workflow, or throws an exception if the workflow threw an exception."}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"get_result_async",children:"get_result_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.get_result_async(\n    workflow_id: str,\n) -> Coroutine[Any, Any, Optional[Any]]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#get_result",children:(0,r.jsx)(n.code,{children:"get_result"})}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"get_workflow_status",children:"get_workflow_status"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.get_workflow_status(\n    workflow_id: str,\n) -> Optional[WorkflowStatus]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Retrieve the status of a workflow by its ID.\nReturns ",(0,r.jsx)(n.code,{children:"None"})," if no workflow with the given ID exists."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"workflow_id"}),": The identifier of the workflow whose status to retrieve."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["The ",(0,r.jsx)(n.a,{href:"#workflow-status",children:(0,r.jsx)(n.code,{children:"WorkflowStatus"})})," of the workflow, or ",(0,r.jsx)(n.code,{children:"None"})," if not found."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"get_workflow_status_async",children:"get_workflow_status_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.get_workflow_status_async(\n    workflow_id: str,\n) -> Coroutine[Any, Any, Optional[WorkflowStatus]]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#get_workflow_status",children:(0,r.jsx)(n.code,{children:"get_workflow_status"})}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"retrieve_workflow",children:"retrieve_workflow"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.retrieve_workflow(\n    workflow_id: str,\n    existing_workflow: bool = True,\n) -> WorkflowHandle[R]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Retrieve the ",(0,r.jsx)(n.a,{href:"/python/reference/workflow_handles",children:"handle"})," of a workflow with identity ",(0,r.jsx)(n.code,{children:"workflow_id"}),"."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"workflow_id"}),": The identifier of the workflow whose handle to retrieve."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"existing_workflow"}),": Whether to throw an exception if the workflow does not yet exist, or to wait for its creation. If set to ",(0,r.jsx)(n.code,{children:"False"})," and the workflow does not exist, will wait for the workflow to be created, then return its handle."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Returns:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["The ",(0,r.jsx)(n.a,{href:"/python/reference/workflow_handles",children:"handle"})," of the workflow whose ID is ",(0,r.jsx)(n.code,{children:"workflow_id"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"retrieve_workflow_async",children:"retrieve_workflow_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.retrieve_workflow(\n    workflow_id: str,\n    existing_workflow: bool = True,\n) -> WorkflowHandleAsync[R]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#retrieve_workflow",children:(0,r.jsx)(n.code,{children:"DBOS.retrieve_workflow"})}),", retrieving an async workflow handle."]}),"\n",(0,r.jsx)(n.h3,{id:"write_stream",children:"write_stream"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.write_stream(\n    key: str,\n    value: Any\n) -> None\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Write a value to a stream.\nCan only be called from within a workflow or its steps.\nThe ",(0,r.jsx)(n.code,{children:"write_stream"})," function should not be used in ",(0,r.jsx)(n.a,{href:"/python/tutorials/workflow-tutorial#coroutine-async-workflows",children:"coroutine workflows"}),", ",(0,r.jsx)(n.a,{href:"#write_stream_async",children:(0,r.jsx)(n.code,{children:"write_stream_async"})})," should be used instead."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"key"}),": The stream key / name within the workflow"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"value"}),": A serializable value to write to the stream"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"write_stream_async",children:"write_stream_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.write_stream_async(\n    key: str,\n    value: Any\n) -> Coroutine[Any, Any, None]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#write_stream",children:(0,r.jsx)(n.code,{children:"write_stream"})})]}),"\n",(0,r.jsx)(n.h3,{id:"close_stream",children:"close_stream"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.close_stream(\n    key: str\n) -> None\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Close a stream identified by a key.\nAfter this is called, no more values can be written to the stream.\nCan only be called from within a workflow.\nThe ",(0,r.jsx)(n.code,{children:"close_stream"})," function should not be used in ",(0,r.jsx)(n.a,{href:"/python/tutorials/workflow-tutorial#coroutine-async-workflows",children:"coroutine workflows"}),", ",(0,r.jsx)(n.a,{href:"#close_stream_async",children:(0,r.jsx)(n.code,{children:"close_stream_async"})})," should be used instead."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"key"}),": The stream key / name within the workflow"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"close_stream_async",children:"close_stream_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.close_stream_async(\n    key: str\n) -> Coroutine[Any, Any, None]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#close_stream",children:(0,r.jsx)(n.code,{children:"close_stream"})})]}),"\n",(0,r.jsx)(n.h3,{id:"read_stream",children:"read_stream"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.read_stream(\n    workflow_id: str,\n    key: str\n) -> Generator[Any, Any, None]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Read values from a stream as a generator."}),"\n",(0,r.jsx)(n.p,{children:"This function reads values from a stream identified by the workflow_id and key,\nyielding each value in order until the stream is closed or the workflow terminates."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"workflow_id"}),": The workflow instance ID that owns the stream"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"key"}),": The stream key / name within the workflow"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Yields:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Each value in the stream until the stream is closed"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example syntax:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'for value in DBOS.read_stream(workflow_id, example_key):\n    print(f"Received: {value}")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"read_stream_async",children:"read_stream_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.read_stream_async(\n    workflow_id: str,\n    key: str\n) -> AsyncGenerator[Any, None]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Read values from a stream as an async generator."}),"\n",(0,r.jsx)(n.p,{children:"This function reads values from a stream identified by the workflow_id and key,\nyielding each value in order until the stream is closed or the workflow terminates."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"workflow_id"}),": The workflow instance ID that owns the stream"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"key"}),": The stream key / name within the workflow"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example syntax:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'async for value in DBOS.read_stream_async(workflow_id, example_key):\n    print(f"Received: {value}")\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Yields:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Each value in the stream until the stream is closed"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"patch",children:"patch"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.patch(\n    patch_name: str\n) -> bool\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Insert a patch marker at the current point in workflow history, returning ",(0,r.jsx)(n.code,{children:"True"})," if it was successfully inserted and ",(0,r.jsx)(n.code,{children:"False"})," if there is already a checkpoint present at this point in history.\nUsed to safely upgrade workflow code, see the ",(0,r.jsx)(n.a,{href:"/python/tutorials/upgrading-workflows#patching",children:"patching tutorial"})," for more detail."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"patch_name"}),": The name to give the patch marker that will be inserted into workflow history."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"patch_async",children:"patch_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.patch_async(\n    patch_name: str\n) -> Coroutine[Any, Any, bool]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#patch",children:(0,r.jsx)(n.code,{children:"DBOS.patch()"})}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"deprecate_patch",children:"deprecate_patch"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.deprecate_patch(\n    patch_name: str\n) -> bool\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Safely bypass a patch marker at the current point in workflow history if present.\nAlways returns ",(0,r.jsx)(n.code,{children:"True"}),".\nUsed to safely deprecate patches, see the ",(0,r.jsx)(n.a,{href:"/python/tutorials/upgrading-workflows#patching",children:"patching tutorial"})," for more detail."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"patch_name"}),": The name of the patch marker to be bypassed."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"deprecate_patch_async",children:"deprecate_patch_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.deprecate_patch_async(\n    patch_name: str\n) -> Coroutine[Any, Any, bool]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#deprecate_patch",children:(0,r.jsx)(n.code,{children:"DBOS.deprecate_patch()"})})]}),"\n",(0,r.jsx)(n.h2,{id:"workflow-management-methods",children:"Workflow Management Methods"}),"\n",(0,r.jsx)(n.h3,{id:"list_workflows",children:"list_workflows"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def list_workflows(\n    *,\n    workflow_ids: Optional[List[str]] = None,\n    status: Optional[Union[str, List[str]]] = None,\n    start_time: Optional[str] = None,\n    end_time: Optional[str] = None,\n    name: Optional[str] = None,\n    app_version: Optional[str] = None,\n    forked_from: Optional[str] = None,\n    user: Optional[str] = None,\n    queue_name: Optional[str] = None,\n    limit: Optional[int] = None,\n    offset: Optional[int] = None,\n    sort_desc: bool = False,\n    workflow_id_prefix: Optional[str] = None,\n    load_input: bool = True,\n    load_output: bool = True,\n    executor_id: Optional[str] = None,\n    queues_only: bool = False,\n) -> List[WorkflowStatus]:\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Retrieve a list of ",(0,r.jsx)(n.a,{href:"#workflow-status",children:(0,r.jsx)(n.code,{children:"WorkflowStatus"})})," of all workflows matching specified criteria."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"workflow_ids"}),": Retrieve workflows with these IDs."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"status"}),": Retrieve workflows with this status (or one of these statuses) (Must be ",(0,r.jsx)(n.code,{children:"ENQUEUED"}),", ",(0,r.jsx)(n.code,{children:"PENDING"}),", ",(0,r.jsx)(n.code,{children:"SUCCESS"}),", ",(0,r.jsx)(n.code,{children:"ERROR"}),", ",(0,r.jsx)(n.code,{children:"CANCELLED"}),", or ",(0,r.jsx)(n.code,{children:"MAX_RECOVERY_ATTEMPTS_EXCEEDED"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"start_time"}),": Retrieve workflows started after this (RFC 3339-compliant) timestamp."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"end_time"}),": Retrieve workflows started before this (RFC 3339-compliant) timestamp."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"name"}),": Retrieve workflows with this fully-qualified name."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"app_version"}),": Retrieve workflows tagged with this application version."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"forked_from"}),": Retrieve workflows forked from this workflow ID."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"user"}),": Retrieve workflows run by this authenticated user."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"queue_name"}),": Retrieve workflows that were enqueued on this queue."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"limit"}),": Retrieve up to this many workflows."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"offset"}),": Skip this many workflows from the results returned (for pagination)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"sort_desc"}),": Whether to sort the results in descending (",(0,r.jsx)(n.code,{children:"True"}),") or ascending (",(0,r.jsx)(n.code,{children:"False"}),") order by workflow start time."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"workflow_id_prefix"}),": Retrieve workflows whose IDs start with the specified string."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"load_input"}),": Whether to load and deserialize workflow inputs. Set to ",(0,r.jsx)(n.code,{children:"False"})," to improve performance when inputs are not needed."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"load_output"}),": Whether to load and deserialize workflow outputs. Set to ",(0,r.jsx)(n.code,{children:"False"})," to improve performance when outputs are not needed."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"executor_id"}),": Retrieve workflows with this executor ID."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"queues_only"}),": If ",(0,r.jsx)(n.code,{children:"True"}),", only retrieve workflows that are currently queued (status ",(0,r.jsx)(n.code,{children:"ENQUEUED"})," or ",(0,r.jsx)(n.code,{children:"PENDING"})," and ",(0,r.jsx)(n.code,{children:"queue_name"})," not null). Equivalent to using ",(0,r.jsx)(n.a,{href:"#list_queued_workflows",children:(0,r.jsx)(n.code,{children:"list_queued_workflows"})}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"list_workflows_async",children:"list_workflows_async"}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#list_workflows",children:(0,r.jsx)(n.code,{children:"list_workflows"})}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"list_queued_workflows",children:"list_queued_workflows"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def list_queued_workflows(\n    *,\n    workflow_ids: Optional[List[str]] = None,\n    status: Optional[Union[str, List[str]]] = None,\n    start_time: Optional[str] = None,\n    end_time: Optional[str] = None,\n    name: Optional[str] = None,\n    app_version: Optional[str] = None,\n    forked_from: Optional[str] = None,\n    user: Optional[str] = None,\n    queue_name: Optional[str] = None,\n    limit: Optional[int] = None,\n    offset: Optional[int] = None,\n    sort_desc: bool = False,\n    workflow_id_prefix: Optional[str] = None,\n    load_input: bool = True,\n    load_output: bool = True,\n    executor_id: Optional[str] = None,\n) -> List[WorkflowStatus]:\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Retrieve a list of ",(0,r.jsx)(n.a,{href:"#workflow-status",children:(0,r.jsx)(n.code,{children:"WorkflowStatus"})})," of all ",(0,r.jsx)(n.strong,{children:"queued"})," workflows (status ",(0,r.jsx)(n.code,{children:"ENQUEUED"})," or ",(0,r.jsx)(n.code,{children:"PENDING"})," and ",(0,r.jsx)(n.code,{children:"queue_name"})," not null) matching specified criteria."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"workflow_ids"}),": Retrieve workflows with these IDs."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"status"}),": Retrieve workflows with this status (or one of these statuses) (Must be ",(0,r.jsx)(n.code,{children:"ENQUEUED"})," or ",(0,r.jsx)(n.code,{children:"PENDING"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"start_time"}),": Retrieve workflows enqueued after this (RFC 3339-compliant) timestamp."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"end_time"}),": Retrieve workflows enqueued before this (RFC 3339-compliant) timestamp."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"name"}),": Retrieve workflows with this fully-qualified name."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"app_version"}),": Retrieve workflows tagged with this application version."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"forked_from"}),": Retrieve workflows forked from this workflow ID."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"user"}),": Retrieve workflows run by this authenticated user."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"queue_name"}),": Retrieve workflows running on this queue."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"limit"}),": Retrieve up to this many workflows."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"offset"}),": Skip this many workflows from the results returned (for pagination)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"sort_desc"}),": Whether to sort the results in descending (",(0,r.jsx)(n.code,{children:"True"}),") or ascending (",(0,r.jsx)(n.code,{children:"False"}),") order by workflow start time."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"workflow_id_prefix"}),": Retrieve workflows whose IDs start with the specified string."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"load_input"}),": Whether to load and deserialize workflow inputs. Set to ",(0,r.jsx)(n.code,{children:"False"})," to improve performance when inputs are not needed."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"load_output"}),": Whether to load and deserialize workflow outputs. Set to ",(0,r.jsx)(n.code,{children:"False"})," to improve performance when outputs are not needed."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"executor_id"}),": Retrieve workflows with this executor ID."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"list_queued_workflows_async",children:"list_queued_workflows_async"}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#list_queued_workflows",children:(0,r.jsx)(n.code,{children:"list_queued_workflows"})}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"list_workflow_steps",children:"list_workflow_steps"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def list_workflow_steps(\n    workflow_id: str,\n) -> List[StepInfo]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Retrieve the steps of a workflow.\nThis is a list of ",(0,r.jsx)(n.code,{children:"StepInfo"})," objects, with the following structure:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class StepInfo(TypedDict):\n    # The unique ID of the step in the workflow. One-indexed.\n    function_id: int\n    # The (fully qualified) name of the step\n    function_name: str\n    # The step's output, if any\n    output: Optional[Any]\n    # The error the step threw, if any\n    error: Optional[Exception]\n    # If the step starts or retrieves the result of a workflow, its ID\n    child_workflow_id: Optional[str]\n    # The Unix epoch timestamp at which this step started\n    started_at_epoch_ms: Optional[int]\n    # The Unix epoch timestamp at which this step completed\n    completed_at_epoch_ms: Optional[int]\n"})}),"\n",(0,r.jsx)(n.h3,{id:"list_workflow_steps_async",children:"list_workflow_steps_async"}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#list_workflow_steps",children:(0,r.jsx)(n.code,{children:"list_workflow_steps"})}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"cancel_workflow",children:"cancel_workflow"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.cancel_workflow(\n    workflow_id: str,\n) -> None\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Cancel a workflow.\nThis sets is status to ",(0,r.jsx)(n.code,{children:"CANCELLED"}),", removes it from its queue (if it is enqueued) and preempts its execution (interrupting it at the beginning of its next step)"]}),"\n",(0,r.jsx)(n.h3,{id:"cancel_workflow_async",children:"cancel_workflow_async"}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#cancel_workflow",children:(0,r.jsx)(n.code,{children:"cancel_workflow"})}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"resume_workflow",children:"resume_workflow"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.resume_workflow(\n    workflow_id: str\n) -> WorkflowHandle[R]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Resume a workflow.\nThis immediately starts it from its last completed step.\nYou can use this to resume workflows that are cancelled or have exceeded their maximum recovery attempts.\nYou can also use this to start an enqueued workflow immediately, bypassing its queue."}),"\n",(0,r.jsx)(n.h3,{id:"resume_workflow_async",children:"resume_workflow_async"}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#resume_workflow",children:(0,r.jsx)(n.code,{children:"resume_workflow"})}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"fork_workflow",children:"fork_workflow"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.fork_workflow(\n    workflow_id: str,\n    start_step: int,\n    *,\n    application_version: Optional[str] = None,\n) -> WorkflowHandle[R]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Start a new execution of a workflow from a specific step.\nThe input step ID must match the ",(0,r.jsx)(n.code,{children:"function_id"})," of the step returned by ",(0,r.jsx)(n.code,{children:"list_workflow_steps"}),".\nThe specified ",(0,r.jsx)(n.code,{children:"start_step"})," is the step from which the new workflow will start, so any steps whose ID is less than ",(0,r.jsx)(n.code,{children:"start_step"})," will not be re-executed."]}),"\n",(0,r.jsxs)(n.p,{children:["The forked workflow will have a new workflow ID, which can be set with ",(0,r.jsx)(n.a,{href:"#setworkflowid",children:(0,r.jsx)(n.code,{children:"SetWorkflowID"})}),".\nIt is possible to specify the application version on which the forked workflow will run by setting ",(0,r.jsx)(n.code,{children:"application_version"}),', this is useful for "patching" workflows that failed due to a bug in a previous application version.']}),"\n",(0,r.jsx)(n.h3,{id:"fork_workflow_async",children:"fork_workflow_async"}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#fork_workflow",children:(0,r.jsx)(n.code,{children:"fork_workflow"})}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"delete_workflow",children:"delete_workflow"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.delete_workflow(\n    workflow_id: str,\n    *,\n    delete_children: bool = False,\n) -> None\n"})}),"\n",(0,r.jsx)(n.p,{children:"Delete a workflow and all its associated data (inputs, outputs, step results, etc.) from the system database."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"workflow_id"}),": The ID of the workflow to delete."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"delete_children"}),": If ",(0,r.jsx)(n.code,{children:"True"}),", also recursively deletes all child workflows started by this workflow."]}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{type:"warning",children:(0,r.jsx)(n.p,{children:"This operation is irreversible. Once a workflow is deleted, it cannot be recovered, resumed, or forked."})}),"\n",(0,r.jsx)(n.h3,{id:"delete_workflow_async",children:"delete_workflow_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.delete_workflow_async(\n    workflow_id: str,\n    *,\n    delete_children: bool = False,\n) -> Coroutine[Any, Any, None]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Coroutine version of ",(0,r.jsx)(n.a,{href:"#delete_workflow",children:(0,r.jsx)(n.code,{children:"delete_workflow"})}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"workflow-status",children:"Workflow Status"}),"\n",(0,r.jsxs)(n.p,{children:["Some workflow introspection and management methods return a ",(0,r.jsx)(n.code,{children:"WorkflowStatus"}),".\nThis object has the following definition:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class WorkflowStatus:\n    # The workflow ID\n    workflow_id: str\n    # The workflow status. Must be one of ENQUEUED, PENDING, SUCCESS, ERROR, CANCELLED, or MAX_RECOVERY_ATTEMPTS_EXCEEDED\n    status: str\n    # The name of the workflow function\n    name: str\n    # The name of the workflow's class, if any\n    class_name: Optional[str]\n    # The name with which the workflow's class instance was configured, if any\n    config_name: Optional[str]\n    # The user who ran the workflow, if specified\n    authenticated_user: Optional[str]\n    # The role with which the workflow ran, if specified\n    assumed_role: Optional[str]\n    # All roles which the authenticated user could assume\n    authenticated_roles: Optional[list[str]]\n    # The deserialized workflow input object\n    input: Optional[WorkflowInputs]\n    # The workflow's output, if any\n    output: Optional[Any]\n    # The error the workflow threw, if any\n    error: Optional[Exception]\n    # Workflow start time, as a Unix epoch timestamp in ms\n    created_at: Optional[int]\n    # Last time the workflow status was updated, as a Unix epoch timestamp in ms\n    updated_at: Optional[int]\n    # If this workflow was enqueued, on which queue\n    queue_name: Optional[str]\n    # The executor to most recently execute this workflow\n    executor_id: Optional[str]\n    # The application version on which this workflow was started\n    app_version: Optional[str]\n    # The start-to-close timeout of the workflow in ms\n    workflow_timeout_ms: Optional[int]\n    # The deadline of a workflow, computed by adding its timeout to its start time.\n    workflow_deadline_epoch_ms: Optional[int]\n    # Unique ID for deduplication on a queue\n    deduplication_id: Optional[str]\n    # Priority of the workflow on the queue, starting from 1 ~ 2,147,483,647. Default 0 (highest priority).\n    priority: Optional[int]\n    # If this workflow is enqueued on a partitioned queue, its partition key\n    queue_partition_key: Optional[str]\n    # If this workflow was forked from another, that workflow's ID.\n    forked_from: Optional[str]\n"})}),"\n",(0,r.jsx)(n.h2,{id:"context-variables",children:"Context Variables"}),"\n",(0,r.jsx)(n.h3,{id:"logger",children:"logger"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.logger: Logger\n"})}),"\n",(0,r.jsx)(n.p,{children:"Retrieve the DBOS logger. This is a pre-configured Python logger provided as a convenience."}),"\n",(0,r.jsx)(n.h3,{id:"sql_session",children:"sql_session"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.sql_session: sqlalchemy.Session\n"})}),"\n",(0,r.jsx)(n.p,{children:"May only be accessed from within a transaction.\nRetrieves the SQLAlchemy session of the transaction, a database connection the transaction can use to interact with the database."}),"\n",(0,r.jsx)(n.admonition,{type:"tip",children:(0,r.jsxs)(n.p,{children:["DBOS automatically wraps your transaction functions in a SQLAlchemy ",(0,r.jsx)(n.a,{href:"https://docs.sqlalchemy.org/en/20/core/connections.html#connect-and-begin-once-from-the-engine",children:'"begin once" block'}),". Transaction functions automatically commit when they successfully complete and roll back if they throw an exception. Therefore, do not use ",(0,r.jsx)(n.code,{children:"DBOS.sql_session.commit()"})," or ",(0,r.jsx)(n.code,{children:"DBOS.sql_session.rollback()"})," in your transaction functions. Otherwise, you might see a ",(0,r.jsx)(n.code,{children:"sqlalchemy.exc.InvalidRequestError: Can't operate on closed transaction inside context manager"})," error."]})}),"\n",(0,r.jsx)(n.h3,{id:"workflow_id",children:"workflow_id"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.workflow_id: str\n"})}),"\n",(0,r.jsx)(n.p,{children:"May only be accessed from within a workflow, step, or transaction.\nReturn the identity of the current workflow."}),"\n",(0,r.jsx)(n.h3,{id:"step_id",children:"step_id"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.step_id: int\n"})}),"\n",(0,r.jsx)(n.p,{children:"Returns the unique ID of the current step within a workflow."}),"\n",(0,r.jsx)(n.h3,{id:"step_status",children:"step_status"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.step_status: StepStatus\n"})}),"\n",(0,r.jsx)(n.p,{children:"Return the status of the currently executing step.\nThis object has the following properties:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class StepStatus:\n    # The unique ID of this step in its workflow.\n    step_id: int\n    # For steps with automatic retries, which attempt number (zero-indexed) is currently executing.\n    current_attempt: Optional[int]\n    # For steps with automatic retries, the maximum number of attempts that will be made before the step fails.\n    max_attempts: Optional[int]\n"})}),"\n",(0,r.jsx)(n.h3,{id:"span",children:"span"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.span: opentelemetry.trace.Span\n"})}),"\n",(0,r.jsx)(n.p,{children:"Retrieve the OpenTelemetry span associated with the curent request.\nYou can use this to set custom attributes in your span."}),"\n",(0,r.jsx)(n.h3,{id:"application_version",children:"application_version"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.application_version: str\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Retrieve the current application version, as documented ",(0,r.jsx)(n.a,{href:"/python/tutorials/upgrading-workflows#versioning",children:"here"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"executor_id",children:"executor_id"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.executor_id: str\n"})}),"\n",(0,r.jsx)(n.p,{children:"Retrieve the current executor ID, a unique process ID used to identify the application instance in distributed environments."}),"\n",(0,r.jsx)(n.h2,{id:"debouncing",children:"Debouncing"}),"\n",(0,r.jsxs)(n.p,{children:["You can create a ",(0,r.jsx)(n.code,{children:"Debouncer"})," to debounce your workflows.\nDebouncing delays workflow execution until some time has passed since the workflow has last been called.\nThis is useful for preventing wasted work when a workflow may be triggered multiple times in quick succession.\nFor example, if a user is editing an input field, you can debounce their changes to execute a processing workflow only after they haven't edited the field for some time:"]}),"\n",(0,r.jsx)(n.h3,{id:"debouncercreate",children:"Debouncer.create"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"Debouncer.create(\n    workflow: Callable[P, R],\n    *,\n    debounce_timeout_sec: Optional[float] = None,\n    queue: Optional[Queue] = None,\n) -> Debouncer[P, R]\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"workflow"}),": The workflow to debounce."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"debounce_key"}),": The debounce key for this debouncer. Used to group workflow executions that will be debounced. For example, if the debounce key is set to customer ID, each customer's workflows would be debounced separately."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"debounce_timeout_sec"}),": After this time elapses since the first time a workflow is submitted from this debouncer, the workflow is started regardless of the debounce period."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"queue"}),": When starting a workflow after debouncing, enqueue it on this queue instead of executing it directly."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"debounce",children:"debounce"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"debouncer.debounce(\n    debounce_key: str,\n    debounce_period_sec: float,\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -> WorkflowHandle[R]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Submit a workflow for execution but delay it by ",(0,r.jsx)(n.code,{children:"debounce_period_sec"}),".\nReturns a handle to the workflow.\nThe workflow may be debounced again, which further delays its execution (up to ",(0,r.jsx)(n.code,{children:"debounce_timeout_sec"}),").\nWhen the workflow eventually executes, it uses the ",(0,r.jsx)(n.strong,{children:"last"})," set of inputs passed into ",(0,r.jsx)(n.code,{children:"debounce"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["After the workflow begins execution, the next call to ",(0,r.jsx)(n.code,{children:"debounce"})," starts the debouncing process again for a new workflow execution."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"debounce_key"}),": A key used to group workflow executions that will be debounced together. For example, if the debounce key is set to customer ID, each customer's workflows would be debounced separately."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"debounce_period_sec"}),": Delay this workflow's execution by this period."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"*args"}),": Variadic workflow arguments."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"**kwargs"}),": Variadic workflow keyword arguments."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Example Syntax"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"@DBOS.workflow()\ndef process_input(user_input):\n    ...\n\n# Each time a user submits a new input, debounce the process_input workflow.\n# The debouncer will wait until 60 seconds after the user stops submitting new inputs,\n# then start the workflow processing the last input submitted.\ndebouncer = Debouncer.create(process_input)\ndef on_user_input_submit(user_id, user_input):\n    debounce_key = user_id\n    debounce_period_sec = 60\n    debouncer.debounce(debounce_key, debounce_period_sec, user_input)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"debouncercreate_async",children:"Debouncer.create_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"Debouncer.create_async(\n    workflow: Callable[P, Coroutine[Any, Any, R]],\n    *,\n    debounce_timeout_sec: Optional[float] = None,\n    queue: Optional[Queue] = None,\n) -> Debouncer[P, R]\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Async version of ",(0,r.jsx)(n.code,{children:"Debouncer.create"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"debounce_async",children:"debounce_async"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"debouncer.debounce_async(\n    debounce_key: str,\n    debounce_period_sec: float,\n    *args: P.args,\n    **kwargs: P.kwargs,\n) -> WorkflowHandleAsync[R]:\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Async version of ",(0,r.jsx)(n.code,{children:"debouncer.debounce"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"authentication",children:"Authentication"}),"\n",(0,r.jsx)(n.h3,{id:"authenticated_user",children:"authenticated_user"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.authenticated_user: Optional[str]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Return the current authenticated user, if any, associated with the current context."}),"\n",(0,r.jsx)(n.h3,{id:"authenticated_roles",children:"authenticated_roles"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.authenticated_roles: Optional[List[str]]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Return the roles granted to the current authenticated user, if any, associated with the current context."}),"\n",(0,r.jsx)(n.h3,{id:"assumed_role",children:"assumed_role"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.assumed_role: Optional[str]\n"})}),"\n",(0,r.jsx)(n.p,{children:"Return the role currently assumed by the authenticated user, if any, associated with the current context."}),"\n",(0,r.jsx)(n.h3,{id:"set_authentication",children:"set_authentication"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOS.set_authentication(\n  authenticated_user: Optional[str],\n  authenticated_roles: Optional[List[str]]\n) -> None\n"})}),"\n",(0,r.jsx)(n.p,{children:"Set the current authenticated user and granted roles into the current context.  This would generally be done by HTTP middleware"}),"\n",(0,r.jsx)(n.h2,{id:"context-management",children:"Context Management"}),"\n",(0,r.jsx)(n.h3,{id:"setworkflowid",children:"SetWorkflowID"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"SetWorkflowID(\n    wfid: str\n)\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Set the ",(0,r.jsx)(n.a,{href:"/python/tutorials/workflow-tutorial#workflow-ids-and-idempotency",children:"workflow ID"})," of the next workflow to run.\nShould be used in a ",(0,r.jsx)(n.code,{children:"with"})," statement."]}),"\n",(0,r.jsx)(n.p,{children:"Example syntax:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'@DBOS.workflow()\ndef example_workflow():\n    DBOS.logger.info(f"I am a workflow with ID {DBOS.workflow_id}")\n\n# The workflow will run with the supplied ID\nwith SetWorkflowID("very-unique-id"):\n    example_workflow()\n'})}),"\n",(0,r.jsx)(n.h3,{id:"setworkflowtimeout",children:"SetWorkflowTimeout"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"SetWorkflowTimeout(\n    workflow_timeout_sec: Optional[float]\n)\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Set a timeout for all enclosed workflow invocations or enqueues.\nWhen the timeout expires, the workflow ",(0,r.jsx)(n.strong,{children:"and all its children"})," are cancelled.\nCancelling a workflow sets its status to ",(0,r.jsx)(n.code,{children:"CANCELLED"})," and preempts its execution at the beginning of its next step."]}),"\n",(0,r.jsxs)(n.p,{children:["Timeouts are ",(0,r.jsx)(n.strong,{children:"start-to-completion"}),": if a workflow is enqueued, the timeout does not begin until the workflow is dequeued and starts execution.\nAlso, timeouts are ",(0,r.jsx)(n.strong,{children:"durable"}),": they are stored in the database and persist across restarts, so workflows can have very long timeouts."]}),"\n",(0,r.jsxs)(n.p,{children:["Timeout deadlines are propagated to child workflows by default, so when a workflow's deadline expires all of its child workflows (and their children, and so on) are also cancelled.\nIf you want to detach a child workflow from its parent's timeout, you can start it with ",(0,r.jsx)(n.code,{children:"SetWorkflowTimeout(custom_timeout)"})," to override the propagated timeout.\nYou can use ",(0,r.jsx)(n.code,{children:"SetWorkflowTimeout(None)"})," to start a child workflow with no timeout."]}),"\n",(0,r.jsx)(n.p,{children:"Example syntax:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"@DBOS.workflow()\ndef example_workflow():\n    ...\n\n# If the workflow does not complete within 10 seconds, it times out and is cancelled\nwith SetWorkflowTimeout(10):\n    example_workflow()\n"})}),"\n",(0,r.jsx)(n.h3,{id:"dboscontextensure",children:"DBOSContextEnsure"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOSContextEnsure()\n\n  # Code inside will run with a DBOS context available\n  with DBOSContextEnsure():\n    # Call DBOS functions\n    pass\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Use of ",(0,r.jsx)(n.code,{children:"DBOSContextEnsure"})," ensures that there is a DBOS context associated with the enclosed code prior to calling DBOS functions.  ",(0,r.jsx)(n.code,{children:"DBOSContextEnsure"})," is generally not used by applications directly, but used by event dispatchers, HTTP server middleware, etc., to set up the DBOS context prior to entry into function calls."]}),"\n",(0,r.jsx)(n.h3,{id:"dboscontextsetauth",children:"DBOSContextSetAuth"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"DBOSContextSetAuth(user: Optional[str], roles: Optional[List[str]])\n\n  # Code inside will run with `curuser` and `curroles`\n  with DBOSContextSetAuth(curuser, curroles):\n    # Call DBOS functions\n    pass\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"with DBOSContextSetAuth"})," sets the current authorized user and roles for the code inside the ",(0,r.jsx)(n.code,{children:"with"})," block.  Similar to ",(0,r.jsx)(n.code,{children:"DBOSContextEnsure"}),", ",(0,r.jsx)(n.code,{children:"DBOSContextSetAuth"})," also ensures that there is a DBOS context associated with the enclosed code prior to calling DBOS functions."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"DBOSContextSetAuth"})," is generally not used by applications directly, but used by event dispatchers, HTTP server middleware, etc., to set up the DBOS context prior to entry into function calls."]}),"\n",(0,r.jsx)(n.h2,{id:"alerting",children:"Alerting"}),"\n",(0,r.jsx)(n.h3,{id:"alert_handler",children:"alert_handler"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"@DBOS.alert_handler\ndef my_handler(rule_type: str, message: str, metadata: Dict[str, str]) -> None:\n    ...\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Register a function to handle ",(0,r.jsx)(n.a,{href:"/production/alerting",children:"alerts"})," received from Conductor.\nThe handler function is called with three arguments:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"rule_type"}),": The type of alert rule. One of ",(0,r.jsx)(n.code,{children:"WorkflowFailure"}),", ",(0,r.jsx)(n.code,{children:"SlowQueue"}),", or ",(0,r.jsx)(n.code,{children:"UnresponsiveApplication"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"message"}),": The alert message."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"metadata"}),": A dictionary of string key-value pairs with additional alert information."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Only one alert handler may be registered per application, and it must be defined before ",(0,r.jsx)(n.code,{children:"DBOS.launch()"})," is called.\nIf no handler is registered, alerts are logged to the DBOS logger."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example syntax:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'@DBOS.alert_handler\ndef handle_alert(rule_type: str, message: str, metadata: dict[str, str]) -> None:\n    DBOS.logger.warning(f"Alert received: {rule_type} - {message}")\n    for key, value in metadata.items():\n        DBOS.logger.warning(f"  {key}: {value}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"custom-serialization",children:"Custom Serialization"}),"\n",(0,r.jsxs)(n.p,{children:["DBOS must serialize data such as workflow inputs and outputs and step outputs to store it in the system database.\nBy default, data is serialized with ",(0,r.jsx)(n.code,{children:"pickle"})," then Base64-encoded, but you can optionally supply a custom serializer through DBOS configuration.\nA custom serializer must match this interface:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class Serializer(ABC):\n\n    @abstractmethod\n    def serialize(self, data: Any) -> str:\n        pass\n\n    @abstractmethod\n    def deserialize(cls, serialized_data: str) -> Any:\n        pass\n"})}),"\n",(0,r.jsx)(n.p,{children:"For example, here is how to configure DBOS to use a JSON serializer:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from dbos import DBOS, DBOSConfig, Serializer\n\nclass JsonSerializer(Serializer):\n    def serialize(self, data: Any) -> str:\n        return json.dumps(data)\n\n    def deserialize(cls, serialized_data: str) -> Any:\n        return json.loads(serialized_data)\n\nserializer = JsonSerializer()\nconfig: DBOSConfig = {\n    "name": "dbos-starter",\n    "system_database_url": os.environ.get("DBOS_SYSTEM_DATABASE_URL"),\n    "serializer": serializer\n}\nDBOS(config=config)\nDBOS.launch()\n'})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>l});var t=s(6540);const r={},o=t.createContext(r);function i(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);