"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[8407],{1164:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"production/hosting-with-kubernetes","title":"Deploying With Kubernetes","description":"This guide covers deploying a DBOS application on Kubernetes.","source":"@site/docs/production/hosting-with-kubernetes.md","sourceDirName":"production","slug":"/production/hosting-with-kubernetes","permalink":"/production/hosting-with-kubernetes","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":70,"frontMatter":{"sidebar_position":70,"title":"Deploying With Kubernetes"},"sidebar":"tutorialSidebar","previous":{"title":"Self-Hosting Conductor With Kubernetes","permalink":"/production/hosting-conductor-with-kubernetes"},"next":{"title":"Deploying With Google Cloud Run","permalink":"/production/hosting-with-cloud-run"}}');var t=n(4848),a=n(8453);const i={sidebar_position:70,title:"Deploying With Kubernetes"},c=void 0,o={},l=[{value:"Deployment",id:"deployment",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Database Privilege Separation",id:"database-privilege-separation",level:2},{value:"Availability",id:"availability",level:2},{value:"Upgrading Workflow Code",id:"upgrading-workflow-code",level:2},{value:"Scaling with KEDA",id:"scaling-with-keda",level:2},{value:"Walkthrough (AWS EKS)",id:"walkthrough-aws-eks",level:2},{value:"Infrastructure",id:"infrastructure",level:3},{value:"Secrets",id:"secrets",level:3},{value:"Database Migrations",id:"database-migrations",level:3},{value:"Application Deployment",id:"application-deployment",level:3},{value:"Scaling with KEDA",id:"scaling-with-keda-1",level:3},{value:"Cleanup",id:"cleanup",level:3}];function d(e){const s={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components},{Details:n,TabItem:r,Tabs:i}=s;return n||p("Details",!0),r||p("TabItem",!0),i||p("Tabs",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.p,{children:"This guide covers deploying a DBOS application on Kubernetes.\nIt walks through DBOS-specific deployment concepts, then provides a full walkthrough covering infrastructure, secrets, database migrations, application deployment, and autoscaling."}),"\n",(0,t.jsx)(s.p,{children:"The Kubernetes manifests are portable to any conformant cluster."}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"deployment",children:"Deployment"}),"\n",(0,t.jsxs)(s.p,{children:["DBOS is a library \u2014 it does not require any sidecar, operator, or external service besides PostgreSQL.\nPods are stateless and interchangeable and should use a standard ",(0,t.jsx)(s.a,{href:"https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",children:"Deployment"}),"."]}),"\n",(0,t.jsx)(s.h2,{id:"configuration",children:"Configuration"}),"\n",(0,t.jsxs)(s.p,{children:["DBOS configuration contains sensitive values: the ",(0,t.jsx)(s.a,{href:"/explanations/system-tables",children:"system database URL"})," and, if using ",(0,t.jsx)(s.a,{href:"/production/conductor",children:"Conductor"}),", an API key.\nStore these as ",(0,t.jsx)(s.a,{href:"https://kubernetes.io/docs/concepts/configuration/secret/",children:"Kubernetes Secrets"})," and inject them via ",(0,t.jsx)(s.a,{href:"https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables",children:(0,t.jsx)(s.code,{children:"secretKeyRef"})}),".\nFor Git-safe storage, encrypt with ",(0,t.jsx)(s.a,{href:"https://github.com/bitnami-labs/sealed-secrets",children:"Sealed Secrets"}),", ",(0,t.jsx)(s.a,{href:"https://github.com/getsops/sops",children:"SOPS"}),", or a cloud-native secrets manager."]}),"\n",(0,t.jsxs)(s.admonition,{title:"Connecting to DBOS Conductor",type:"info",children:[(0,t.jsxs)(s.p,{children:["If you use ",(0,t.jsx)(s.a,{href:"https://console.dbos.dev/",children:"DBOS managed Conductor"}),", no ",(0,t.jsx)(s.code,{children:"DBOS_CONDUCTOR_URL"})," is needed. The SDK connects automatically.\nIf you ",(0,t.jsx)(s.a,{href:"/production/hosting-conductor",children:"self-host Conductor"}),", set ",(0,t.jsx)(s.code,{children:"DBOS_CONDUCTOR_URL"})," in your application's environment."]}),(0,t.jsxs)(s.p,{children:["When Conductor is in a different cluster, use ",(0,t.jsx)(s.code,{children:"wss://"})," so the WebSocket connection is encrypted. In the same cluster, use ",(0,t.jsx)(s.code,{children:"ws://"}),", as Conductor requires TLS termination at the ingress layer."]})]}),"\n",(0,t.jsx)(s.h2,{id:"database-privilege-separation",children:"Database Privilege Separation"}),"\n",(0,t.jsxs)(s.p,{children:["DBOS applications store workflow state in ",(0,t.jsx)(s.a,{href:"/explanations/system-tables",children:"system tables"}),".\nThese tables must be created before the application can start."]}),"\n",(0,t.jsxs)(s.p,{children:["Run ",(0,t.jsx)(s.code,{children:"dbos migrate"})," (",(0,t.jsx)(s.a,{href:"/python/reference/cli#dbos-migrate",children:"Python"}),", ",(0,t.jsx)(s.a,{href:"/golang/reference/cli",children:"Go"}),") or ",(0,t.jsx)(s.code,{children:"dbos schema"})," (",(0,t.jsx)(s.a,{href:"/typescript/reference/cli#npx-dbos-schema",children:"TypeScript"}),") with an ",(0,t.jsx)(s.strong,{children:"admin"})," role that can create schema and grant permissions, and run the application with a ",(0,t.jsx)(s.strong,{children:"restricted"})," role that can only read/write data. Use the ",(0,t.jsx)(s.code,{children:"--app-role"})," flag to grant the necessary schema permissions to the restricted role."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.code,{children:"dbos migrate"})," works well as a Kubernetes ",(0,t.jsx)(s.a,{href:"https://kubernetes.io/docs/concepts/workloads/controllers/job/",children:"Job"})," that you compose into your CI/CD pipeline."]}),"\n",(0,t.jsx)(s.h2,{id:"availability",children:"Availability"}),"\n",(0,t.jsxs)(s.p,{children:["In addition to ",(0,t.jsx)(s.a,{href:"/production/checklist",children:"general tips"})," for running a DBOS-enabled app in production:"]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Readiness probe"})," \u2014 have the probe wait until DBOS is launched before Kubernetes routes traffic to pods."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Resource limits"})," \u2014 DBOS doesn't add significant CPU or memory overhead, but all DBOS SDKs run background tasks; setting more than 1000m CPU can significantly improve the performance of a busy application."]}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Replicas"})," \u2014 configure more than one replica. Each replica starts an independent DBOS worker that can process scheduled workflows and handle tasks from DBOS queues. Each replica should have a unique executor ID (which is automatically assigned when using ",(0,t.jsx)(s.a,{href:"/production/conductor",children:"DBOS Conductor"}),")"]}),"\n",(0,t.jsx)(s.h2,{id:"upgrading-workflow-code",children:"Upgrading Workflow Code"}),"\n",(0,t.jsx)(s.p,{children:"DBOS workflows can run for weeks or years while the underlying code evolves.\nTwo patterns support this:"}),"\n",(0,t.jsxs)(s.ol,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Application versioning"})," \u2014 DBOS SDKs store a version number alongside each workflow record. You should create a separate Deployment per active version. Point the Service selector at the latest version only, such that new HTTP requests creating DBOS workflows go exclusively to the new Deployment. Old deployments will stay alive and keep executing pending workflows. Once workflows for an old version complete, delete its Deployment. Tools like ",(0,t.jsx)(s.a,{href:"https://flagger.app/",children:"Flagger"})," or ",(0,t.jsx)(s.a,{href:"https://argoproj.github.io/argo-rollouts/",children:"Argo Rollouts"})," can automate this lifecycle."]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Workflow patching"})," \u2014 Keep a single Deployment. Add conditional logic (patches) that detect which code path a recovering workflow should take. See the ",(0,t.jsx)(s.a,{href:"/python/tutorials/upgrading-workflows",children:"workflow patching guide"})," for details."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"scaling-with-keda",children:"Scaling with KEDA"}),"\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.a,{href:"https://keda.sh/",children:"KEDA"})," scales application pods based on external metrics.\nA simple pattern for scaling based on DBOS queue depth:"]}),"\n",(0,t.jsxs)(s.ol,{children:["\n",(0,t.jsxs)(s.li,{children:["The application exposes a ",(0,t.jsx)(s.code,{children:"/metrics/:queueName"})," endpoint returning the current queue depth as JSON."]}),"\n",(0,t.jsxs)(s.li,{children:["KEDA's ",(0,t.jsx)(s.code,{children:"metrics-api"})," trigger polls this endpoint on an interval."]}),"\n",(0,t.jsxs)(s.li,{children:["KEDA computes ",(0,t.jsx)(s.code,{children:"desiredReplicas = ceil(queue_length / targetValue)"}),", where ",(0,t.jsx)(s.code,{children:"targetValue"})," matches the queue's per-worker concurrency."]}),"\n"]}),"\n",(0,t.jsxs)(s.p,{children:["Since the ",(0,t.jsx)(s.code,{children:"metrics-api"})," trigger polls the application itself, ",(0,t.jsx)(s.code,{children:"minReplicaCount"})," must be at least 1 \u2014 KEDA needs a running pod to scrape. For scale-to-zero, use a push-based trigger (e.g., PostgreSQL) or an external metrics endpoint."]}),"\n",(0,t.jsx)(s.hr,{}),"\n",(0,t.jsx)(s.h2,{id:"walkthrough-aws-eks",children:"Walkthrough (AWS EKS)"}),"\n",(0,t.jsx)(i,{groupId:"cloud-provider",children:(0,t.jsxs)(r,{value:"eks",label:"EKS (AWS)",children:[(0,t.jsx)(s.p,{children:"This walkthrough deploys a sample DBOS Go application on EKS with RDS PostgreSQL, Sealed Secrets, database migrations, and KEDA autoscaling."}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"Set environment variables"})}),(0,t.jsx)(s.p,{children:"Set these variables before proceeding \u2014 replace the placeholder values with your own:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"# Your AWS account ID (12-digit number)\nAWS_ACCOUNT_ID=123456789012\n\n# AWS region for all resources\nAWS_REGION=us-west-2\n\n# PostgreSQL admin password (used for the RDS master user)\nPOSTGRES_PASSWORD='choose-a-secure-password'\n\n# Password for the restricted application database role\nAPP_ROLE_PASSWORD='choose-another-secure-password'\n\n# Conductor API key (from the Console after registering your app)\nCONDUCTOR_API_KEY='your-api-key'\n\n# Conductor URL\n# DBOS Cloud: wss://conductor.dbos.dev/\n# Self-hosted (same cluster): ws://conductor.dbos.svc.cluster.local:8090\n# Self-hosted (external): wss://your-conductor-hostname/conductor/\nCONDUCTOR_URL='wss://conductor.dbos.dev/'\n"})})]}),(0,t.jsx)(s.h3,{id:"infrastructure",children:"Infrastructure"}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"CLI tools required on your workstation"})}),(0,t.jsxs)(s.table,{children:[(0,t.jsx)(s.thead,{children:(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.th,{children:"Tool"}),(0,t.jsx)(s.th,{children:"Purpose"}),(0,t.jsx)(s.th,{children:"Install"})]})}),(0,t.jsxs)(s.tbody,{children:[(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.strong,{children:"AWS CLI"})}),(0,t.jsx)(s.td,{children:"AWS account access"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.a,{href:"https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html",children:"Install guide"})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.strong,{children:"eksctl"})}),(0,t.jsx)(s.td,{children:"Create and manage EKS clusters"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.a,{href:"https://eksctl.io/installation/",children:"Install guide"})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.strong,{children:"kubectl"})}),(0,t.jsx)(s.td,{children:"Interact with Kubernetes"}),(0,t.jsxs)(s.td,{children:["Included with eksctl, or ",(0,t.jsx)(s.a,{href:"https://kubernetes.io/docs/tasks/tools/",children:"install separately"})]})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.strong,{children:"Helm"})}),(0,t.jsx)(s.td,{children:"Install cluster add-ons (KEDA, Sealed Secrets)"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.a,{href:"https://helm.sh/docs/intro/install/",children:"Install guide"})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.strong,{children:"kubeseal"})}),(0,t.jsx)(s.td,{children:"Encrypt Kubernetes secrets"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.a,{href:"https://github.com/bitnami-labs/sealed-secrets#kubeseal",children:"Install guide"})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.strong,{children:"Go"})}),(0,t.jsx)(s.td,{children:"Build the DBOS application"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.a,{href:"https://go.dev/doc/install",children:"Install guide"})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.strong,{children:"Docker"})}),(0,t.jsx)(s.td,{children:"Build application container images"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.a,{href:"https://docs.docker.com/get-docker/",children:"Install guide"})})]})]})]}),(0,t.jsx)(s.p,{children:"Verify your AWS credentials are configured:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"aws sts get-caller-identity\n"})})]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"DBOS Conductor"})}),(0,t.jsxs)(s.p,{children:["This walkthrough connects the application to ",(0,t.jsx)(s.a,{href:"/production/conductor",children:"DBOS Conductor"})," for workflow recovery and observability.\nYou can use either ",(0,t.jsx)(s.a,{href:"https://console.dbos.dev/",children:"DBOS Cloud"})," or a ",(0,t.jsx)(s.a,{href:"/production/hosting-conductor-with-kubernetes",children:"self-hosted Conductor"}),".\nYou'll need the ",(0,t.jsx)(s.strong,{children:"Conductor URL"})," and an ",(0,t.jsx)(s.strong,{children:"API key"})," \u2014 both are available from the Console after ",(0,t.jsx)(s.a,{href:"/production/conductor#connecting-to-conductor",children:"registering your application"}),"."]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Create an EKS Cluster"})}),(0,t.jsx)(s.p,{children:"Create a managed EKS cluster with two nodes. This takes approximately 15 minutes."}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"Create EKS cluster"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"eksctl create cluster \\\n  --name dbos-app-cluster \\\n  --region $AWS_REGION \\\n  --version 1.31 \\\n  --nodegroup-name default \\\n  --node-type t3.medium \\\n  --nodes 2 \\\n  --managed\n"})}),(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.code,{children:"eksctl"})," automatically:"]}),(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Creates a VPC with public and private subnets"}),"\n",(0,t.jsxs)(s.li,{children:["Configures the ",(0,t.jsx)(s.a,{href:"https://docs.aws.amazon.com/eks/latest/userguide/managing-vpc-cni.html",children:"Amazon VPC CNI"})]}),"\n",(0,t.jsxs)(s.li,{children:["Sets up your ",(0,t.jsx)(s.code,{children:"~/.kube/config"})," to point at the new cluster"]}),"\n"]}),(0,t.jsx)(s.p,{children:"Once complete, verify the cluster is ready:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl get nodes\n"})}),(0,t.jsxs)(s.p,{children:["You should see two nodes in ",(0,t.jsx)(s.code,{children:"Ready"})," status."]})]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Create a Namespace"})}),(0,t.jsxs)(s.p,{children:["All resources in this walkthrough are deployed to a dedicated ",(0,t.jsx)(s.code,{children:"dbos"})," namespace:"]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl create namespace dbos\n"})}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Provision an RDS PostgreSQL Instance"})}),(0,t.jsxs)(s.p,{children:["Your DBOS application needs a PostgreSQL database for its ",(0,t.jsx)(s.a,{href:"/explanations/system-tables",children:"system tables"}),"."]}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"RDS provisioning commands"})}),(0,t.jsxs)(s.p,{children:["Find the VPC and private subnets that ",(0,t.jsx)(s.code,{children:"eksctl"})," created:"]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'# Get the VPC ID\nVPC_ID=$(aws ec2 describe-vpcs \\\n  --filters "Name=tag:alpha.eksctl.io/cluster-name,Values=dbos-app-cluster" \\\n  --query "Vpcs[0].VpcId" --output text --region $AWS_REGION)\necho "VPC: $VPC_ID"\n\n# Get the private subnets (array for bash/zsh compatibility)\nPRIVATE_SUBNETS=($(aws ec2 describe-subnets \\\n  --filters "Name=vpc-id,Values=$VPC_ID" \\\n             "Name=tag:aws:cloudformation:logical-id,Values=SubnetPrivate*" \\\n  --query "Subnets[*].SubnetId" --output text --region $AWS_REGION))\necho "Private subnets: ${PRIVATE_SUBNETS[@]}"\n'})}),(0,t.jsx)(s.p,{children:"Create a DB subnet group from the private subnets:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'aws rds create-db-subnet-group \\\n  --db-subnet-group-name dbos-app-db \\\n  --db-subnet-group-description "DBOS application RDS subnets" \\\n  --subnet-ids "${PRIVATE_SUBNETS[@]}" \\\n  --region $AWS_REGION\n'})}),(0,t.jsx)(s.p,{children:"Create a security group that allows PostgreSQL access from the EKS nodes:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'# Get the EKS cluster security group\nEKS_SG=$(aws ec2 describe-security-groups \\\n  --filters "Name=vpc-id,Values=$VPC_ID" \\\n            "Name=tag:aws:eks:cluster-name,Values=dbos-app-cluster" \\\n  --query "SecurityGroups[0].GroupId" \\\n  --output text --region $AWS_REGION)\necho "EKS SG: $EKS_SG"\n\n# Create a security group for RDS\nRDS_SG=$(aws ec2 create-security-group \\\n  --group-name dbos-app-rds \\\n  --description "Allow PostgreSQL from EKS nodes" \\\n  --vpc-id $VPC_ID \\\n  --query "GroupId" --output text --region $AWS_REGION)\necho "RDS SG: $RDS_SG"\n\n# Allow inbound PostgreSQL from EKS nodes\naws ec2 authorize-security-group-ingress \\\n  --group-id $RDS_SG \\\n  --protocol tcp --port 5432 \\\n  --source-group $EKS_SG \\\n  --region $AWS_REGION\n'})}),(0,t.jsx)(s.p,{children:"Create the RDS instance:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'aws rds create-db-instance \\\n  --db-instance-identifier dbos-app-pg \\\n  --db-instance-class db.t4g.micro \\\n  --engine postgres \\\n  --engine-version 16 \\\n  --master-username postgres \\\n  --master-user-password "$POSTGRES_PASSWORD" \\\n  --allocated-storage 20 \\\n  --db-subnet-group-name dbos-app-db \\\n  --vpc-security-group-ids $RDS_SG \\\n  --no-publicly-accessible \\\n  --region $AWS_REGION\n'})}),(0,t.jsx)(s.p,{children:"Wait for the instance to become available (this takes a few minutes):"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"aws rds wait db-instance-available \\\n  --db-instance-identifier dbos-app-pg \\\n  --region $AWS_REGION\n"})}),(0,t.jsx)(s.p,{children:"Get the RDS endpoint:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'RDS_ENDPOINT=$(aws rds describe-db-instances \\\n  --db-instance-identifier dbos-app-pg \\\n  --query "DBInstances[0].Endpoint.Address" \\\n  --output text --region $AWS_REGION)\necho "RDS endpoint: $RDS_ENDPOINT"\n'})})]}),(0,t.jsx)(s.p,{children:"Create the database and application role from a pod inside the cluster (since the RDS instance is not publicly accessible):"}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"Create database and role"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'kubectl run pg-setup --restart=Never \\\n  --namespace dbos \\\n  --image=postgres:16 \\\n  --env="PGPASSWORD=$POSTGRES_PASSWORD" \\\n  --command -- bash -c "\n    psql -h $RDS_ENDPOINT -U postgres -c \'CREATE DATABASE dbos_app;\'\n    psql -h $RDS_ENDPOINT -U postgres -c \\"CREATE ROLE dbos_app_role WITH LOGIN PASSWORD \'$APP_ROLE_PASSWORD\';\\"\n  "\n# Wait for the pod to finish, then clean up\nsleep 15 && kubectl logs pg-setup -n dbos && kubectl delete pod pg-setup -n dbos\n'})}),(0,t.jsx)(s.p,{children:"This creates:"}),(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"dbos_app"})," \u2014 the application's system database for workflow state"]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"dbos_app_role"})," \u2014 a restricted role the application uses at runtime (granted permissions by ",(0,t.jsx)(s.code,{children:"dbos migrate"}),")"]}),"\n"]})]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Install Cluster Add-ons"})}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"Helm installs (Sealed Secrets, KEDA)"})}),(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"Sealed Secrets"})," \u2014 encrypt secrets for safe Git storage:"]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"helm repo add sealed-secrets https://bitnami-labs.github.io/sealed-secrets\nhelm install sealed-secrets sealed-secrets/sealed-secrets \\\n  --namespace kube-system\n"})}),(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.strong,{children:"KEDA"})," \u2014 event-driven autoscaling:"]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"helm repo add kedacore https://kedacore.github.io/charts\nhelm repo update\nhelm install keda kedacore/keda \\\n  --namespace keda --create-namespace\n"})}),(0,t.jsx)(s.p,{children:"Verify both add-ons are running:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"# Sealed Secrets controller\nkubectl get pods -n kube-system -l app.kubernetes.io/name=sealed-secrets\n\n# KEDA\nkubectl get pods -n keda\n"})})]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Create ECR Repositories"})}),(0,t.jsx)(s.p,{children:"We push two container images to Amazon ECR \u2014 one for the application and one for the migration job:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"aws ecr create-repository --repository-name dbos-app --region $AWS_REGION\naws ecr create-repository --repository-name dbos-migrate --region $AWS_REGION\n"})}),(0,t.jsxs)(s.p,{children:["Note the repository URIs from the output (e.g., ",(0,t.jsx)(s.code,{children:"${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/dbos-app"}),").\nThe commands below use ",(0,t.jsx)(s.code,{children:"$AWS_ACCOUNT_ID"})," and ",(0,t.jsx)(s.code,{children:"$AWS_REGION"}),", which you set earlier."]}),(0,t.jsx)(s.p,{children:"Authenticate Docker with ECR (tokens expire after 12 hours):"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"aws ecr get-login-password --region $AWS_REGION | \\\n  docker login --username AWS --password-stdin \\\n  ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com\n"})}),(0,t.jsx)(s.h3,{id:"secrets",children:"Secrets"}),(0,t.jsxs)(s.p,{children:["Several components need sensitive credentials.\nWe use ",(0,t.jsx)(s.a,{href:"https://github.com/bitnami-labs/sealed-secrets",children:"Bitnami Sealed Secrets"}),": create a regular Secret, encrypt it with ",(0,t.jsx)(s.code,{children:"kubeseal"}),", and apply the encrypted ",(0,t.jsx)(s.code,{children:"SealedSecret"})," to the cluster.\nThe controller decrypts it in-cluster into a standard Kubernetes Secret that pods can reference.\nThe encrypted form is safe to commit to Git."]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Secrets Inventory"})}),(0,t.jsxs)(s.table,{children:[(0,t.jsx)(s.thead,{children:(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.th,{children:"Secret"}),(0,t.jsx)(s.th,{children:"Keys"}),(0,t.jsx)(s.th,{children:"Used by"})]})}),(0,t.jsxs)(s.tbody,{children:[(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"postgres-admin"})}),(0,t.jsxs)(s.td,{children:[(0,t.jsx)(s.code,{children:"password"}),", ",(0,t.jsx)(s.code,{children:"database-url"})]}),(0,t.jsx)(s.td,{children:"Migration Job \u2014 admin access to create/update DBOS system tables"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"dbos-app-db"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"database-url"})}),(0,t.jsxs)(s.td,{children:["DBOS Application \u2014 restricted access to ",(0,t.jsx)(s.code,{children:"dbos_app"})," database"]})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"conductor-api-key"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"api-key"})}),(0,t.jsx)(s.td,{children:"DBOS Application \u2014 authenticates with Conductor"})]})]})]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Create and Seal Secrets"})}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"kubeseal commands for all 3 secrets"})}),(0,t.jsxs)(s.p,{children:["Create each secret, pipe it through ",(0,t.jsx)(s.code,{children:"kubeseal"}),", and save the encrypted form:"]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'# 1. PostgreSQL admin credentials (used by the migration Job)\nkubectl create secret generic postgres-admin \\\n  --namespace dbos \\\n  --from-literal=password="$POSTGRES_PASSWORD" \\\n  --from-literal=database-url="postgresql://postgres:${POSTGRES_PASSWORD}@${RDS_ENDPOINT}:5432/dbos_app?sslmode=require" \\\n  --dry-run=client -o yaml | \\\n  kubeseal --controller-name=sealed-secrets --controller-namespace=kube-system --format yaml \\\n  > sealed-postgres-admin.yaml\n\n# 2. DBOS application database credentials (restricted role)\nkubectl create secret generic dbos-app-db \\\n  --namespace dbos \\\n  --from-literal=database-url="postgresql://dbos_app_role:${APP_ROLE_PASSWORD}@${RDS_ENDPOINT}:5432/dbos_app?sslmode=require" \\\n  --dry-run=client -o yaml | \\\n  kubeseal --controller-name=sealed-secrets --controller-namespace=kube-system --format yaml \\\n  > sealed-dbos-app-db.yaml\n\n# 3. Conductor API key\nkubectl create secret generic conductor-api-key \\\n  --namespace dbos \\\n  --from-literal=api-key="$CONDUCTOR_API_KEY" \\\n  --dry-run=client -o yaml | \\\n  kubeseal --controller-name=sealed-secrets --controller-namespace=kube-system --format yaml \\\n  > sealed-conductor-api-key.yaml\n'})})]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Apply and Verify"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl apply -f sealed-postgres-admin.yaml\nkubectl apply -f sealed-dbos-app-db.yaml\nkubectl apply -f sealed-conductor-api-key.yaml\n"})}),(0,t.jsx)(s.p,{children:"Verify the controller has decrypted them into regular Kubernetes Secrets:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl get secrets -n dbos\n"})}),(0,t.jsxs)(s.p,{children:["You should see all three secrets with type ",(0,t.jsx)(s.code,{children:"Opaque"}),":"]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"NAME                TYPE     DATA   AGE\nconductor-api-key   Opaque   1      10s\ndbos-app-db         Opaque   1      10s\npostgres-admin      Opaque   2      10s\n"})}),(0,t.jsx)(s.h3,{id:"database-migrations",children:"Database Migrations"}),(0,t.jsxs)(s.p,{children:["DBOS applications store workflow state in ",(0,t.jsx)(s.a,{href:"/explanations/system-tables",children:"system tables"}),".\nThese tables must be created before the application can start.\nWe use a separate Kubernetes Job that runs ",(0,t.jsx)(s.code,{children:"dbos migrate"})," with ",(0,t.jsx)(s.strong,{children:"admin"})," credentials, then the application itself runs with a ",(0,t.jsx)(s.strong,{children:"restricted"})," role that can only read/write data \u2014 not modify schema."]}),(0,t.jsx)(s.p,{children:"This separation follows the principle of least privilege: the application never holds the keys to alter its own schema."}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"Migration image and build"})}),(0,t.jsx)(s.p,{children:"The migration image contains only the DBOS CLI \u2014 it doesn't include your application code."}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-dockerfile",metastring:'title="Dockerfile.migrate"',children:'FROM golang:1.25-alpine AS builder\nRUN CGO_ENABLED=0 GOOS=linux go install github.com/dbos-inc/dbos-transact-golang/cmd/dbos@latest\n\nFROM alpine:latest\nRUN apk --no-cache add ca-certificates\nCOPY --from=builder /go/bin/dbos /usr/local/bin/dbos\nENTRYPOINT ["dbos"]\n'})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"# Set your ECR repository URI\nECR_MIGRATE=${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/dbos-migrate\n\n# Build for linux/amd64\ndocker build --platform linux/amd64 \\\n  -t ${ECR_MIGRATE}:latest \\\n  -f Dockerfile.migrate .\n\n# Push to ECR\ndocker push ${ECR_MIGRATE}:latest\n"})})]}),(0,t.jsxs)(s.p,{children:["The Job runs ",(0,t.jsx)(s.code,{children:"dbos migrate --app-role dbos_app_role"}),", which:"]}),(0,t.jsxs)(s.ol,{children:["\n",(0,t.jsxs)(s.li,{children:["Creates the DBOS system tables in the ",(0,t.jsx)(s.code,{children:"dbos_app"})," database (if they don't exist)"]}),"\n",(0,t.jsx)(s.li,{children:"Applies any pending schema migrations"}),"\n",(0,t.jsxs)(s.li,{children:["Grants the necessary permissions to ",(0,t.jsx)(s.code,{children:"dbos_app_role"})," so the application can read and write workflow state"]}),"\n"]}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"manifests/migrate-job.yaml"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-yaml",children:'apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: dbos-migrate\n  namespace: dbos\nspec:\n  backoffLimit: 3\n  template:\n    spec:\n      restartPolicy: OnFailure\n      containers:\n        - name: migrate\n          image: ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/dbos-migrate:latest\n          args:\n            - "migrate"\n            - "--app-role"\n            - "dbos_app_role"\n          env:\n            - name: DBOS_SYSTEM_DATABASE_URL\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-admin\n                  key: database-url\n'})}),(0,t.jsxs)(s.p,{children:["The ",(0,t.jsx)(s.code,{children:"postgres-admin"})," secret contains the admin connection string, which has the privileges needed to create tables and grant permissions.\nThe ",(0,t.jsx)(s.code,{children:"--app-role"})," flag tells ",(0,t.jsx)(s.code,{children:"dbos migrate"})," to grant the specified role access to the system tables."]})]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Run the Migration"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl apply -f manifests/migrate-job.yaml\n"})}),(0,t.jsx)(s.p,{children:"Wait for the job to complete:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl get jobs -n dbos\n"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"NAME           STATUS     COMPLETIONS   DURATION   AGE\ndbos-migrate   Complete   1/1           8s         30s\n"})}),(0,t.jsx)(s.p,{children:"Check the logs to confirm the migration succeeded:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl logs -n dbos job/dbos-migrate\n"})}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Re-running Migrations"})}),(0,t.jsx)(s.p,{children:"When you deploy a new version of the DBOS SDK that includes schema changes, re-run the migration job.\nSince Kubernetes Job names must be unique, delete the old job first:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl delete job dbos-migrate -n dbos\nkubectl apply -f manifests/migrate-job.yaml\n"})}),(0,t.jsxs)(s.p,{children:["In a CI/CD pipeline, you would typically give each migration job a unique name (e.g., ",(0,t.jsx)(s.code,{children:"dbos-migrate-v2"}),") or use a Helm hook with ",(0,t.jsx)(s.code,{children:"hook-delete-policy: before-hook-creation"}),"."]}),(0,t.jsx)(s.h3,{id:"application-deployment",children:"Application Deployment"}),(0,t.jsx)(s.p,{children:"Build and push the application image to ECR, then apply the application manifest."}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"Dockerfile, manifest, and ECR push"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-dockerfile",metastring:'title="Dockerfile"',children:'FROM golang:1.25-alpine AS builder\nWORKDIR /app\nCOPY go.mod go.sum ./\nRUN go mod download\nCOPY . .\nRUN CGO_ENABLED=0 GOOS=linux go build -o dbos-app .\n\nFROM alpine:latest\nRUN apk --no-cache add ca-certificates\nWORKDIR /app\nCOPY --from=builder /app/dbos-app .\nEXPOSE 8080\nCMD ["./dbos-app"]\n'})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"# Set your ECR repository URI\nECR_REPO=${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/dbos-app\n\n# Build for linux/amd64 (EKS nodes run Linux)\ndocker build --platform linux/amd64 -t ${ECR_REPO}:latest .\n\n# Push to ECR\ndocker push ${ECR_REPO}:latest\n"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-yaml",metastring:'title="manifests/dbos-app.yaml"',children:'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dbos-app\n  namespace: dbos\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: dbos-app\n  template:\n    metadata:\n      labels:\n        app: dbos-app\n    spec:\n      containers:\n        - name: dbos-app\n          image: ${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/dbos-app:latest\n          env:\n            - name: DBOS_SYSTEM_DATABASE_URL\n              valueFrom:\n                secretKeyRef:\n                  name: dbos-app-db\n                  key: database-url\n            - name: DBOS_CONDUCTOR_URL\n              value: "${CONDUCTOR_URL}"\n            - name: DBOS_CONDUCTOR_KEY\n              valueFrom:\n                secretKeyRef:\n                  name: conductor-api-key\n                  key: api-key\n          ports:\n            - containerPort: 8080\n          readinessProbe:\n            httpGet:\n              path: /healthz\n              port: 8080\n            initialDelaySeconds: 5\n            periodSeconds: 10\n          livenessProbe:\n            httpGet:\n              path: /healthz\n              port: 8080\n            initialDelaySeconds: 10\n            periodSeconds: 30\n          resources:\n            requests:\n              cpu: 500m\n              memory: 256Mi\n            limits:\n              cpu: "2"\n              memory: 512Mi\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dbos-app\n  namespace: dbos\nspec:\n  selector:\n    app: dbos-app\n  ports:\n    - port: 8080\n      targetPort: 8080\n'})}),(0,t.jsxs)(s.p,{children:["Replace ",(0,t.jsx)(s.code,{children:"${CONDUCTOR_URL}"})," with the value you set earlier:"]}),(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"DBOS Cloud"}),": ",(0,t.jsx)(s.code,{children:"wss://conductor.dbos.dev/"})]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Self-hosted (same cluster)"}),": ",(0,t.jsx)(s.code,{children:"ws://conductor.dbos.svc.cluster.local:8090"})]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.strong,{children:"Self-hosted (external)"}),": ",(0,t.jsx)(s.code,{children:"wss://<your-conductor-hostname>/conductor/"})]}),"\n"]}),(0,t.jsxs)(s.p,{children:["The database URL and API key are pulled from the Sealed Secrets created in the ",(0,t.jsx)(s.a,{href:"#secrets",children:"Secrets"})," section."]}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"Trusting a self-signed TLS certificate"})}),(0,t.jsxs)(s.p,{children:["If your self-hosted Conductor uses a ",(0,t.jsx)(s.strong,{children:"CA-signed certificate"})," (e.g., from ",(0,t.jsx)(s.a,{href:"https://cert-manager.io/",children:"cert-manager"})," with Let's Encrypt), no extra configuration is needed \u2014 the system CA bundle already trusts it."]}),(0,t.jsxs)(s.p,{children:["If Conductor uses a ",(0,t.jsx)(s.strong,{children:"self-signed certificate"}),", the application must explicitly trust it.\nStore the certificate as a Kubernetes Secret, mount it into an init container that appends it to the system CA bundle, and point the app container at the extended bundle via ",(0,t.jsx)(s.code,{children:"SSL_CERT_FILE"}),":"]}),(0,t.jsxs)(s.ol,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsx)(s.p,{children:"Create a TLS secret from your certificate files:"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl create secret tls dbos-tls \\\n  --cert=tls.crt --key=tls.key --namespace dbos\n"})}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsx)(s.p,{children:"Add an init container and volumes to the Deployment spec:"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-yaml",children:'      initContainers:\n        - name: setup-certs\n          image: alpine:latest\n          command: ["sh", "-c", "cp /etc/ssl/certs/ca-certificates.crt /certs/ca-certificates.crt && cat /tls/tls.crt >> /certs/ca-certificates.crt"]\n          volumeMounts:\n            - { name: tls-cert, mountPath: /tls, readOnly: true }\n            - { name: ca-certs, mountPath: /certs }\n      # ... app container with:\n      #   env:\n      #     - name: SSL_CERT_FILE\n      #       value: "/certs/ca-certificates.crt"\n      #   volumeMounts:\n      #     - { name: ca-certs, mountPath: /certs, readOnly: true }\n      volumes:\n        - name: tls-cert\n          secret:\n            secretName: dbos-tls\n            items:\n              - { key: tls.crt, path: tls.crt }\n        - name: ca-certs\n          emptyDir: {}\n'})}),"\n"]}),"\n"]})]})]}),(0,t.jsx)(s.admonition,{type:"tip",children:(0,t.jsxs)(s.p,{children:["When using DBOS managed Conductor, you don't need to set ",(0,t.jsx)(s.code,{children:"DBOS_CONDUCTOR_URL"})," in the manifest."]})}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Deploy the Application"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl apply -f manifests/dbos-app.yaml\n"})}),(0,t.jsx)(s.p,{children:"Verify the pod is running:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl get pods -n dbos -l app=dbos-app\nkubectl logs -n dbos -l app=dbos-app --tail=20\n"})}),(0,t.jsx)(s.p,{children:"You should see Conductor connection messages in the logs. You can also verify the connection in the Console UI."}),(0,t.jsx)(s.p,{children:"To access the application locally, use port-forwarding:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl port-forward svc/dbos-app -n dbos 8080:8080\n"})}),(0,t.jsx)(s.p,{children:"Then in another terminal:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"curl http://localhost:8080/healthz\n"})}),(0,t.jsx)(s.h3,{id:"scaling-with-keda-1",children:"Scaling with KEDA"}),(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.a,{href:"https://keda.sh/",children:"KEDA"})," (Kubernetes Event-Driven Autoscaling) scales your application pods based on external metrics.\nIn this section, KEDA polls the application's queue-depth endpoint and adjusts the replica count so that your application deployment has enough capacity to absorb load."]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"How the Metrics Endpoint Works"})}),(0,t.jsxs)(s.p,{children:["The sample application exposes ",(0,t.jsx)(s.code,{children:"GET /metrics/:queueName"}),", which returns the number of workflows currently waiting on a queue:"]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'curl http://dbos-app.dbos.svc.cluster.local:8080/metrics/taskQueue\n# {"queue_length": 7}\n'})}),(0,t.jsxs)(s.p,{children:["KEDA uses the ",(0,t.jsx)(s.code,{children:"metrics-api"})," trigger to poll this endpoint and extract ",(0,t.jsx)(s.code,{children:"queue_length"}),".\nIt computes the desired replica count as:"]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"desiredReplicas = ceil(queue_length / targetValue)\n"})}),(0,t.jsxs)(s.p,{children:["With ",(0,t.jsx)(s.code,{children:'targetValue: "2"'})," (matching the queue's ",(0,t.jsx)(s.code,{children:"WithWorkerConcurrency(2)"}),"), each pod handles two concurrent workflows.\nFor example, if 7 workflows are queued, KEDA scales to ",(0,t.jsx)(s.code,{children:"ceil(7 / 2) = 4"})," pods."]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"ScaledObject Manifest"})}),(0,t.jsxs)(n,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("strong",{children:"manifests/keda-scaledobject.yaml"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-yaml",children:'apiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: dbos-app-scaledobject\n  namespace: dbos\nspec:\n  scaleTargetRef:\n    name: dbos-app\n  pollingInterval: 15\n  cooldownPeriod: 60\n  minReplicaCount: 1\n  maxReplicaCount: 10\n  triggers:\n    - type: metrics-api\n      metadata:\n        url: "http://dbos-app.dbos.svc.cluster.local:8080/metrics/taskQueue"\n        valueLocation: "queue_length"\n        targetValue: "2"\n'})}),(0,t.jsxs)(s.table,{children:[(0,t.jsx)(s.thead,{children:(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.th,{children:"Field"}),(0,t.jsx)(s.th,{children:"Value"}),(0,t.jsx)(s.th,{children:"Description"})]})}),(0,t.jsxs)(s.tbody,{children:[(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"scaleTargetRef.name"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"dbos-app"})}),(0,t.jsx)(s.td,{children:"The Deployment to scale"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"pollingInterval"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"15"})}),(0,t.jsx)(s.td,{children:"Seconds between metric checks (default 30)"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"cooldownPeriod"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"60"})}),(0,t.jsx)(s.td,{children:"Seconds to wait after the last trigger activation before scaling down (default 300)"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"minReplicaCount"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"1"})}),(0,t.jsxs)(s.td,{children:["Minimum replicas \u2014 must be \u22651 because the ",(0,t.jsx)(s.code,{children:"metrics-api"})," trigger polls the app itself"]})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"maxReplicaCount"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"10"})}),(0,t.jsx)(s.td,{children:"Upper bound for the replica count"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"url"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"http://dbos-app..."})}),(0,t.jsx)(s.td,{children:"In-cluster URL to the app's queue metrics endpoint"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"valueLocation"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"queue_length"})}),(0,t.jsx)(s.td,{children:"JSON field to extract from the response"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"targetValue"})}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:'"2"'})}),(0,t.jsxs)(s.td,{children:["Desired metric value per replica \u2014 matches ",(0,t.jsx)(s.code,{children:"WithWorkerConcurrency(2)"})]})]})]})]})]}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Apply and Verify"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl apply -f manifests/keda-scaledobject.yaml\n"})}),(0,t.jsx)(s.p,{children:"Verify the ScaledObject is ready:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl get scaledobject -n dbos\n"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"NAME                      SCALETARGETKIND      SCALETARGETNAME   MIN   MAX   TRIGGERS      AUTHENTICATION   READY   ACTIVE   FALLBACK   AGE\ndbos-app-scaledobject     apps/v1.Deployment   dbos-app          1     10    metrics-api                    True    False    False      10s\n"})}),(0,t.jsx)(s.p,{children:"KEDA auto-creates a Horizontal Pod Autoscaler (HPA) under the hood:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl get hpa -n dbos\n"})}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"NAME                               REFERENCE             TARGETS       MINPODS   MAXPODS   REPLICAS   AGE\nkeda-hpa-dbos-app-scaledobject     Deployment/dbos-app   0/2 (avg)     1         10        1          10s\n"})}),(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Test Autoscaling"})}),(0,t.jsxs)(s.p,{children:["With port-forwarding active (",(0,t.jsx)(s.code,{children:"kubectl port-forward svc/dbos-app -n dbos 8080:8080"}),"), enqueue several long-running workflows to build up queue depth.\nEach call enqueues a workflow that sleeps for 60 seconds:"]}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"for i in $(seq 1 10); do\n  curl -s http://localhost:8080/enqueue/60\ndone\n"})}),(0,t.jsx)(s.p,{children:"Watch the pods scale up (in another terminal):"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"kubectl get pods -n dbos -l app=dbos-app -w\n"})}),(0,t.jsx)(s.p,{children:"You should see new pods appear as KEDA detects the growing queue:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{children:"NAME                        READY   STATUS    RESTARTS   AGE\ndbos-app-xxxxxxxxx-aaaaa    1/1     Running   0          5m\ndbos-app-xxxxxxxxx-bbbbb    1/1     Running   0          15s\ndbos-app-xxxxxxxxx-ccccc    1/1     Running   0          15s\ndbos-app-xxxxxxxxx-ddddd    1/1     Running   0          15s\ndbos-app-xxxxxxxxx-eeeee    1/1     Running   0          15s\n"})}),(0,t.jsx)(s.p,{children:"Check the current queue depth:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"curl -s http://localhost:8080/metrics/taskQueue\n"})}),(0,t.jsxs)(s.p,{children:["As workflows complete and the queue drains, the metric drops.\nAfter the ",(0,t.jsx)(s.code,{children:"cooldownPeriod"})," (60 seconds of no trigger activation), KEDA scales back down to ",(0,t.jsx)(s.code,{children:"minReplicaCount"})," (1)."]}),(0,t.jsx)(s.h3,{id:"cleanup",children:"Cleanup"}),(0,t.jsx)(s.p,{children:"To tear down all AWS resources when done:"}),(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'# Delete the EKS cluster (includes VPC, security groups, and node group)\neksctl delete cluster --name dbos-app-cluster --region $AWS_REGION\n\n# Delete the RDS instance\naws rds delete-db-instance --db-instance-identifier dbos-app-pg \\\n  --skip-final-snapshot --region $AWS_REGION\n\n# Delete ECR repositories\naws ecr delete-repository --repository-name dbos-app --force --region $AWS_REGION\naws ecr delete-repository --repository-name dbos-migrate --force --region $AWS_REGION\n\n# Delete the RDS security group\nRDS_SG=$(aws ec2 describe-security-groups \\\n  --filters "Name=group-name,Values=dbos-app-rds" \\\n  --query "SecurityGroups[0].GroupId" --output text --region $AWS_REGION)\naws ec2 delete-security-group --group-id $RDS_SG --region $AWS_REGION\n\n# Delete the DB subnet group\naws rds delete-db-subnet-group --db-subnet-group-name dbos-app-db --region $AWS_REGION\n'})})]})})]})}function h(e={}){const{wrapper:s}={...(0,a.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}function p(e,s){throw new Error("Expected "+(s?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}},8453:(e,s,n)=>{n.d(s,{R:()=>i,x:()=>c});var r=n(6540);const t={},a=r.createContext(t);function i(e){const s=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function c(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),r.createElement(a.Provider,{value:s},e.children)}}}]);