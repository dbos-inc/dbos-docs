"use strict";(self.webpackChunkdbos_docs=self.webpackChunkdbos_docs||[]).push([[8933],{3290:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>f,frontMatter:()=>a,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"typescript/prompting","title":"AI Model Prompting","description":"You may want assistance from an AI model in building a DBOS application.","source":"@site/docs/typescript/prompting.md","sourceDirName":"typescript","slug":"/typescript/prompting","permalink":"/typescript/prompting","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":30,"frontMatter":{"sidebar_position":30,"title":"AI Model Prompting"},"sidebar":"tutorialSidebar","previous":{"title":"Add DBOS To Your App","permalink":"/typescript/integrating-dbos"},"next":{"title":"Workflows","permalink":"/typescript/tutorials/workflow-tutorial"}}');var s=t(4848),r=t(8453);const a={sidebar_position:30,title:"AI Model Prompting"},i=void 0,l={},c=[{value:"How To Use",id:"how-to-use",level:2},{value:"Prompt",id:"prompt",level:2},{value:"Configuring DBOS",id:"configuring-dbos",level:2}];function u(e){const n={a:"a",code:"code",h2:"h2",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"You may want assistance from an AI model in building a DBOS application.\nTo make sure your model has the latest information on how to use DBOS, provide it with this prompt."}),"\n",(0,s.jsx)(n.h2,{id:"how-to-use",children:"How To Use"}),"\n",(0,s.jsx)(n.p,{children:"First, use the click-to-copy button in the top right of the code block to copy the full prompt to your clipboard.\nThen, paste into your AI tool of choice (for example OpenAI's ChatGPT or Anthropic's Claude).\nThis adds the prompt to your AI model's context, giving it up-to-date instructions on how to build an application with DBOS."}),"\n",(0,s.jsx)(n.p,{children:"If you are using an AI-powered IDE, you can add this prompt to your project's context.\nFor example:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Claude Code: Add the prompt, or a link to it, to your CLAUDE.md file."}),"\n",(0,s.jsxs)(n.li,{children:["Cursor: Add the prompt to ",(0,s.jsx)(n.a,{href:"https://docs.cursor.com/context/rules-for-ai",children:"your project rules"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Zed: Copy the prompt to a file in your project, then use the ",(0,s.jsx)(n.a,{href:"https://zed.dev/docs/assistant/commands?highlight=%2Ffile#file",children:(0,s.jsx)(n.code,{children:"/file"})})," command to add the file to your context."]}),"\n",(0,s.jsxs)(n.li,{children:["GitHub Copilot: Create a ",(0,s.jsx)(n.a,{href:"https://docs.github.com/en/copilot/customizing-copilot/adding-repository-custom-instructions-for-github-copilot",children:(0,s.jsx)(n.code,{children:".github/copilot-instructions.md"})})," file in your repository and add the prompt to it."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"prompt",children:"Prompt"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-markdown",children:'# Build Reliable Applications With DBOS\n\n## Guidelines\n\n- Respond in a friendly and concise manner\n- Ask clarifying questions when requirements are ambiguous\n- Generate code in TypeScript using the DBOS library. Make sure to fully type everything.\n- You MUST import all methods and classes used in the code you generate\n- You SHALL keep all code in a single file unless otherwise specified.\n- You MUST await all promises.\n- DBOS does NOT stand for anything.\n\n## Workflow Guidelines\n\nWorkflows provide durable execution so you can write programs that are resilient to any failure.\nWorkflows are comprised of steps, which are ordinary TypeScript functions called with DBOS.runStep().\nWhen using DBOS workflows, you should call any function that performs complex operations or accesses external APIs or services as a step using DBOS.runStep.\n\nIf a workflow is interrupted for any reason (e.g., an executor restarts or crashes), when your program restarts the workflow automatically resumes execution from the last completed step.\n\n- If asked to add DBOS to existing code, you MUST ask which function to make a workflow. Do NOT recommend any changes until they have told you what function to make a workflow. Do NOT make a function a workflow unless SPECIFICALLY requested.\n- When making a function a workflow, you should make all functions it calls steps. Do NOT change the functions in any way.\n- Do NOT make functions steps unless they are DIRECTLY called by a workflow.\n- If the workflow function performs a non-deterministic action, you MUST move that action to its own function and make that function a step. Examples of non-deterministic actions include accessing an external API or service, accessing files on disk, generating a random number, of getting the current time.\n- Do NOT use Promise.all() due to the risks posed by multiple rejections.  Using Promise.allSettled() for parallelism is allowed for single-step promises only.  For any complex parallel execution, you should instead use DBOS.startWorkflow and DBOS queues to achieve the parallelism.\n- DBOS workflows and steps should NOT have side effects in memory outside of their own scope. They can access global variables, but they should NOT create or update global variables or variables outside their scope.\n- Do NOT call any DBOS context method (DBOS.send, DBOS.recv, DBOS.startWorkflow, DBOS.sleep, DBOS.setEvent, DBOS.getEvent) from a step.\n- Do NOT start workflows from inside a step.\n- Do NOT call DBOS.setEvent and DBOS.recv from outside a workflow function.\n- Do NOT use DBOS.getApi, DBOS.postApi, or other DBOS HTTP annotations. These are DEPRECATED. Instead, use Express for HTTP serving by default, unless another web framework is specified.\n\n## DBOS Lifecycle Guidelines\n\nDBOS should be installed and imported from the `@dbos-inc/dbos-sdk` package.\nDue to its internal workflow registry, The DBOS library and DBOS workflows cannot be bundled with JavaScript or TypeScript bundlers (Webpack, Vite, Rollup, esbuild, Parcel, etc.) and must be treated as an external library by these tools.  Configuration for bundlers should be suggested if these tools are in use and cannot be avoided.\n\nDBOS does not support "serverless" frameworks due to its long-running background jobs.  DBOS programs MUST have a starting file (typically \'main.ts\' or \'server.ts\') that creates all objects and workflow functions during startup.\n\nAny DBOS program MUST call DBOS.setConfig and DBOS.launch in its main function, like so.\nYou MUST use this default configuration (changing the name as appropriate) unless otherwise specified.\n\n```javascript\nDBOS.setConfig({\n  "name": "dbos-node-starter",\n  "systemDatabaseUrl": process.env.DBOS_SYSTEM_DATABASE_URL,\n});\nawait DBOS.launch();\n```\n\nHere is an example main function using Express:\n\n```javascript\nimport { DBOS } from "@dbos-inc/dbos-sdk";\n\nasync function main() {\n  DBOS.setConfig({\n    "name": "dbos-node-starter",\n    "systemDatabaseUrl": process.env.DBOS_SYSTEM_DATABASE_URL,\n  });\n  await DBOS.launch();\n  const PORT = 3000;\n  app.listen(PORT, () => {\n    console.log(`\ud83d\ude80 Server is running on http://localhost:${PORT}`);\n  });\n}\n\nmain().catch(console.log);\n```\n\n## Workflow and Steps Examples\n\nSimple example:\n\n\n```javascript\nimport { DBOS } from "@dbos-inc/dbos-sdk";\n\nasync function stepOne() {\n  DBOS.logger.info("Step one completed!");\n}\n\nasync function stepTwo() {\n  DBOS.logger.info("Step two completed!");\n}\n\nasync function exampleFunction() {\n  await DBOS.runStep(() => stepOne());\n  await DBOS.runStep(() => stepTwo());\n}\nconst exampleWorkflow = DBOS.registerWorkflow(exampleFunction);\n\nasync function main() {\n  DBOS.setConfig({\n    "name": "dbos-node-starter",\n    "systemDatabaseUrl": process.env.DBOS_SYSTEM_DATABASE_URL,\n  });\n  await DBOS.launch();\n  await exampleWorkflow();\n  await DBOS.shutdown();\n}\n\nmain().catch(console.log);\n```\n\nExample with Express:\n\n```javascript\nimport { DBOS } from "@dbos-inc/dbos-sdk";\nimport express from "express";\n\nexport const app = express();\napp.use(express.json());\n\nasync function stepOne() {\n  DBOS.logger.info("Step one completed!");\n}\n\nasync function stepTwo() {\n  DBOS.logger.info("Step two completed!");\n}\n\nasync function exampleFunction() {\n  await DBOS.runStep(() => stepOne());\n  await DBOS.runStep(() => stepTwo());\n}\nconst exampleWorkflow = DBOS.registerWorkflow(exampleFunction);\n\napp.get("/", async (req, res) => {\n  await exampleWorkflow();\n  res.send();\n});\n\nasync function main() {\n  DBOS.setConfig({\n    "name": "dbos-node-starter",\n    "systemDatabaseUrl": process.env.DBOS_SYSTEM_DATABASE_URL,\n  });\n  await DBOS.launch();\n  const PORT = 3000;\n  app.listen(PORT, () => {\n    console.log(`\ud83d\ude80 Server is running on http://localhost:${PORT}`);\n  });\n}\n\nmain().catch(console.log);\n```\n\nExample with queues:\n\n```javascript\nimport { DBOS, WorkflowQueue } from "@dbos-inc/dbos-sdk";\nimport express from "express";\n\nexport const app = express();\napp.use(express.json());\n\nconst queue = new WorkflowQueue("example_queue");\n\nasync function taskFunction(n: number) {\n  await DBOS.sleep(5000);\n  DBOS.logger.info(`Task ${n} completed!`)\n}\nconst taskWorkflow = DBOS.registerWorkflow(taskFunction);\n\nasync function queueFunction() {\n  DBOS.logger.info("Enqueueing tasks!")\n  const handles = []\n  for (let i = 0; i < 10; i++) {\n    handles.push(await DBOS.startWorkflow(taskWorkflow, { queueName: queue.name })(i))\n  }\n  const results = []\n  for (const h of handles) {\n    results.push(await h.getResult())\n  }\n  DBOS.logger.info(`Successfully completed ${results.length} tasks`)\n}\nconst queueWorkflow = DBOS.registerWorkflow(queueFunction)\n\napp.get("/", async (req, res) => {\n  await queueWorkflow();\n  res.send();\n});\n\nasync function main() {\n  DBOS.setConfig({\n    "name": "dbos-node-starter",\n    "systemDatabaseUrl": process.env.DBOS_SYSTEM_DATABASE_URL,\n  });\n  await DBOS.launch();\n  const PORT = 3000;\n  app.listen(PORT, () => {\n    console.log(`\ud83d\ude80 Server is running on http://localhost:${PORT}`);\n  });\n}\n\nmain().catch(console.log);\n```\n\n### Scheduled Workflow\n\nYou can schedule DBOS workflows to run exactly once per time interval.\nTo do this, use the the `DBOS.registerScheduled` method or the `DBOS.scheduled` decorator and specify the schedule in crontab syntax.  For example:\n\n- A scheduled workflow MUST specify a crontab schedule.\n- It MUST take in two arguments, scheduled and actual time. Both are Date of when the workflow started.\n\n```typescript\nasync function scheduledFunction(schedTime: Date, startTime: Date) {\n    DBOS.logger.info(`I am a workflow scheduled to run every 30 seconds`);\n}\n\nconst scheduledWorkflow = DBOS.registerWorkflow(scheduledFunction);\nDBOS.registerScheduled(scheduledWorkflow, {crontab: \'*/30 * * * * *\'});\n```\n\nOr using decorators:\n\n```typescript\nclass ScheduledExample{\n  @DBOS.workflow()\n  @DBOS.scheduled({crontab: \'*/30 * * * * *\'})\n  static async scheduledWorkflow(schedTime: Date, startTime: Date) {\n    DBOS.logger.info(`I am a workflow scheduled to run every 30 seconds`);\n  }\n}\n```\n\n## Workflow Documentation:\n\nWorkflows provide **durable execution** so you can write programs that are **resilient to any failure**.\nWorkflows are comprised of steps, which wrap ordinary TypeScript (or JavaScript) functions.\nIf a workflow is interrupted for any reason (e.g., an executor restarts or crashes), when your program restarts the workflow automatically resumes execution from the last completed step.\n\nTo write a workflow, register a TypeScript function with `DBOS.registerWorkflow`.\nThe function\'s inputs and outputs must be serializable to JSON.\nFor example:\n\n```typescript\nasync function stepOne() {\n  DBOS.logger.info("Step one completed!");\n}\n\nasync function stepTwo() {\n  DBOS.logger.info("Step two completed!");\n}\n\nasync function workflowFunction() {\n  await DBOS.runStep(() => stepOne(), {name: "stepOne"});\n  await DBOS.runStep(() => stepTwo(), {name: "stepTwo"});\n}\nconst workflow = DBOS.registerWorkflow(workflowFunction)\n\nawait workflow();\n```\n\nAlternatively, you can register workflows and steps with decorators:\n\n```typescript\nexport class Example {\n  @DBOS.step()\n  static async stepOne() {\n    DBOS.logger.info("Step one completed!");\n  }\n\n  @DBOS.step()\n  static async stepTwo() {\n    DBOS.logger.info("Step two completed!");\n  }\n\n  // Call steps from workflows\n  @DBOS.workflow()\n  static async exampleWorkflow() {\n    await Toolbox.stepOne();\n    await Toolbox.stepTwo();\n  }\n}\n\nawait Example.exampleWorkflow();\n```\n\n## Starting Workflows In The Background\n\nOne common use-case for workflows is building reliable background tasks that keep running even when your program is interrupted, restarted, or crashes.\nYou can use `DBOS.startWorkflow` to start a workflow in the background.\nIf you start a workflow this way, it returns a workflow handle, from which you can access information about the workflow or wait for it to complete and retrieve its result.\n\nHere\'s an example:\n\n```javascript\nclass Example {\n    @DBOS.workflow()\n    static async exampleWorkflow(var1: string, var2: string) {\n        return var1 + var2;\n    }\n}\n\nasync function main() {\n    // Start exampleWorkflow in the background\n    const handle = await DBOS.startWorkflow(Example).exampleWorkflow("one", "two");\n    // Wait for the workflow to complete and return its results\n    const result = await handle.getResult();\n}\n```\n\nAfter starting a workflow in the background, you can use `DBOS.retrieveWorkflow` to retrieve a workflow\'s handle from its ID.\nYou can also retrieve a workflow\'s handle from outside of your DBOS application with \'DBOSClient.retrieveWorkflow`.\n\nIf you need to run many workflows in the background and manage their concurrency or flow control, you can also use DBOS queues.\n\n## Workflow IDs and Idempotency\n\nEvery time you execute a workflow, that execution is assigned a unique ID, by default a UUID.\nYou can access this ID through the `DBOS.workflowID` context variable.\nWorkflow IDs are useful for communicating with workflows and developing interactive workflows.\n\nYou can set the workflow ID of a workflow as an argument to `DBOS.startWorkflow()`.\nWorkflow IDs must be **globally unique** for your application.\nAn assigned workflow ID acts as an idempotency key: if a workflow is called multiple times with the same ID, it executes only once.\nThis is useful if your operations have side effects like making a payment or sending an email.\nWorkflow IDs are also useful for communicating with workflows and developing interactive workflows - see Communicating with Workflows for more details.\n\nFor example:\n\n```javascript\nclass Example {\n    @DBOS.workflow()\n    static async exampleWorkflow(var1: string, var2: string) {\n        // ...\n    }\n}\n\nasync function main() {\n    const myID: string = ...\n    const handle = await DBOS.startWorkflow(Example, {workflowID: myID}).exampleWorkflow("one", "two");\n    const result = await handle.getResult();\n}\n```\n\n## Determinism\n\nWorkflows are in most respects normal TypeScript functions.\nThey can have loops, branches, conditionals, and so on.\nHowever, a workflow function must be **deterministic**: if called multiple times with the same inputs, it should invoke the same steps with the same inputs in the same order (given the same return values from those steps).\nIf you need to perform a non-deterministic operation like accessing the database, calling a third-party API, generating a random number, or getting the local time, you shouldn\'t do it directly in a workflow function.\nInstead, you should do all database operations in transactions and all other non-deterministic operations in steps.\n\nFor example, **don\'t do this**:\n\n```javascript\nclass Example {\n    @DBOS.workflow()\n    static async exampleWorkflow() {\n        // Don\'t make an HTTP request in a workflow function\n        const body = await fetch("https://example.com").then(r => r.text()); \n        await Example.exampleTransaction(body);\n    }\n}\n```\n\nInstead, do this:\n```javascript\nclass Example {\n    @DBOS.workflow()\n    static async exampleWorkflow() {\n        // Don\'t make an HTTP request in a workflow function\n        const body = await DBOS.runStep(\n          async ()=>{return await fetch("https://example.com").then(r => r.text())},\n          {name: "fetchBody"}\n        );\n        await Example.exampleTransaction(body);\n    }\n}\n```\n\nOr this:\n```javascript\nclass Example {\n    @DBOS.step()\n    static async fetchBody() {\n      // Instead, make HTTP requests in steps\n      return await fetch("https://example.com").then(r => r.text());\n    }\n\n    @DBOS.workflow()\n    static async exampleWorkflow() {\n        const body = await Example.fetchBody();\n        await Example.exampleTransaction(body);\n    }\n}\n```\n\n### Running Steps In Parallel\nInitiating several concurrent steps in a workflow, followed by awaiting them with `Promise.allSettled`, is valid as long as the steps are started in a deterministic order.  For example the following is allowed:\n```typescript\nconst results = await Promise.allSettled([\n  step1("arg1"),\n  step2("arg2"),\n  step3("arg3"),\n  step4("arg4"),\n])\n```\nThis is allowed because each step is started in a well-defined sequence before awaiting.\n\nBy contrast, the following is not allowed:\n```typescript\nconst results = await Promise.allSettled([\n  async () => { await step1("arg1"); await step2("arg3"); },\n  async () => { await step3("arg2"); await step4("arg4"); },\n]);\n```\nHere, `step2` and `step4` may be started in either order since their execution depends on the relative time taken by `step1` and `step3`.\n\nIf you need to run sequences of operations concurrently, start child workflows with `startWorkflow` and await the results from their `WorkflowHandle`s.\n\nAvoid using `Promise.all` because of how it handles errors and rejections.  When any promise rejects, `Promise.all` immediately fails, leaving the other promises unresolved.  If one of those later throws an unhandled exception, it can crash your Node.js process.  Instead, prefer `Promise.allSettled`, which safely waits for all promises to complete and reports their outcomes.\n\n## Workflow Timeouts\n\nYou can set a timeout for a workflow by passing a `timeoutMS` argument to `DBOS.startWorkflow`.\nWhen the timeout expires, the workflow **and all its children** are cancelled.\nCancelling a workflow sets its status to `CANCELLED` and preempts its execution at the beginning of its next step.\n\nTimeouts are **start-to-completion**: a workflow\'s timeout does not begin until the workflow starts execution.\nAlso, timeouts are **durable**: they are stored in the database and persist across restarts, so workflows can have very long timeouts.\n\nExample syntax:\n\n```javascript\nasync function taskFunction(task) {\n    // ...\n}\nconst taskWorkflow = DBOS.registerWorkflow(taskFunction);\n\nasync function main() {\n  const task = ...\n  const timeout = ... // Timeout in milliseconds\n  const handle = await DBOS.startWorkflow(taskWorkflow, {timeoutMS: timeout})(task);\n}\n```\n\n## Durable Sleep\n\nYou can use `DBOS.sleep()` to put your workflow to sleep for any period of time.\nThis sleep is **durable**&mdash;DBOS saves the wakeup time in the database so that even if the workflow is interrupted and restarted multiple times while sleeping, it still wakes up on schedule.\n\nSleeping is useful for scheduling a workflow to run in the future (even days, weeks, or months from now).\nFor example:\n\n```javascript\n@DBOS.workflow()\nstatic async exampleWorkflow(timeToSleep, task) {\n    await DBOS.sleep(timeToSleep);\n    await runTask(task);\n}\n```\n\n## Debouncing Workflows\n\nYou can create a `Debouncer` to debounce your workflows.\nDebouncing delays workflow execution until some time has passed since the workflow has last been called.\nThis is useful for preventing wasted work when a workflow may be triggered multiple times in quick succession.\nFor example, if a user is editing an input field, you can debounce their changes to execute a processing workflow only after they haven\'t edited the field for some time:\n\n### Debouncer\n\n```typescript\nnew Debouncer<Args extends unknown[], Return>(\n  params: DebouncerConfig<Args, Return>\n)\n```\n\n```typescript\ninterface DebouncerConfig<Args extends unknown[], Return> {\n  workflow: (...args: Args) => Promise<Return>;\n  startWorkflowParams?: StartWorkflowParams;\n  debounceTimeoutMs?: number;\n}\n```\n\n**Parameters:**\n- **workflow**: The workflow to debounce. Note that workflows from configured instances cannot be debounced.\n- **startWorkflowParams**: Optional workflow parameters, as in `startWorkflow`. Applied to all workflows started from this debouncer.\n- **debounceTimeoutMs**: After this time elapses since the first time a workflow is submitted from this debouncer, the workflow is started regardless of the debounce period.\n\n### debouncer.debounce\n\n```typescript\ndebouncer.debounce(\n  debounceKey: string,\n  debouncePeriodMs: number,\n  ...args: Args\n): Promise<WorkflowHandle<Return>>\n```\n\nSubmit a workflow for execution but delay it by `debouncePeriodMs`.\nReturns a handle to the workflow.\nThe workflow may be debounced again, which further delays its execution (up to `debounceTimeoutMs`).\nWhen the workflow eventually executes, it uses the **last** set of inputs passed into `debounce`.\nAfter the workflow begins execution, the next call to `debounce` starts the debouncing process again for a new workflow execution.\n\n**Parameters:**\n- **debounceKey**: A key used to group workflow executions that will be debounced together. For example, if the debounce key is set to customer ID, each customer\'s workflows would be debounced separately.\n- **debouncePeriodMs**: Delay this workflow\'s execution by this period in milliseconds.\n- **...args**: Variadic workflow arguments.\n\n**Example Syntax**:\n\n```typescript\nasync function processInput(userInput: string) {\n  ...\n}\nconst processInputWorkflow = DBOS.registerWorkflow(processInput);\n\n// Each time a user submits a new input, debounce the processInput workflow.\n// The workflow will wait until 60 seconds after the user stops submitting new inputs,\n// then process the last input submitted.\nconst debouncer = new Debouncer({\n  workflow: processInputWorkflow,\n});\n\nasync function onUserInputSubmit(userId: string, userInput: string) {\n  const debounceKey = userId;\n  const debouncePeriodMs = 60000; // 60 seconds\n  await debouncer.debounce(debounceKey, debouncePeriodMs, userInput);\n}\n```\n\n## Workflow Versioning and Recovery\n\nBecause DBOS recovers workflows by re-executing them using information saved in the database, a workflow cannot safely be recovered if its code has changed since the workflow was started.\nTo guard against this, DBOS _versions_ applications and their workflows.\nWhen DBOS is launched, it computes an application version from a hash of the source code of its workflows (this can be overridden through the `applicationVersion`) configuration parameter.\nAll workflows are tagged with the application version on which they started.\n\nWhen DBOS tries to recover workflows, it only recovers workflows whose version matches the current application version.\nThis prevents unsafe recovery of workflows that depend on different code.\nYou cannot change the version of a workflow, but you can use `DBOS.forkWorkflow` to restart a workflow from a specific step on a specific code version.\n\n\n## Workflow Communication\n\nDBOS provides a few different ways to communicate with your workflows.\nYou can:\n\n- Send messages to workflows\n- Publish events from workflows for clients to read\n- Stream values from workflows to clients\n\n\n## Workflow Messaging and Notifications\nYou can send messages to a specific workflow.\nThis is useful for signaling a workflow or sending notifications to it while it\'s running.\n\n<img src={require(\'@site/static/img/workflow-communication/workflow-messages.png\').default} alt="DBOS Steps" width="750" className="custom-img"/>\n\n### Send\n\n```typescript\nDBOS.send<T>(destinationID: string, message: T, topic?: string): Promise<void>;\n```\n\nYou can call `DBOS.send()` to send a message to a workflow.\nMessages can optionally be associated with a topic and are queued on the receiver per topic.\n\nYou can also call `send` from outside of your DBOS application with the DBOS Client.\n\n### Recv\n\n```typescript\nDBOS.recv<T>(topic?: string, timeoutSeconds?: number): Promise<T | null>\n```\n\nWorkflows can call `DBOS.recv()` to receive messages sent to them, optionally for a particular topic.\nEach call to `recv()` waits for and consumes the next message to arrive in the queue for the specified topic, returning `null` if the wait times out.\nIf the topic is not specified, this method only receives messages sent without a topic.\n\n### Messages Example\n\nMessages are especially useful for sending notifications to a workflow.\nFor example, in the e-commerce demo, the checkout workflow, after redirecting customers to a secure payments service, must wait for a notification from that service that the payment has finished processing.\n\nTo wait for this notification, the payments workflow uses `recv()`, executing failure-handling code if the notification doesn\'t arrive in time:\n\n```javascript\n@DBOS.workflow()\nstatic async checkoutWorkflow(...): Promise<void> {\n  ...\n  const notification = await DBOS.recv<string>(PAYMENT_STATUS, timeout);\n  if (notification) {\n      ... // Handle the notification.\n  } else {\n      ... // Handle a timeout.\n  }\n}\n```\n\nA webhook waits for the payment processor to send the notification, then uses `send()` to forward it to the workflow:\n\n```javascript\nstatic async paymentWebhook(): Promise<void> {\n  const notificationMessage = ... // Parse the notification.\n  const workflowID = ... // Retrieve the workflow ID from notification metadata.\n  await DBOS.send(workflowID, notificationMessage, PAYMENT_STATUS);\n}\n```\n\n### Reliability Guarantees\n\nAll messages are persisted to the database, so if `send` completes successfully, the destination workflow is guaranteed to be able to `recv` it.\nIf you\'re sending a message from a workflow, DBOS guarantees exactly-once delivery.\nIf you\'re sending a message from normal TypeScript code, you can specify an idempotency key for `send` to guarantee exactly-once delivery.\n\n## Workflow Events\n\nWorkflows can publish _events_, which are key-value pairs associated with the workflow.\nThey are useful for publishing information about the status of a workflow or to send a result to clients while the workflow is running.\n\n<img src={require(\'@site/static/img/workflow-communication/workflow-events.png\').default} alt="DBOS Steps" width="750" className="custom-img"/>\n\n### setEvent\n\n```typescript\nDBOS.setEvent<T>(key: string, value: T): Promise<void>\n```\n\nAny workflow can call `DBOS.setEvent` to publish a key-value pair, or update its value if has already been published.\n\n### getEvent\n\n```typescript\nDBOS.getEvent<T>(workflowID: string, key: string, timeoutSeconds?: number): Promise<T | null>\n```\n\nYou can call `DBOS.getEvent` to retrieve the value published by a particular workflow ID for a particular key.\nIf the event does not yet exist, this call waits for it to be published, returning `null` if the wait times out.\n\nYou can also call `getEvent` from outside of your DBOS application with DBOS Client.\n\n### Events Example\n\nEvents are especially useful for writing interactive workflows that communicate information to their caller.\nFor example, in the e-commerce demo, the checkout workflow, after validating an order, directs the customer to a secure payments service to handle credit card processing.\nTo communicate the payments URL to the customer, it uses events.\n\nThe checkout workflow emits the payments URL using `setEvent()`:\n\n```javascript\n@DBOS.workflow()\nstatic async checkoutWorkflow(...): Promise<void> {\n  ...\n  const paymentsURL = ...\n  await DBOS.setEvent(PAYMENT_URL, paymentsURL);\n  ... \n}\n```\n\nThe HTTP handler that originally started the workflow uses `getEvent()` to await this URL, then redirects the customer to it:\n\n```javascript\nstatic async webCheckout(...): Promise<void> {\n  const handle = await DBOS.startWorkflow(Shop).checkoutWorkflow(...);\n  const url = await DBOS.getEvent<string>(handle.workflowID, PAYMENT_URL);\n  if (url === null) {\n    DBOS.koaContext.redirect(`${origin}/checkout/cancel`);\n  } else {\n    DBOS.koaContext.redirect(url);\n  }\n}\n```\n\n### Reliability Guarantees\n\nAll events are persisted to the database, so the latest version of an event is always retrievable.\nAdditionally, if `getEvent` is called in a workflow, the retrieved value is persisted in the database so workflow recovery can use that value, even if the event is later updated.\n\n## Workflow Streaming\n\nWorkflows can stream data in real time to clients.\nThis is useful for streaming results from a long-running workflow or LLM call or for monitoring or progress reporting.\n\n<img src={require(\'@site/static/img/workflow-communication/workflow-streams.png\').default} alt="DBOS Steps" width="750" className="custom-img"/>\n\n### Writing to Streams\n\n```typescript\nDBOS.writeStream<T>(key: string, value: T): Promise<void>\n```\n\nYou can write values to a stream from a workflow or its steps using `DBOS.writeStream`.\nA workflow may have any number of streams, each identified by a unique key.\n\nWhen you are done writing to a stream, you should close it with `DBOS.closeStream`.\nOtherwise, streams are automatically closed when the workflow terminates.\n\n```typescript\nDBOS.closeStream(key: string): Promise<void>\n```\n\nDBOS streams are immutable and append-only.\nWrites to a stream from a workflow happen exactly-once.\nWrites to a stream from a step happen at-least-once; if a step fails and is retried, it may write to the stream multiple times.\nReaders will see all values written to the stream from all tries of the step in the order in which they were written.\n\n**Example syntax:**\n\n```typescript\nasync function producerWorkflowFunction() {\n  await DBOS.writeStream("example_key", { step: 1, data: "value1" });\n  await DBOS.writeStream("example_key", { step: 2, data: "value2" });\n  await DBOS.closeStream("example_key"); // Signal completion\n}\n\nconst producerWorkflow = DBOS.registerWorkflow(producerWorkflowFunction);\n```\n\n### Reading from Streams\n\n```typescript\nDBOS.readStream<T>(workflowID: string, key: string): AsyncGenerator<T, void, unknown>\n```\n\nYou can read values from a stream from anywhere using `DBOS.readStream`.\nThis function reads values from a stream identified by a workflow ID and key, yielding each value in order until the stream is closed or the workflow terminates.\n\nYou can also read from a stream from outside a DBOS application with a DBOS Client.\n\n**Example syntax:**\n\n```typescript\nfor await (const value of DBOS.readStream(workflowID, "example_key")) {\n  console.log(`Received: ${JSON.stringify(value)}`);\n}\n```\n\n## Steps\n\n\nWhen using DBOS workflows, you should call any function that performs complex operations or accesses external APIs or services as a _step_.\nIf a workflow is interrupted, upon restart it automatically resumes execution from the **last completed step**.\n\nYou can use `DBOS.runStep` to call a function as a step.  For a function to be used as a step, it should have a return value that can be serialized as JSON, and should not have non-durable side effects. ALWAYS call steps this way unless otherwise specify.\n\n```javascript\nasync function generateRandomNumber() {\n  return Math.random();\n}\n\nasync function workflowFunction() {\n  const randomNumber = await DBOS.runStep(() => generateRandomNumber(), {name: "generateRandomNumber"});\n}\nconst workflow = DBOS.registerWorkflow(workflowFunction)\n```\n\nAlternatively, you can register a function as a step using `DBOS.registerStep`:\nNEVER do this unless specifically asked, ALWAYS use DBOS.runStep instead.\n\n```javascript\nasync function generateRandomNumber() {\n  return Math.random();\n}\nconst randomStep = DBOS.registerStep(generateRandomNumber);\n\nasync function workflowFunction() {\n  const randomNumber = await randomStep();\n}\nconst workflow = DBOS.registerWorkflow(workflowFunction)\n```\n\nOr use the `@DBOS.step()` decorator:\nNEVER do this unless specifically asked, ALWAYS use DBOS.runStep instead.\n\n```typescript\nexport class Example {\n  @DBOS.step()\n  static async generateRandomNumber() {\n    return Math.random();\n  }\n\n  @DBOS.workflow()\n  static async exampleWorkflow() {\n    await Example.generateRandomNumber();\n  }\n}\n```\n\n### Configurable Retries\n\nYou can optionally configure a step to automatically retry any exception a set number of times with exponential backoff.\nThis is useful for automatically handling transient failures, like making requests to unreliable APIs.\nRetries are configurable through arguments to the step decorator:\n\n```typescript\nexport interface StepConfig {\n  retriesAllowed?: boolean; // Should failures be retried? (default false)\n  intervalSeconds?: number; // Seconds to wait before the first retry attempt (default 1).\n  maxAttempts?: number;     // Maximum number of retry attempts (default 3). If errors occur more times than this, throw an exception.\n  backoffRate?: number;     // Multiplier by which the retry interval increases after a retry attempt (default 2).\n}\n```\n\nFor example, let\'s configure this step to retry exceptions (such as if `example.com` is temporarily down) up to 10 times:\n\n```javascript\nasync function fetchFunction() {\n    return await fetch("https://example.com").then(r => r.text());\n}\n\nasync function workflowFunction() {\n    const randomNumber = await DBOS.runStep(() => fetchFunction(), {\n        name: "fetchFunction",\n        retriesAllowed: true,\n        maxAttempts: 10\n    });\n}\n```\n\nOr if registering the step:\n\n```javascript\nasync function fetchFunction() {\n    return await fetch("https://example.com").then(r => r.text());\n}\nconst fetchStep = DBOS.registerStep(fetchFunction, {\n    retriesAllowed: true,\n    maxAttempts: 10\n});\n```\n\nOr if using decorators:\n\n```javascript\n@DBOS.step({retriesAllowed: true, maxAttempts: 10})\nstatic async exampleStep() {\n  return await fetch("https://example.com").then(r => r.text());\n}\n```\n## Queues\n\nYou can use queues to run many workflows at once with managed concurrency.\nQueues provide _flow control_, letting you manage how many workflows run at once or how often workflows are started.\n\nTo create a queue, specify its name:\n\n```javascript\nimport { DBOS, WorkflowQueue } from "@dbos-inc/dbos-sdk";\n\nconst queue = new WorkflowQueue("example_queue");\n```\n\nYou can then enqueue any workflow by passing the queue as an argument to `DBOS.startWorkflow`.\nEnqueuing a function submits it for execution and returns a handle to it.\nQueued tasks are started in first-in, first-out (FIFO) order.\n\n```javascript\nconst queue = new WorkflowQueue("example_queue");\n\nclass Tasks {\n  @DBOS.workflow()\n  static async processTask(task) {\n    // ...\n  }\n}\n\nasync function main() {\n  const task = ...\n  const handle = await DBOS.startWorkflow(Tasks, {queueName: queue.name}).processTask(task)\n}\n```\n\n### Queue Example\n\nHere\'s an example of a workflow using a queue to process tasks in parallel:\n\n```javascript\nimport { DBOS, WorkflowQueue } from "@dbos-inc/dbos-sdk";\n\nconst queue = new WorkflowQueue("example_queue");\n\nasync function taskFunction(task) {\n    // ...\n}\nconst taskWorkflow = DBOS.registerWorkflow(taskFunction, {"name": "taskWorkflow"});\n\nasync function queueFunction(tasks) {\n  const handles = []\n  \n  // Enqueue each task so all tasks are processed concurrently.\n  for (const task of tasks) {\n    handles.push(await DBOS.startWorkflow(taskWorkflow, { queueName: queue.name })(task))\n  }\n\n  // Wait for each task to complete and retrieve its result.\n  // Return the results of all tasks.\n  const results = []\n  for (const h of handles) {\n    results.push(await h.getResult())\n  }\n  return results\n}\nconst queueWorkflow = DBOS.registerWorkflow(queueFunction, {"name": "queueWorkflow"})\n```\n\n### Enqueueing from Another Application\n\nOften, you want to enqueue a workflow from outside your DBOS application.\nFor example, let\'s say you have an API server and a data processing service.\nYou\'re using DBOS to build a durable data pipeline in the data processing service.\nWhen the API server receives a request, it should enqueue the data pipeline for execution on the data processing service.\n\nYou can use the DBOS Client to enqueue workflows from outside your DBOS application by connecting directly to your DBOS application\'s system database.\nSince the DBOS Client is designed to be used from outside your DBOS application, workflow and queue metadata must be specified explicitly.\n\nFor example, this code enqueues the `dataPipeline` workflow on the `pipelineQueue` queue with `task` as an argument.\n\n```ts\nimport { DBOSClient } from "@dbos-inc/dbos-sdk";\n\nconst client = await DBOSClient.create({systemDatabaseUrl: process.env.DBOS_SYSTEM_DATABASE_URL});\n\ntype ProcessTask = typeof Tasks.processTask;\nawait client.enqueue<ProcessTask>(\n    {\n        workflowName: \'dataPipeline\',\n        queueName: \'pipelineQueue\',\n    },\n    task);\n```\n\n### Managing Concurrency\n\nYou can control how many workflows from a queue run simultaneously by configuring concurrency limits.\nThis helps prevent resource exhaustion when workflows consume significant memory or processing power.\n\n#### Worker Concurrency\n\nWorker concurrency sets the maximum number of workflows from a queue that can run concurrently on a single DBOS process.\nThis is particularly useful for resource-intensive workflows to avoid exhausting the resources of any process.\nFor example, this queue has a worker concurrency of 5, so each process will run at most 5 workflows from this queue simultaneously:\n```javascript\nimport { DBOS, WorkflowQueue } from "@dbos-inc/dbos-sdk";\n\nconst queue = new WorkflowQueue("example_queue", { workerConcurrency: 5 });\n```\n\n#### Global Concurrency\n\nGlobal concurrency limits the total number of workflows from a queue that can run concurrently across all DBOS processes in your application.\nFor example, this queue will have a maximum of 10 workflows running simultaneously across your entire application.\n\n:::warning\nWorker concurrency limits are recommended for most use cases.\nTake care when using a global concurrency limit as any `PENDING` workflow on the queue counts toward the limit, including workflows from previous application versions\n:::\n\n```javascript\nimport { DBOS, WorkflowQueue } from "@dbos-inc/dbos-sdk";\n\nconst queue = new WorkflowQueue("example_queue", { concurrency: 10 });\n```\n\n#### In-Order Processing\n\nYou can use a queue with `concurrency=1` to guarantee sequential, in-order processing of events.\nOnly a single event will be processed at a time.\nFor example, this app processes events sequentially in the order of their arrival:\n\n```javascript\nimport { DBOS, WorkflowQueue } from "@dbos-inc/dbos-sdk";\nimport express from "express";\n\nconst serialQueue = new WorkflowQueue("in_order_queue", { concurrency: 1 });\nconst app = express();\n\nclass Tasks {\n  @DBOS.workflow()\n  static async processTask(task){\n    // ... process task\n  }\n}\n\napp.get("/events/:event", async (req, res) => {\n  await DBOS.startWorkflow(Tasks, {queueName: serialQueue.name}).processTask(req.params);\n  await res.send("Workflow Started!");\n});\n\n// Launch DBOS and start the server\nasync function main() {\n  await DBOS.launch();\n  app.listen(3000, () => {});\n}\n\nmain().catch(console.log);\n```\n\n\n### Rate Limiting\n\nYou can set _rate limits_ for a queue, limiting the number of functions that it can start in a given period.\nRate limits are global across all DBOS processes using this queue.\nFor example, this queue has a limit of 50 with a period of 30 seconds, so it may not start more than 50 functions in 30 seconds:\n\n```javascript\nconst queue = new WorkflowQueue("example_queue", { rateLimit: { limitPerPeriod: 50, periodSec: 30 } });\n```\n\nRate limits are especially useful when working with a rate-limited API, such as many LLM APIs.\n\n### Setting Timeouts\n\nYou can set a timeout for an enqueued workflow by passing a `timeoutMS` argument to `DBOS.startWorkflow`.\nWhen the timeout expires, the workflow **and all its children** are cancelled.\nCancelling a workflow sets its status to `CANCELLED` and preempts its execution at the beginning of its next step.\n\nTimeouts are **start-to-completion**: a workflow\'s timeout does not begin until the workflow is dequeued and starts execution.\nAlso, timeouts are **durable**: they are stored in the database and persist across restarts, so workflows can have very long timeouts.\n\nExample syntax:\n\n```javascript\nconst queue = new WorkflowQueue("example_queue");\n\nasync function taskFunction(task) {\n    // ...\n}\nconst taskWorkflow = DBOS.registerWorkflow(taskFunction, {"name": "taskWorkflow"});\n\nasync function main() {\n  const task = ...\n  const timeout = ... // Timeout in milliseconds\n  const handle = await DBOS.startWorkflow(taskWorkflow, {queueName: queue.name, timeoutMS: timeout})(task);\n}\n```\n\n### Partitioning Queues\n\nYou can **partition** queues to distribute work across dynamically created queue partitions.\nWhen you enqueue a workflow on a partitioned queue, you must supply a queue partition key.\nPartitioned queues dequeue workflows and apply flow control limits for individual partitions, not for the entire queue.\nEssentially, you can think of each partition as a "subqueue" you dynamically create by enqueueing a workflow with a partition key.\n\nFor example, suppose you want your users to each be able to run at most one task at a time.\nYou can do this with a partitioned queue with a maximum concurrency limit of 1 where the partition key is user ID.\n\n**Example Syntax**\n\n```ts\nconst queue = new WorkflowQueue("example_queue", { partitionQueue: true, concurrency: 1 });\n\nasync function onUserTaskSubmission(userID: string, task: Task) {\n    // Partition the task queue by user ID. As the queue has a\n    // maximum concurrency of 1, this means that at most one\n    // task can run at once per user (but tasks from different\n    // users can run concurrently).\n    await DBOS.startWorkflow(taskWorkflow, {queueName: queue.name, enqueueOptions: {queuePartitionKey: userID}})(task);\n}\n```\n\n### Deduplication\n\nYou can set a deduplication ID for an enqueued workflow as an argument to `DBOS.startWorkflow`.\nAt any given time, only one workflow with a specific deduplication ID can be enqueued in the specified queue.\nIf a workflow with a deduplication ID is currently enqueued or actively executing (status `ENQUEUED` or `PENDING`), subsequent workflow enqueue attempt with the same deduplication ID in the same queue will raise a `DBOSQueueDuplicatedError` exception.\n\nFor example, this is useful if you only want to have one workflow active at a time per user&mdash;set the deduplication ID to the user\'s ID.\n\nExample syntax:\n\n```javascript\nconst queue = new WorkflowQueue("example_queue");\n\nasync function taskFunction(task) {\n    // ...\n}\nconst taskWorkflow = DBOS.registerWorkflow(taskFunction, {"name": "taskWorkflow"});\n\nasync function main() {\n  const task = ...\n  const dedup: string = ...\n  try {\n    const handle = await DBOS.startWorkflow(taskWorkflow, {queueName: queue.name, enqueueOptions: {deduplicationID: dedup}})(task);\n  } catch (e) {\n    // Handle DBOSQueueDuplicatedError\n  }\n}\n```\n\n### Priority\n\nYou can set a priority for an enqueued workflow as an argument to `DBOS.startWorkflow`.\nWorkflows with the same priority are dequeued in **FIFO (first in, first out)** order. Priority values can range from `1` to `2,147,483,647`, where **a low number indicates a higher priority**.\nIf using priority, you must set `usePriority: true` on your queue.\n\n:::tip\nWorkflows without assigned priorities have the highest priority and are dequeued before workflows with assigned priorities.\n:::\n\nExample syntax:\n\n```javascript\nconst queue = new WorkflowQueue("example_queue", {usePriority: true});\n\nasync function taskFunction(task) {\n    // ...\n}\nconst taskWorkflow = DBOS.registerWorkflow(taskFunction, {"name": "taskWorkflow"});\n\nasync function main() {\n  const task = ...\n  const priority: number = ...\n  const handle = await DBOS.startWorkflow(taskWorkflow, {queueName: queue.name, enqueueOptions: {priority: priority}})(task);\n}\n```\n\n## Classes\n\nYou can use class instance methods as workflows and steps.\nAny class instance method can be freely used as a step using the DBOS.step decorator or DBOS.runstep; there are no special requirements.\nTo use a class instance method as a workflow, you must use the DBOS.workflow decorator and the class must inherit from `ConfiguredInstance`.\nFor example:\n\n```typescript\nclass MyClass extends ConfiguredInstance {\n  cfg: MyConfig;\n  constructor(name: string, config: MyConfig) {\n    super(name);\n    this.cfg = cfg;\n  }\n\n  override async initialize() : Promise<void> {\n    // ... Validate this.cfg; will be called at DBOS.launch()\n  }\n\n  @DBOS.workflow()\n  async testWorkflow(p: string): Promise<void> {\n    // ... Operations that use this.cfg\n  }\n}\n\nconst myClassInstance = new MyClass(\'instanceA\');\n```\n\nWhen you create a new instance of such a class, the constructor for the base `ConfiguredInstance` must be called with a `name`.\nThis `name` should be unique among instances of the same class.\nAdditionally, all `ConfiguredInstance` classes must be instantiated before DBOS.launch() is called.\n\nThe reason for these requirements is to enable workflow recovery.  When you create a new instance of, DBOS stores it in a global registry indexed by `name`.  When DBOS needs to recover a workflow belonging to that class, it looks up the `name` so it can run the workflow using the right class instance.  While names are used by DBOS Transact internally to find the correct object instance across system restarts, they are also potentially useful for monitoring, tracing, and debugging.\nYou should AVOID using ConfiguredInstance if at all possible and instead use registerWorkflow on regular non-class functions.\n\n\n### Testing DBOS Functions\n\nUnless otherwise specified, recommend testing DBOS applications with jest.\n\nYou MUST use this beforeAll to reset DBOS between tests:\n\n```javascript\n  beforeAll(async () => {\n    DBOS.setConfig({\n      name: \'my-app\',\n      databaseUrl: process.env.DBOS_TESTING_DATABASE_URL,\n    });\n    await DBOS.launch();\n  });\n```\n\n\n### Logging\n\nALWAYS log errors like this:\n\n```typescript\n      DBOS.logger.error(`Error: ${(error as Error).message}`);\n```\n\n## Workflow Handles\n\nA workflow handle represents the state of a particular active or completed workflow execution.\nYou obtain a workflow handle when using `DBOS.startWorkflow` to start a workflow in the background.\nIf you know a workflow\'s identity, you can also retrieve its handle using `DBOS.retrieveWorkflow`.\n\nWorkflow handles have the following methods:\n\n### handle.workflowID\n\n```typescript\nhandle.workflowID(): string;\n```\n\nRetrieve the ID of the workflow.\n\n### handle.getResult\n\n```typescript\nhandle.getResult(): Promise<R>;\n```\n\nWait for the workflow to complete, then return its result.\n\n### handle.getStatus\n\n```typescript\nhandle.getStatus(): Promise<WorkflowStatus>;\n```\n\nRetrieve the WorkflowStatus of the workflow:\n\n### Workflow Status\n\nSome workflow introspection and management methods return a `WorkflowStatus`.\nThis object has the following definition:\n\n```typescript\nexport interface WorkflowStatus {\n  // The workflow ID\n  readonly workflowID: string;\n  // The workflow status. Must be one of ENQUEUED, PENDING, SUCCESS, ERROR, CANCELLED, or RETRIES_EXCEEDED\n  readonly status: string;\n  // The name of the workflow function.\n  readonly workflowName: string;\n  // The name of the workflow\'s class, if any\n  readonly workflowClassName: string; // The class name holding the workflow function.\n  // The name with which the workflow\'s class instance was configured, if any.\n  readonly workflowConfigName?: string;\n  // If the workflow was enqueued, the name of the queue.\n  readonly queueName?: string;\n  // The workflow\'s output, if any.\n  readonly output?: unknown;\n  // The error thrown by the workflow, if any.\n  readonly error?: unknown;\n  // The deserialized workflow inputs.\n  readonly input?: unknown[];\n  // The ID of the executor (process) that most recently executed this workflow.\n  readonly executorId?: string;\n  // The application version on which this workflow started.\n  readonly applicationVersion?: string;\n  // The number of times this workflow has been started.\n  readonly recoveryAttempts?: number;\n  // Workflow start time, as a UNIX epoch timestamp in milliseconds\n  readonly createdAt: number;\n  // Last time the workflow status was updated, as a UNIX epoch timestamp in milliseconds. For a completed workflow, this is the workflow completion timestamp.\n  readonly updatedAt?: number;\n  // The timeout specified for this workflow, if any. Timeouts are start-to-close.\n  readonly timeoutMS?: number | null;\n  // The deadline at which this workflow times out, if any. Not set until the workflow begins execution.\n  readonly deadlineEpochMS?: number;\n}\n```\n\n## DBOS Variables\n\n### DBOS.workflowID\n\n```typescript\nDBOS.workflowID: string | undefined;\n```\n\nReturn the ID of the current workflow, if in a workflow.\n\n### DBOS.stepID\n\n```typescript\nDBOS.stepID: string | undefined;\n```\n\nReturn the unique ID of the current step within a workflow.\n\n### DBOS.stepStatus\n\n```typescript\nDBOS.stepStatus: StepStatus | undefined;\n```\n\nReturn the status of the currently executing step.\nThis object has the following properties:\n\n```typescript\ninterface StepStatus {\n  // The unique ID of this step in its workflow.\n  stepID: number;\n  // For steps with automatic retries, which attempt number (zero-indexed) is currently executing.\n  currentAttempt?: number;\n  // For steps with automatic retries, the maximum number of attempts that will be made before the step fails.\n  maxAttempts?: number;\n}\n```\n\n\n## Workflow Management Methods\n\n### DBOS.listWorkflows\n\n```typescript\nDBOS.listWorkflows(\n  input: GetWorkflowsInput\n): Promise<WorkflowStatus[]>\n```\n\n```typescript\ninterface GetWorkflowsInput {\n  workflowIDs?: string[];\n  workflowName?: string;\n  status?: string;\n  startTime?: string;\n  endTime?: string;\n  applicationVersion?: string;\n  authenticatedUser?: string;\n  limit?: number;\n  offset?: number;\n  sortDesc?: boolean;\n}\n```\n\nRetrieve a list of WorkflowStatus of all workflows matching specified criteria.\n\n**Parameters:**\n- **workflowIDs**: Retrieve workflows with these IDs.\n- **workflowName**: Retrieve workflows with this name.\n- **status**: Retrieve workflows with this status (Must be `ENQUEUED`, `PENDING`, `SUCCESS`, `ERROR`, `CANCELLED`, or `RETRIES_EXCEEDED`)\n- **startTime**: Retrieve workflows started after this (RFC 3339-compliant) timestamp.\n- **endTime**: Retrieve workflows started before this (RFC 3339-compliant) timestamp.\n- **applicationVersion**: Retrieve workflows tagged with this application version.\n- **authenticatedUser**: Retrieve workflows run by this authenticated user.\n- **limit**: Retrieve up to this many workflows.\n- **offset**: Skip this many workflows from the results returned (for pagination).\n- **sortDesc**: Whether to sort the results in descending (`True`) or ascending (`False`) order by workflow start time.\n\n### DBOS.listQueuedWorkflows\n\n```typescript\nDBOS.listQueuedWorkflows(\n  input: GetQueuedWorkflowsInput\n): Promise<WorkflowStatus[]>\n```\n\n```typescript\ninterface GetQueuedWorkflowsInput {\n  workflowName?: string;\n  status?: string;\n  queueName?: number;\n  startTime?: string;\n  endTime?: string;\n  limit?: number;\n  offset?: number;\n  sortDesc?: boolean;\n}\n```\n\nRetrieve a list of WorkflowStatus of all **currently enqueued** workflows matching specified criteria.\n\n**Parameters:**\n- **workflowName**: Retrieve workflows with this name.\n- **status**: Retrieve workflows with this status (Must be `ENQUEUED`, `PENDING`, `SUCCESS`, `ERROR`, `CANCELLED`, or `RETRIES_EXCEEDED`)\n- **queueName**: Retrieve workflows running on this queue.\n- **startTime**: Retrieve workflows started after this (RFC 3339-compliant) timestamp.\n- **endTime**: Retrieve workflows started before this (RFC 3339-compliant) timestamp.\n- **limit**: Retrieve up to this many workflows.\n- **offset**: Skip this many workflows from the results returned (for pagination).\n- **sortDesc**: Whether to sort the results in descending (`True`) or ascending (`False`) order by workflow start time.\n\n### DBOS.listWorkflowSteps\n```typescript\nDBOS.listWorkflowSteps(\n  workflowID: string)\n: Promise<StepInfo[]>\n```\n\nRetrieve the steps of a workflow.\nThis is a list of `StepInfo` objects, with the following structure:\n\n```typescript\ninterface StepInfo {\n  // The unique ID of the step in the workflow. Zero-indexed.\n  readonly functionID: number;\n  // The name of the step\n  readonly name: string;\n  // The step\'s output, if any\n  readonly output: unknown;\n  // The error the step threw, if any\n  readonly error: Error | null;\n  // If the step starts or retrieves the result of a workflow, its ID\n  readonly childWorkflowID: string | null;\n}\n```\n\n### DBOS.cancelWorkflow\n\n```typescript\ncancelWorkflow(\n  workflowID: string\n): Promise<void>\n```\n\nCancel a workflow.\nThis sets is status to `CANCELLED`, removes it from its queue (if it is enqueued) and preempts its execution (interrupting it at the beginning of its next step)\n\n### DBOS.resumeWorkflow\n\n```typescript\nDBOS.resumeWorkflow<T>(\n  workflowID: string\n): Promise<WorkflowHandle<Awaited<T>>> \n```\n\nResume a workflow.\nThis immediately starts it from its last completed step.\nYou can use this to resume workflows that are cancelled or have exceeded their maximum recovery attempts.\nYou can also use this to start an enqueued workflow immediately, bypassing its queue.\n\n### DBOS.forkWorkflow\n\n```typescript\nstatic async forkWorkflow<T>(\n  workflowID: string,\n  startStep: number,\n  options?: { newWorkflowID?: string; applicationVersion?: string; timeoutMS?: number },\n): Promise<WorkflowHandle<Awaited<T>>>\n```\n\nStart a new execution of a workflow from a specific step.\nThe input step ID (`startStep`) must match the `functionID` of the step returned by `listWorkflowSteps`.\nThe specified `startStep` is the step from which the new workflow will start, so any steps whose ID is less than `startStep` will not be re-executed.\n\n**Parameters:**\n- **workflowID**: The ID of the workflow to fork.\n- **startStep**: The ID of the step from which to start the forked workflow. Must match the `functionID` of the step in the original workflow execution.\n- **newWorkflowID**: The ID of the new workflow created by the fork. If not specified, a random UUID is used.\n- **applicationVersion**: The application version on which the forked workflow will run. Useful for "patching" workflows that failed due to a bug in the previous application version.\n- **timeoutMS**: A timeout for the forked workflow in milliseconds.\n'})}),"\n",(0,s.jsx)(n.h2,{id:"configuring-dbos",children:"Configuring DBOS"}),"\n",(0,s.jsxs)(n.p,{children:["To configure DBOS, pass in a configuration with ",(0,s.jsx)(n.code,{children:"DBOS.setConfig"})," before you call ",(0,s.jsx)(n.code,{children:"DBOS.launch"}),".\nFor example:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"DBOS.setConfig({\n  name: 'my-app',\n  systemDatabaseUrl: process.env.DBOS_SYSTEM_DATABASE_URL,\n});\nawait DBOS.launch();\n"})}),"\n",(0,s.jsxs)(n.p,{children:["A configuration object has the following fields.\nAll fields except ",(0,s.jsx)(n.code,{children:"name"})," are optional."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"export interface DBOSConfig {\n  name?: string;\n\n  systemDatabaseUrl?: string;\n  systemDatabasePoolSize?: number;\n  systemDatabasePool?: Pool;\n\n  enableOTLP?: boolean;\n  logLevel?: string;\n  otlpLogsEndpoints?: string[];\n  otlpTracesEndpoints?: string[];\n\n  runAdminServer?: boolean;\n  adminPort?: number;\n\n  applicationVersion?: string;\n}\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"name"}),": Your application's name."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"systemDatabaseUrl"}),": A connection string to a Postgres database in which DBOS can store internal state. The supported format is:"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"postgresql://[username]:[password]@[hostname]:[port]/[database name]\n"})}),"\n",(0,s.jsx)(n.p,{children:"The default is:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"postgresql://postgres:dbos@localhost:5432/[application name]_dbos_sys\n"})}),"\n",(0,s.jsx)(n.p,{children:"If the Postgres database referenced by this connection string does not exist, DBOS will attempt to create it."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"systemDatabasePoolSize"}),": The size of the connection pool used for the DBOS system database. Defaults to 10."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"systemDatabasePool"}),": A custom ",(0,s.jsx)(n.code,{children:"node-postgres"})," connection pool to use to connect to your system database. If provided, DBOS will not create a connection pool but use this instead."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"enableOTLP"}),": Enable DBOS OpenTelemetry tracing and export. Defaults to False."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"logLevel"}),": Configure the DBOS logger severity. Defaults to ",(0,s.jsx)(n.code,{children:"info"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"otlpTracesEndpoints"}),": DBOS operations automatically generate OpenTelemetry Traces. Use this field to declare a list of OTLP-compatible receivers."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"otlpLogsEndpoints"}),": DBOS operations automatically generate OpenTelemetry Logs. Use this field to declare a list of OTLP-compatible receivers."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"runAdminServer"}),": Whether to run an HTTP admin server for workflow management operations. Defaults to True."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"adminPort"}),": The port on which the admin server runs. Defaults to 3001."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"applicationVersion"}),": The code version for this application and its workflows."]}),"\n"]})]})}function f(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>i});var o=t(6540);const s={},r=o.createContext(s);function a(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);